{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lesson 1: Introduction to Deep Learning and Fully Connected Networks\n",
    "\n",
    "### Topics\n",
    "* Introduction to PyTorch\n",
    "* Fully-connected neural networks for regression and classification\n",
    "* Modeling process: prepare data, prepare model, train model, evaluate model, make predictions\n",
    "\n",
    "### Outcomes\n",
    "\n",
    "1. **Understand deep learning fundamentals**, including the structure of neural networks.\n",
    "2. **Utilize PyTorch datasets and data loaders** to efficiently handle and preprocess data for training deep learning models.\n",
    "3. **Develop and train basic fully connected neural networks** in PyTorch, applying optimization techniques and appropriate loss functions.\n",
    "4. **Evaluate model performance** by plotting loss functions and other metrics.\n",
    "5. **Make predictions for new data** by applying a trained neural network to new inputs.\n",
    "\n",
    "### Readings and Videos\n",
    "\n",
    "* **Course Intro Notebook / Video** (Still to come)\n",
    "\n",
    "* **(Optional) Review Neural Networks from DS740**\n",
    "\n",
    "    * You might want to review the first 14 slides of the [Lesson on Neural networks in DS740](https://media.uwex.edu/content/ds/ds740_r23/ds740_artificial-neural-networks.sbproj/).  We're covering similar material this week.  Don't review the material about neural networks in R since we'll be using Python.\n",
    "\n",
    "* **Readings from Inside Deep Learning (IDL)**\n",
    "\n",
    "    * **Chapter 1: The Mechanics of Learning**\n",
    "        - **Read Sections 1.2, 1.4, and 1.5**. Skim the other sections. No need to understand the detailed code or the backpropagation algorithm, but ensure you understand how the gradient is used in training.\n",
    "\n",
    "    * **Chapter 2: Fully Connected Networks**\n",
    "        - **Section 2.1**: Focus on understanding the training loop structure and process. Skip the code details but grasp the concept.\n",
    "            - Don’t worry about the math notation at the bottom of page 40. It's shorthand for a fully connected linear layer. If you want to learn more about matrix multiplication see the videos listed under Auxiliary Materials below.\n",
    "        - **Section 2.2**: Understand how activation functions introduce nonlinearity into networks.\n",
    "        - **Section 2.3**: Grasp the basics of softmax and cross-entropy, especially how the loss function changes for classification tasks. An example will be explained in a notebook and video.\n",
    "        - **Section 2.4**: Note the key concepts; they will be reinforced in video lectures.\n",
    "        - **Section 2.5**: Understand the importance of batch training, particularly for large datasets that won’t fit in memory.\n",
    "\n",
    "* **Course Notebooks with Videos**  Open each of the notebooks included in the lesson folder and watch the embedded video.  You can read along and work through the code examples as needed.  The notebooks for this lesson are in the Lesson_01 directory.  The notebooks are numbered in the order they should be used.\n",
    "### Assessments\n",
    "\n",
    "1.  Complete the reading quiz in Canvas (10 points).\n",
    "2.  Complete the exercises in your the homework notebook in CoCalc (40 points).\n",
    "\n",
    "### Auxiliary Materials\n",
    "\n",
    "- **Background Mathematics from Dr. Anne Hsu:**\n",
    "    * [Matrices and Vectors](https://www.youtube.com/watch?v=sM2Mm6aT_HI)\n",
    "    * [Derivatives and Gradients 1](https://www.youtube.com/watch?v=Fiw0_w4AykA)\n",
    "    * [Derivatives and Gradients 2](https://www.youtube.com/watch?v=qORZmKCB0g8)\n",
    "    * [Playlist for entire Intro to Deep Learning](https://www.youtube.com/@drannehsu/playlists)\n",
    "- **Object-Oriented Programming** It helps to have a basic familiarity with classes, inheritance, and methods for finding your way around in PyTorch.  [Real Python has a great tutorial](https://realpython.com/python3-object-oriented-programming/) on the basics of OOP with many code examples that you can either read or watch (40 minutes).\n",
    "- **Deep Learning Basics: Introduction and Overview**  Lex Fridman is a well known podcast host for AI and Data Science.  Here he gives an [introductory lecture](https://youtu.be/O5xeyoRL95U?si=SrM7RLWB_iBPMiK4) for MIT's public deep learning class.  Since it was recorded in 2019 it doesn't include the latest on transformer architectures that are driving the current boom in AI (ChatGPT, etc.), it's still a great introduction that discusses many applications of deep learning.  Watch this if you want a good overview.  I also recommend his podcast.\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "UWL-DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
