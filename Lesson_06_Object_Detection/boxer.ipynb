{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed JSON saved to ./pictures/stick_peds.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "\n",
    "def process_annotations(input_file, output_file):\n",
    "    \"\"\"\n",
    "    Process an annotation JSON file to output bounding boxes in x, y, w, h format.\n",
    "\n",
    "    Parameters:\n",
    "    - input_file (str): Path to the input annotation JSON file.\n",
    "    - output_file (str): Path to save the processed JSON file.\n",
    "    \"\"\"\n",
    "    # Load the original JSON file\n",
    "    with open(input_file, 'r') as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    # Initialize lists for ground truth and predictions\n",
    "    gt_boxes = []\n",
    "    pred_boxes = []\n",
    "\n",
    "    # Process ground truth and predictions\n",
    "    for annotation in data[\"imagesLib\"][0][\"annotations\"]:\n",
    "        # Get the class name\n",
    "        class_name = data[\"classes\"][annotation[\"classI\"]][\"name\"]\n",
    "        \n",
    "        # Extract bounding box in x, y, w, h format\n",
    "        x = annotation[\"position\"][\"x\"]\n",
    "        y = annotation[\"position\"][\"y\"]\n",
    "        w = annotation[\"position\"][\"width\"]\n",
    "        h = annotation[\"position\"][\"height\"]\n",
    "        box = [x, y, w, h]\n",
    "        \n",
    "        # Separate ground truth and predictions based on the class name\n",
    "        if class_name == \"Truth\":\n",
    "            gt_boxes.append(box)\n",
    "        elif class_name == \"Pred\":\n",
    "            pred_boxes.append(box)\n",
    "\n",
    "    # Convert lists to numpy arrays\n",
    "    gt_boxes_np = np.array(gt_boxes)\n",
    "    pred_boxes_np = np.array(pred_boxes)\n",
    "\n",
    "    # Generate ground truth labels (all ones)\n",
    "    gt_labels_np = np.ones(len(gt_boxes_np), dtype=int)\n",
    "\n",
    "    # Generate predicted labels (all ones) and random scores\n",
    "    pred_labels_np = np.ones(len(pred_boxes_np), dtype=int)\n",
    "    pred_scores_np = np.random.uniform(0, 1, size=len(pred_boxes_np))\n",
    "\n",
    "    # Create the output structure\n",
    "    output_data = {\n",
    "        \"gt_boxes\": gt_boxes_np.tolist(),\n",
    "        \"gt_labels\": gt_labels_np.tolist(),\n",
    "        \"pred_boxes\": pred_boxes_np.tolist(),\n",
    "        \"pred_labels\": pred_labels_np.tolist(),\n",
    "        \"pred_scores\": pred_scores_np.tolist()\n",
    "    }\n",
    "\n",
    "    # Save the processed data to a new JSON file\n",
    "    with open(output_file, 'w') as file:\n",
    "        json.dump(output_data, file, indent=4)\n",
    "\n",
    "    print(f\"Processed JSON saved to {output_file}\")\n",
    "\n",
    "# Example usage\n",
    "input_file = \"./pictures/annotations.json\"  # Replace with the path to your input file\n",
    "output_file = \"./pictures/stick_peds.json\"  # Replace with the desired output file path\n",
    "process_annotations(input_file, output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "\n",
    "def load_annotations(json_file):\n",
    "    \"\"\"\n",
    "    Load annotations from a JSON file and return values as numpy arrays.\n",
    "\n",
    "    Parameters:\n",
    "    json_file (str): Path to the annotations JSON file.\n",
    "\n",
    "    Returns:\n",
    "    tuple: Numpy arrays for gt_boxes, gt_labels, pred_boxes, pred_labels, pred_scores.\n",
    "    \"\"\"\n",
    "    # Load the JSON file\n",
    "    with open(json_file, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    \n",
    "    # Convert the JSON lists to numpy arrays\n",
    "    gt_boxes = np.array(data[\"gt_boxes\"])\n",
    "    gt_labels = np.array(data[\"gt_labels\"])\n",
    "    pred_boxes = np.array(data[\"pred_boxes\"])\n",
    "    pred_labels = np.array(data[\"pred_labels\"])\n",
    "    pred_scores = np.array(data[\"pred_scores\"])\n",
    "    \n",
    "    return gt_boxes, gt_labels, pred_boxes, pred_labels, pred_scores\n",
    "\n",
    "gt_boxes, gt_labels, pred_boxes, pred_labels, pred_scores = load_annotations(\"./pictures/stick_peds.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground Truth Boxes:\n",
      " [[170.35074627  97.34328358 251.47014925 235.24626866]\n",
      " [377.20522388  73.00746269 454.26865672 200.77052239]\n",
      " [547.55597015 168.32276119 615.49347015 273.77798507]\n",
      " [748.32649254  60.83955224 810.18003731 175.42070896]\n",
      " [908.53731343 165.28078358 985.60074627 295.07182836]\n",
      " [867.97761194 416.75093284 933.88712687 523.22014925]\n",
      " [717.90671642 283.91791045 794.97014925 412.69496269]\n",
      " [488.74440299 386.33115672 567.8358209  511.05223881]\n",
      " [265.66604478 335.6299774  340.70149254 454.26710426]\n",
      " [ 75.03544776 306.22574627 136.88899254 405.59701493]]\n",
      "Ground Truth Labels:\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      "Predicted Boxes:\n",
      " [[179.4766791  102.41324627 256.54011194 242.34421642]\n",
      " [366.05130597  82.13339552 442.10074627 210.91044776]\n",
      " [519.1641791  149.05690299 600.28358209 239.30223881]\n",
      " [492.80037313  31.43376866 552.62593284 112.55317164]\n",
      " [145.00093284 159.19682836 235.24626866 225.10634328]\n",
      " [121.67910448 440.07276119 181.50466418 517.13619403]\n",
      " [ 79.09141791 307.23973881 134.86100746 404.58302239]\n",
      " [257.55410448 331.5755597  347.7994403  465.42257463]\n",
      " [233.21828358 325.49160448 332.58955224 397.48507463]\n",
      " [296.0858209  425.87686567 365.03731343 477.59048507]\n",
      " [482.66044776 379.23320896 569.86380597 518.15018657]\n",
      " [511.05223881 446.15671642 596.22761194 488.74440299]\n",
      " [945.04104478  39.54570896 997.76865672 132.83302239]\n",
      " [697.62686567 307.23973881 781.78824627 433.98880597]\n",
      " [711.82276119  51.7136194  758.46641791 136.88899254]\n",
      " [555.66791045 177.44869403 624.61940299 286.95988806]\n",
      " [861.89365672 409.65298507 928.81716418 518.15018657]\n",
      " [915.63526119 169.33675373 980.53078358 299.12779851]]\n",
      "Predicted Labels:\n",
      " [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "Predicted Scores:\n",
      " [0.2384148  0.35424461 0.29132913 0.54043922 0.81906137 0.87885093\n",
      " 0.42911579 0.71010653 0.51089904 0.14968711 0.11734798 0.69700301\n",
      " 0.76346963 0.8970509  0.63767008 0.96248478 0.25422128 0.53295308]\n"
     ]
    }
   ],
   "source": [
    "# Load the annotations from the JSON file\n",
    "gt_boxes, gt_labels, pred_boxes, pred_labels, pred_scores = load_annotations(\"./pictures/processed_annotations.json\")\n",
    "\n",
    "# Print the arrays\n",
    "print(\"Ground Truth Boxes:\\n\", gt_boxes)\n",
    "print(\"Ground Truth Labels:\\n\", gt_labels)\n",
    "print(\"Predicted Boxes:\\n\", pred_boxes)\n",
    "print(\"Predicted Labels:\\n\", pred_labels)\n",
    "print(\"Predicted Scores:\\n\", pred_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DS776_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
