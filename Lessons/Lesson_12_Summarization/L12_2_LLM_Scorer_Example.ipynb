{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35984259",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DS776 Auto-Update (runs in ~2 seconds, only updates when needed)\n",
    "# If this cell fails, see Lessons/Course_Tools/AUTO_UPDATE_SYSTEM.md for help\n",
    "%run ../Course_Tools/auto_update_introdl.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d5c176",
   "metadata": {},
   "outputs": [],
   "source": [
    "from introdl import config_paths_keys, llm_generate\n",
    "\n",
    "# call config_paths_keys() before importing hugging face packages\n",
    "paths = config_paths_keys()\n",
    "MODELS_PATH = paths['MODELS_PATH'] # where to store your trained models\n",
    "DATA_PATH = paths['DATA_PATH'] # where to store downloaded data\n",
    "CACHE_PATH = paths['CACHE_PATH'] # where to store pretrained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5849fa60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_score(generated_text, reference_text, model_name=\"google/gemini-2.5-flash-lite\"):\n",
    "    \n",
    "    system_instruct = \"You are an expert text evaluator.\"\n",
    "    \n",
    "    prompt = (\n",
    "    f\"Evaluate the similarity between the following generated text and reference text. \"\n",
    "    f\"Score their similarity on a scale from 0 to 100, where 0 means no similarity and 100 means perfect similarity.\\n\\n\"\n",
    "    \n",
    "    \"Example:\\n\"\n",
    "    \"Reference Text: The quick brown fox jumps over the lazy dog.\\n\"\n",
    "    \"Generated Text: The fast crimson fox bounded over the sluggish brown hound.\\n\"\n",
    "    \"Similarity Score: 90\\n\\n\"\n",
    "        \n",
    "    \"Example 2:\\n\"\n",
    "    \"Reference Text: The quick brown fox jumps over the lazy dog.\\n\"\n",
    "    \"Generated Text: A slow green lizard leaps over a sleepy cat.\\n\"\n",
    "    \"Similarity Score: 10\\n\\n\"\n",
    "        \n",
    "    f\"Reference Text: {reference_text}\\n\\n\"\n",
    "    f\"Generated Text: {generated_text}\\n\\n\"\n",
    "    f\"Respond with only the numeric score.\"\n",
    "    )\n",
    "\n",
    "\n",
    "    # Make the API request\n",
    "    try:\n",
    "        response= llm_generate(model_name, prompt, system_prompt=system_instruct, temperature=0)\n",
    "        return int(response)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
