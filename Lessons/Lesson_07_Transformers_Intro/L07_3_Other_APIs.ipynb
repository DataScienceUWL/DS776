{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Other LLM Providers (Optional)\n",
    "\n",
    "**‚ö†Ô∏è This notebook is optional** - you only need it if you want to use LLM providers other than OpenRouter.\n",
    "\n",
    "## Why Use Other Providers?\n",
    "\n",
    "**OpenRouter** is our default and **recommended** provider because:\n",
    "- ‚úÖ **Automatic cost tracking** - know exactly how much you're spending\n",
    "- ‚úÖ **Access to many models** - Claude, GPT, Gemini, Llama, and more\n",
    "- ‚úÖ **Single API key** - one key for all models\n",
    "- ‚úÖ **Student credits** - $15 credit provided for this course\n",
    "\n",
    "However, you might want to use other providers directly if:\n",
    "- üí∞ **~10-20% cheaper** - Direct API access skips OpenRouter's small markup\n",
    "- üîë **You already have API keys** - from OpenAI, Google, Anthropic, etc.\n",
    "- ‚ö° **Ultra-fast inference** - Groq offers extremely fast responses\n",
    "\n",
    "## Comparison of Providers\n",
    "\n",
    "| Provider | Best For | Cost Tracking | Setup Complexity |\n",
    "|----------|----------|---------------|------------------|\n",
    "| **OpenRouter** (default) | Everything - recommended | ‚úÖ Automatic | ‚úÖ Easy (one key) |\n",
    "| **OpenAI** | Latest GPT models | ‚ö†Ô∏è Manual | ‚ö†Ô∏è Moderate |\n",
    "| **Anthropic** | Claude models | ‚ö†Ô∏è Manual | ‚ö†Ô∏è Moderate |\n",
    "| **Google** | Gemini models | ‚ö†Ô∏è Manual | ‚ö†Ô∏è Moderate |\n",
    "| **Together.AI** | Open-weight models | ‚ö†Ô∏è Manual | ‚ö†Ô∏è Moderate |\n",
    "| **Groq** | Ultra-fast inference | ‚ö†Ô∏è Manual | ‚ö†Ô∏è Moderate |\n",
    "\n",
    "**Cost Tracking:**\n",
    "- **Automatic (OpenRouter only)**: Tracks every API call, shows warnings at 50%/75%/90% of credit\n",
    "- **Manual**: You provide `cost_per_m_in` and `cost_per_m_out` parameters for basic tracking, or monitor through provider dashboards"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup: Adding API Keys\n",
    "\n",
    "All API keys should be added to `~/home_workspace/api_keys.env`. They'll be automatically loaded by `config_paths_keys()`.\n",
    "\n",
    "### Get API Keys:\n",
    "1. **OpenAI**: https://platform.openai.com/api-keys\n",
    "2. **Anthropic**: https://console.anthropic.com/settings/keys\n",
    "3. **Google**: https://makersuite.google.com/app/apikey\n",
    "4. **Together.AI**: https://api.together.xyz/settings/api-keys\n",
    "5. **Groq**: https://console.groq.com/keys\n",
    "\n",
    "### Add to `~/home_workspace/api_keys.env`:\n",
    "```bash\n",
    "# OpenRouter (already set up for you)\n",
    "OPENROUTER_API_KEY=sk-or-...\n",
    "\n",
    "# Add these only if you have accounts:\n",
    "OPENAI_API_KEY=sk-proj-...\n",
    "ANTHROPIC_API_KEY=sk-ant-...\n",
    "GOOGLE_API_KEY=...\n",
    "TOGETHER_API_KEY=...\n",
    "GROQ_API_KEY=gsk_...\n",
    "```\n",
    "\n",
    "The keys will be available as `os.environ['PROVIDER_API_KEY']` after running `config_paths_keys()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How `llm_generate()` Works with Multiple Providers\n",
    "\n",
    "The function has been simplified:\n",
    "\n",
    "```python\n",
    "llm_generate(\n",
    "    model_name,\n",
    "    prompts,\n",
    "    api_key=None,  # If None, uses OPENROUTER_API_KEY\n",
    "    base_url=\"https://openrouter.ai/api/v1\",  # Default to OpenRouter\n",
    "    cost_per_m_in=None,  # $/M input tokens (optional, for cost tracking)\n",
    "    cost_per_m_out=None,  # $/M output tokens (optional, for cost tracking)\n",
    "    ...\n",
    ")\n",
    "```\n",
    "\n",
    "**Key Points:**\n",
    "- Default behavior: Uses OpenRouter with automatic cost tracking\n",
    "- To use other providers: Pass `api_key` and `base_url`\n",
    "- For cost tracking: Also pass `cost_per_m_in` and `cost_per_m_out`\n",
    "- All providers loaded by `config_paths_keys()` are available as `os.environ['KEY_NAME']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Standard imports\nimport os\nfrom introdl.utils import config_paths_keys, wrap_print_text\nfrom introdl.nlp import llm_generate\n\n# Load API keys from ~/home_workspace/api_keys.env\npaths = config_paths_keys()\n\n# Wrap print to format text nicely at 120 characters\nprint = wrap_print_text(print, width=120)\n\nprint(\"‚úÖ API keys loaded into os.environ\")\nprint(f\"   Available keys: {[k for k in os.environ.keys() if 'API_KEY' in k]}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: OpenRouter (Default - Automatic Cost Tracking)\n",
    "\n",
    "No changes needed - this is our default and still works exactly the same!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenRouter - automatic cost tracking (unchanged!)\n",
    "response = llm_generate(\n",
    "    'gemini-flash-lite',\n",
    "    'Explain transformers in one sentence',\n",
    "    print_cost=True\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: OpenAI with Manual Cost Tracking\n",
    "\n",
    "Use GPT models directly with manual cost tracking.\n",
    "\n",
    "**GPT-4o Pricing:** $2.50/M input, $10.00/M output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI with manual cost tracking\n",
    "response = llm_generate(\n",
    "    'gpt-4o',\n",
    "    'Explain deep learning in one sentence',\n",
    "    api_key=os.environ['OPENAI_API_KEY'],\n",
    "    base_url='https://api.openai.com/v1',\n",
    "    cost_per_m_in=2.50,  # $2.50 per M input tokens\n",
    "    cost_per_m_out=10.00,  # $10.00 per M output tokens\n",
    "    print_cost=True\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 3: Anthropic (Claude)\n",
    "\n",
    "Access Claude models directly (no cost tracking by default)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anthropic (no cost tracking)\n",
    "response = llm_generate(\n",
    "    'claude-3-5-sonnet-20241022',\n",
    "    'What is attention in transformers?',\n",
    "    api_key=os.environ['ANTHROPIC_API_KEY'],\n",
    "    base_url='https://api.anthropic.com/v1',\n",
    "    max_tokens=200\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 4: Google Gemini\n",
    "\n",
    "Use Gemini models directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google Gemini\n",
    "response = llm_generate(\n",
    "    'gemini-2.0-flash-exp',\n",
    "    'Explain backpropagation briefly',\n",
    "    api_key=os.environ['GOOGLE_API_KEY'],\n",
    "    base_url='https://generativelanguage.googleapis.com/v1beta/openai/',\n",
    "    max_tokens=150\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 5: Together.AI (Open Models)\n",
    "\n",
    "Access open-weight models like Llama through Together.AI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Together.AI\n",
    "response = llm_generate(\n",
    "    'meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo',\n",
    "    'What is gradient descent?',\n",
    "    api_key=os.environ['TOGETHER_API_KEY'],\n",
    "    base_url='https://api.together.xyz/v1',\n",
    "    max_tokens=150\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 6: Groq (Ultra-Fast Inference)\n",
    "\n",
    "Groq offers extremely fast inference for supported models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Groq - ultra-fast\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "response = llm_generate(\n",
    "    'llama-3.3-70b-versatile',\n",
    "    'What are CNNs?',\n",
    "    api_key=os.environ['GROQ_API_KEY'],\n",
    "    base_url='https://api.groq.com/openai/v1',\n",
    "    max_tokens=100\n",
    ")\n",
    "elapsed = time.time() - start\n",
    "\n",
    "print(response)\n",
    "print(f\"\\n‚ö° Response time: {elapsed:.2f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost Tracking Comparison\n",
    "\n",
    "### OpenRouter (Automatic)\n",
    "```python\n",
    "llm_generate('gemini-flash-lite', 'Your prompt', print_cost=True)\n",
    "# üí∞ Cost: $0.000012 | Tokens: 15 in / 25 out | Model: google/gemini-2.5-flash-lite\n",
    "```\n",
    "\n",
    "### Other Providers (Manual)\n",
    "```python\n",
    "llm_generate('gpt-4o', 'Your prompt',\n",
    "             api_key=os.environ['OPENAI_API_KEY'],\n",
    "             base_url='https://api.openai.com/v1',\n",
    "             cost_per_m_in=2.50,\n",
    "             cost_per_m_out=10.00,\n",
    "             print_cost=True)\n",
    "# üí∞ Cost: $0.000287 | Tokens: 15 in / 25 out | Model: gpt-4o\n",
    "```\n",
    "\n",
    "### Without Cost Parameters\n",
    "```python\n",
    "llm_generate('gpt-4o', 'Your prompt',\n",
    "             api_key=os.environ['OPENAI_API_KEY'],\n",
    "             base_url='https://api.openai.com/v1',\n",
    "             print_cost=True)\n",
    "# ‚ö†Ô∏è  Cost tracking requested but no pricing provided. Add cost_per_m_in and cost_per_m_out parameters...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monitoring Costs Through Provider Dashboards\n",
    "\n",
    "Since automatic tracking only works with OpenRouter, monitor costs through provider dashboards:\n",
    "\n",
    "- **OpenAI**: https://platform.openai.com/usage\n",
    "- **Anthropic**: https://console.anthropic.com/settings/usage  \n",
    "- **Google**: https://console.cloud.google.com/billing\n",
    "- **Together.AI**: https://api.together.xyz/settings/billing\n",
    "- **Groq**: https://console.groq.com/settings/billing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Processing Works with All Providers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch processing with any provider\n",
    "prompts = [\n",
    "    \"What is supervised learning?\",\n",
    "    \"What is unsupervised learning?\",\n",
    "    \"What is reinforcement learning?\"\n",
    "]\n",
    "\n",
    "responses = llm_generate(\n",
    "    'gpt-4o-mini',\n",
    "    prompts,\n",
    "    api_key=os.environ['OPENAI_API_KEY'],\n",
    "    base_url='https://api.openai.com/v1',\n",
    "    cost_per_m_in=0.15,\n",
    "    cost_per_m_out=0.60,\n",
    "    print_cost=True\n",
    ")\n",
    "\n",
    "for i, response in enumerate(responses, 1):\n",
    "    print(f\"\\n{i}. {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common Base URLs Reference\n",
    "\n",
    "```python\n",
    "# OpenRouter (default)\n",
    "base_url = \"https://openrouter.ai/api/v1\"\n",
    "\n",
    "# OpenAI\n",
    "base_url = \"https://api.openai.com/v1\"\n",
    "\n",
    "# Anthropic\n",
    "base_url = \"https://api.anthropic.com/v1\"\n",
    "\n",
    "# Google (Gemini)\n",
    "base_url = \"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    "\n",
    "# Together.AI\n",
    "base_url = \"https://api.together.xyz/v1\"\n",
    "\n",
    "# Groq\n",
    "base_url = \"https://api.groq.com/openai/v1\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "**Recommendation: Stick with OpenRouter** for this course because:\n",
    "- ‚úÖ Automatic cost tracking\n",
    "- ‚úÖ Single API key for all models\n",
    "- ‚úÖ $15 credit provided\n",
    "- ‚úÖ Simple to use\n",
    "\n",
    "**Use other providers if:**\n",
    "- You need ~10-20% lower costs (direct API)\n",
    "- You already have API credits elsewhere\n",
    "- You need ultra-fast inference (Groq)\n",
    "\n",
    "**Remember:**\n",
    "- All keys go in `~/home_workspace/api_keys.env`\n",
    "- Load with `config_paths_keys()`\n",
    "- Pass `cost_per_m_in` and `cost_per_m_out` for manual cost tracking\n",
    "- Monitor costs through provider dashboards"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}