{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DS776 Auto-Update (runs in ~2 seconds, only updates when needed)\n",
    "# If this cell fails, see Lessons/Course_Tools/AUTO_UPDATE_SYSTEM.md for help\n",
    "%run ../../Lessons/Course_Tools/auto_update_introdl.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Homework 01 Assignment\n**Name:** [Student Name Here]  \n**Total Points:** 40\n\n## Submission Checklist\n- [ ] All code cells executed with output saved\n- [ ] All questions answered\n- [ ] Notebook converted to HTML (use the Homework_01_Utilities notebook)\n- [ ] Canvas notebook filename includes `_GRADE_THIS_ONE`\n- [ ] Files uploaded to Canvas\n\n---"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## [6 pts] Syllabus Understanding\n\nBefore we begin with neural networks, let's ensure you've read and understood the course syllabus. Please answer the following questions:\n\n### [2 pts] Question 1: Assignment Deadlines and Late Policy\nBased on the syllabus, when are assignments due each week? What is the penalty for submitting an assignment on Wednesday versus Thursday? What happens if you submit after Thursday's deadline?\n\nüìù **YOUR ANSWER HERE:**\n\n### [2 pts] Question 2: AI Use Policy Summary\nIn your own words, summarize the course's AI use policy. Include:\n- Two specific examples of ENCOURAGED uses of AI in this course\n- Two specific examples of PROHIBITED uses that would result in 0 points\n- Why does the course have this policy (what skills are we trying to develop)?\n\nüìù **YOUR ANSWER HERE:**\n\n### [2 pts] Question 3: Getting Help\nAccording to the syllabus, what is the primary way you should communicate with the instructor for course-related questions? What are the instructor's typical response times during weekdays versus weekends?\n\nüìù **YOUR ANSWER HERE:**"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Classification of 2D Points Arranged in a Spiral\n",
    "\n",
    "## Instructions\n",
    "\n",
    "Read these carefully to be sure you don't leave anything out.\n",
    "\n",
    "Start by playing with the 2 class spiral classification problem in the [Neural Network Playground](https://playground.tensorflow.org/#activation=relu&batchSize=10&dataset=spiral&regDataset=reg-plane&learningRate=0.03&regularizationRate=0&noise=35&networkShape=4,2&seed=0.76765&showTestData=false&discretize=false&percTrainData=80&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification&initZero=false&hideText=false&problem_hide=true&discretize_hide=true&regularization_hide=true&dataset_hide=true&regularizationRate_hide=true).  Note - this link gives you a reduced version of the original website so you can focus on mainly the structure of the NN for this assignment.  \n",
    "\n",
    "Don't change the test/training ratio or the noise level.  Also, use only X1 and X2 as features (inputs) for your network.  Experiment with the network structure and try retraining each network a few times until you find a network architecture that seems to work reasonably well.  Once you've done that you should implement that network here in PyTorch.  \n",
    "\n",
    "We'll generate the initial spiral data for you.  You do the rest.  You should mimic the setup in the compact version of the logisitic regression notebook from class (in Canvas), but make changes to the network, training loop, etc. as needed.\n",
    "\n",
    "In addition to plotting the loss for the training and validation sets vs the epochs, figure out how to do the same for accuracy and share that plot.\n",
    "\n",
    "In the end you should be able to achieve 95% accuracy on the validation data.  I'll likely change a couple of random seeds to see if you've picked a robust architecture and training parameters!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === YOUR IMPORTS HERE ===\n",
    "# Add any additional imports you need below this line\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from Homework_01_Helpers import make_spirals\n",
    "\n",
    "from introdl.utils import config_paths_keys\n",
    "\n",
    "paths = config_paths_keys()\n",
    "MODELS_PATH = paths['MODELS_PATH']\n",
    "DATA_PATH = paths['DATA_PATH']\n",
    "\n",
    "# config_paths_keys() sets where models and data will be stored\n",
    "paths = config_paths_keys()\n",
    "MODELS_PATH = paths[\"MODELS_PATH\"] # Where to save models\n",
    "DATA_PATH = paths[\"DATA_PATH\"]     # Where to save data\n",
    "# === END YOUR IMPORTS ==="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [4 pts] Describe What You Learned in NN Playground\n",
    "\n",
    "Use this cell to explain what you learned in NN playground. What model did you select? What learning rate? What activation function?  Elaborate a bit on your answers to support the choices you made.\n",
    "\n",
    "üìù **YOUR ANSWER HERE:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [4 pts] Prepare the Data\n",
    "\n",
    "We'll build the spirals and split the data into train and test sets. We're using a larger training set than in NN playground for more robust training. Don't modify the provided code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provided code - DO NOT MODIFY\n",
    "from Homework_01_Helpers import make_spirals\n",
    "\n",
    "# Generate spiral data\n",
    "X, y = make_spirals(n_samples=400, noise=35, random_state=0)\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train_tensor = torch.FloatTensor(X_train)\n",
    "y_train_tensor = torch.LongTensor(y_train)\n",
    "X_test_tensor = torch.FloatTensor(X_test)\n",
    "y_test_tensor = torch.LongTensor(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup the Datasets and DataLoaders here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === YOUR CODE HERE ===\n",
    "# TODO: Create TensorDatasets for training and test data\n",
    "# TODO: Create DataLoaders with appropriate batch size\n",
    "\n",
    "\n",
    "# === END YOUR CODE ==="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [4 pts] Visualize the Data\n",
    "\n",
    "Make side-by-side plots showing the training and test data along with the classes for each point. You may have to look up how to use matplotlib.pyplot.subplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === YOUR CODE HERE ===\n",
    "# TODO: Create side-by-side plots of training and test data\n",
    "# - Use subplots to create two plots side by side\n",
    "# - Color points by their class (0 or 1)\n",
    "# - Add titles and labels\n",
    "\n",
    "\n",
    "# === END YOUR CODE ==="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [4 pts] Define the Model\n",
    "\n",
    "Define your model. Create an instance of it. Use `summary` from torchinfo to generate a model summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === YOUR CODE HERE ===\n",
    "# TODO: Define your model class inheriting from nn.Module\n",
    "# Based on your experiments in NN Playground, implement:\n",
    "#   - The appropriate number of layers\n",
    "#   - The appropriate activation functions\n",
    "#   - The appropriate layer sizes\n",
    "\n",
    "class SpiralClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Your implementation\n",
    "        pass\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Your implementation\n",
    "        pass\n",
    "\n",
    "# Create an instance of your model\n",
    "# model = SpiralClassifier()\n",
    "\n",
    "# Display model summary\n",
    "# from torchinfo import summary\n",
    "# summary(model, input_size=(1, 2))\n",
    "\n",
    "# === END YOUR CODE ==="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many trainable parameters are in your model?\n",
    "\n",
    "üìù **YOUR ANSWER HERE:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [4 pts] Train the Model\n",
    "\n",
    "Configure the model training and do the training. Save the checkpoint file in MODELS_PATH.\n",
    "\n",
    "**You should be able to achieve around 95% accuracy on the test data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === YOUR CODE HERE ===\n",
    "# TODO: Configure and train your model\n",
    "# - Set up loss function (appropriate for classification)\n",
    "# - Set up optimizer with appropriate learning rate\n",
    "# - Use train_network function with appropriate parameters\n",
    "# - Save checkpoint to MODELS_PATH\n",
    "\n",
    "\n",
    "# === END YOUR CODE ==="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [4 pts] Inspect Convergence Graphically\n",
    "\n",
    "Load the checkpoint file and use it to plot training and test loss vs epoch and training and test accuracy vs epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === YOUR CODE HERE ===\n",
    "# TODO: Load checkpoint and create plots\n",
    "# - Load the checkpoint file\n",
    "# - Extract training history\n",
    "# - Create 2 subplots: loss vs epoch and accuracy vs epoch\n",
    "# - Show both training and validation metrics\n",
    "\n",
    "\n",
    "# === END YOUR CODE ==="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the maximum test accuracy found by your model?\n",
    "\n",
    "üìù **YOUR ANSWER HERE:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [4 pts] Visualize the Model Fit\n",
    "\n",
    "Plot the fitted model as in the lesson."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === YOUR CODE HERE ===\n",
    "# TODO: Visualize the decision boundary\n",
    "# - Create a mesh grid covering the data space\n",
    "# - Use your model to predict on the grid\n",
    "# - Plot the decision boundary as a contour\n",
    "# - Overlay the actual data points\n",
    "\n",
    "\n",
    "# === END YOUR CODE ==="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comment on the quality of the fit. Does the decision boundary accurately represent the separation of the classes or is there anything about it that seems incorrect?\n",
    "\n",
    "üìù **YOUR ANSWER HERE:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [4 pts] Make Predictions\n",
    "\n",
    "Include a function for making predictions and find the probabilities and predicted labels for new points: (0,0), (0,2), and (0,4)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === YOUR CODE HERE ===\n",
    "# TODO: Create prediction function and make predictions\n",
    "# - Define a function that takes points and returns probabilities and labels\n",
    "# - Make predictions for the three specified points\n",
    "# - Display the results clearly\n",
    "\n",
    "def predict_points(model, points):\n",
    "    \"\"\"\n",
    "    Make predictions for given points.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained model\n",
    "        points: Array of points to predict\n",
    "    \n",
    "    Returns:\n",
    "        probabilities: Class probabilities for each point\n",
    "        predictions: Predicted class labels\n",
    "    \"\"\"\n",
    "    # Your implementation\n",
    "    pass\n",
    "\n",
    "# Test points\n",
    "test_points = np.array([[0, 0], [0, 2], [0, 4]])\n",
    "\n",
    "# Make predictions\n",
    "# probs, preds = predict_points(model, test_points)\n",
    "\n",
    "# === END YOUR CODE ==="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [2 pts] Reflection\n",
    "\n",
    "1. What, if anything, did you find difficult to understand for the lesson? Why?\n",
    "\n",
    "üìù **YOUR ANSWER HERE:**\n",
    "\n",
    "2. What resources did you find supported your learning most and least for this lesson? (Be honest - I use your input to shape the course.)\n",
    "\n",
    "üìù **YOUR ANSWER HERE:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from introdl import export_this_to_html\n# export_this_to_html()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [
    {
     "file_id": "1-HQWPweMIqAYecMoaiEwveKgKWaENYwo",
     "timestamp": 1707429755677
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}