{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Named Entity Recognition\n",
    "\n",
    "In this notebook we'll\n",
    "\n",
    "* List some common applications of NER\n",
    "* Give a brief history of NER\n",
    "* Demonstrate how to setup and fine-tune a DistilBERT model for NER\n",
    "* Discuss some of the issues with using an LLM for an NER task\n",
    "\n",
    "First, make sure your course package is updated for this lesson and homework.  You need to do this once per server, but not once per notebook.  The exact path will depend on where this notebook is in relation to the folder /Lessons/Course_Tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing c:\\users\\bagge\\my drive\\python_projects\\ds776_develop_project\\ds776\\lessons\\course_tools\\introdl\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: accelerate in c:\\users\\bagge\\miniforge-pypy3\\envs\\ds776env\\lib\\site-packages (from introdl==1.0) (1.5.1)\n",
      "Requirement already satisfied: bertviz in c:\\users\\bagge\\miniforge-pypy3\\envs\\ds776env\\lib\\site-packages (from introdl==1.0) (1.4.0)\n",
      "Requirement already satisfied: bitsandbytes>=0.45.3 in c:\\users\\bagge\\miniforge-pypy3\\envs\\ds776env\\lib\\site-packages (from introdl==1.0) (0.45.3)\n",
      "Requirement already satisfied: datasets in c:\\users\\bagge\\miniforge-pypy3\\envs\\ds776env\\lib\\site-packages (from introdl==1.0) (3.3.2)\n",
      "Requirement already satisfied: evaluate in c:\\users\\bagge\\miniforge-pypy3\\envs\\ds776env\\lib\\site-packages (from introdl==1.0) (0.4.3)\n",
      "Requirement already satisfied: gliner in c:\\users\\bagge\\miniforge-pypy3\\envs\\ds776env\\lib\\site-packages (from introdl==1.0) (0.2.17)\n",
      "Requirement already satisfied: google-genai in c:\\users\\bagge\\miniforge-pypy3\\envs\\ds776env\\lib\\site-packages (from introdl==1.0) (1.5.0)\n",
      "Requirement already satisfied: IPython in c:\\users\\bagge\\miniforge-pypy3\\envs\\ds776env\\lib\\site-packages (from introdl==1.0) (9.0.2)\n",
      "Requirement already satisfied: ipywidgets in c:\\users\\bagge\\miniforge-pypy3\\envs\\ds776env\\lib\\site-packages (from introdl==1.0) (8.1.5)\n",
      "Requirement already satisfied: ipycanvas in c:\\users\\bagge\\miniforge-pypy3\\envs\\ds776env\\lib\\site-packages (from introdl==1.0) (0.13.3)\n",
      "Requirement already satisfied: kagglehub in c:\\users\\bagge\\miniforge-pypy3\\envs\\ds776env\\lib\\site-packages (from introdl==1.0) (0.3.10)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\bagge\\miniforge-pypy3\\envs\\ds776env\\lib\\site-packages (from introdl==1.0) (3.10.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\bagge\\miniforge-pypy3\\envs\\ds776env\\lib\\site-packages (from introdl==1.0) (2.1.1)\n",
      "Requirement already satisfied: openai>=1.65.5 in c:\\users\\bagge\\miniforge-pypy3\\envs\\ds776env\\lib\\site-packages (from introdl==1.0) (1.66.3)\n",
      "Requirement already satisfied: pandas in c:\\users\\bagge\\miniforge-pypy3\\envs\\ds776env\\lib\\site-packages (from introdl==1.0) (2.2.3)\n",
      "Requirement already satisfied: protobuf in c:\\users\\bagge\\miniforge-pypy3\\envs\\ds776env\\lib\\site-packages (from introdl==1.0) (6.30.1)\n",
      "Requirement already satisfied: pyperclip in c:\\users\\bagge\\miniforge-pypy3\\envs\\ds776env\\lib\\site-packages (from introdl==1.0) (1.9.0)\n",
      "Requirement already satisfied: rapidfuzz in c:\\users\\bagge\\miniforge-pypy3\\envs\\ds776env\\lib\\site-packages (from introdl==1.0) (3.12.2)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\bagge\\miniforge-pypy3\\envs\\ds776env\\lib\\site-packages (from introdl==1.0) (1.6.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\bagge\\miniforge-pypy3\\envs\\ds776env\\lib\\site-packages (from introdl==1.0) (1.15.2)\n",
      "Requirement already satisfied: seaborn in c:\\users\\bagge\\miniforge-pypy3\\envs\\ds776env\\lib\\site-packages (from introdl==1.0) (0.13.2)\n",
      "Requirement already satisfied: segmentation_models_pytorch in c:\\users\\bagge\\miniforge-pypy3\\envs\\ds776env\\lib\\site-packages (from introdl==1.0) (0.4.0)\n",
      "Requirement already satisfied: seqeval in c:\\users\\bagge\\miniforge-pypy3\\envs\\ds776env\\lib\\site-packages (from introdl==1.0) (1.2.2)\n",
      "Requirement already satisfied: spacy in c:\\users\\bagge\\miniforge-pypy3\\envs\\ds776env\\lib\\site-packages (from introdl==1.0) (3.8.4)\n",
      "Requirement already satisfied: timm in c:\\users\\bagge\\miniforge-pypy3\\envs\\ds776env\\lib\\site-packages (from introdl==1.0) (1.0.15)\n",
      "Requirement already satisfied: torch in c:\\users\\bagge\\miniforge-pypy3\\envs\\ds776env\\lib\\site-packages (from introdl==1.0) (2.6.0+cu124)\n",
      "Requirement already satisfied: torchinfo in c:\\users\\bagge\\miniforge-pypy3\\envs\\ds776env\\lib\\site-packages (from introdl==1.0) (1.8.0)\n",
      "Requirement already satisfied: torchmetrics in c:\\users\\bagge\\miniforge-pypy3\\envs\\ds776env\\lib\\site-packages (from introdl==1.0) (1.6.2)\n",
      "Requirement already satisfied: torchvision in c:\\users\\bagge\\miniforge-pypy3\\envs\\ds776env\\lib\\site-packages (from introdl==1.0) (0.21.0+cu124)\n",
      "Requirement already satisfied: tqdm in c:\\users\\bagge\\miniforge-pypy3\\envs\\ds776env\\lib\\site-packages (from introdl==1.0) (4.67.1)\n",
      "Requirement already satisfied: transformers>=4.40.9 in c:\\users\\bagge\\miniforge-pypy3\\envs\\ds776env\\lib\\site-packages (from introdl==1.0) (4.49.0)\n",
      "Requirement already satisfied: ultralytics in c:\\users\\bagge\\miniforge-pypy3\\envs\\ds776env\\lib\\site-packages (from introdl==1.0) (8.3.89)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\bagge\\miniforge-pypy3\\envs\\ds776env\\lib\\site-packages (from openai>=1.65.5->introdl==1.0) (4.8.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\bagge\\miniforge-pypy3\\envs\\ds776env\\lib\\site-packages (from openai>=1.65.5->introdl==1.0) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\bagge\\miniforge-pypy3\\envs\\ds776env\\lib\\site-packages (from openai>=1.65.5->introdl==1.0) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\bagge\\miniforge-pypy3\\envs\\ds776env\\lib\\site-packages (from openai>=1.65.5->introdl==1.0) (0.9.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\bagge\\miniforge-pypy3\\envs\\ds776env\\lib\\site-packages (from openai>=1.65.5->introdl==1.0) (2.11.0b1)\n",
      "Requirement already satisfied: sniffio in c:\\users\\bagge\\miniforge-pypy3\\envs\\ds776env\\lib\\site-packages (from openai>=1.65.5->introdl==1.0) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\bagge\\miniforge-pypy3\\envs\\ds776env\\lib\\site-packages (from openai>=1.65.5->introdl==1.0) (4.12.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\bagge\\miniforge-pypy3\\envs\\ds776env\\lib\\site-packages (from torch->introdl==1.0) (3.13.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\bagge\\miniforge-pypy3\\envs\\ds776env\\lib\\site-packages (from torch->introdl==1.0) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\bagge\\miniforge-pypy3\\envs\\ds776env\\lib\\site-packages (from torch->introdl==1.0) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\bagge\\miniforge-pypy3\\envs\\ds776env\\lib\\site-packages (from torch->introdl==1.0) (2024.6.1)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\bagge\\miniforge-pypy3\\envs\\ds776env\\lib\\site-packages (from torch->introdl==1.0) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\bagge\\miniforge-pypy3\\envs\\ds776env\\lib\\site-packages (from sympy==1.13.1->torch->introdl==1.0) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\bagge\\miniforge-pypy3\\envs\\ds776env\\lib\\site-packages (from tqdm->introdl==1.0) (0.4.6)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in c:\\users\\bagge\\miniforge-pypy3\\envs\\ds776env\\lib\\site-packages (from transformers>=4.40.9->introdl==1.0) (0.29.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\bagge\\miniforge-pypy3\\envs\\ds776env\\lib\\site-packages (from transformers>=4.40.9->introdl==1.0) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\bagge\\miniforge-pypy3\\envs\\ds776env\\lib\\site-packages (from transformers>=4.40.9->introdl==1.0) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\bagge\\miniforge-pypy3\\envs\\ds776env\\lib\\site-packages (from transformers>=4.40.9->introdl==1.0) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\bagge\\miniforge-pypy3\\envs\\ds776env\\lib\\site-packages (from transformers>=4.40.9->introdl==1.0) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\bagge\\miniforge-pypy3\\envs\\ds776env\\lib\\site-packages (from transformers>=4.40.9->introdl==1.0) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\bagge\\miniforge-pypy3\\envs\\ds776env\\lib\\site-packages (from transformers>=4.40.9->introdl==1.0) (0.5.3)\n",
      "Requirement already satisfied: psutil in c:\\users\\bagge\\miniforge-pypy3\\envs\\ds776env\\lib\\site-packages (from accelerate->introdl==1.0) (7.0.0)\n",
      "Requirement already satisfied: boto3 in c:\\users\\bagge\\miniforge-pypy3\\envs\\ds776env\\lib\\site-packages (from bertviz->introdl==1.0) (1.37.13)\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\bagge\\miniforge-pypy3\\envs\\ds776env\\lib\\site-packages (from bertviz->introdl==1.0) (0.2.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\bagge\\miniforge-pypy3\\envs\\ds776env\\lib\\site-packages (from datasets->introdl==1.0) (19.0.1)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\bagge\\miniforge-pypy3\\envs\\ds776env\\lib\\site-packages (from datasets->introdl==1.0) (0.3.8)\n",
      "Requirement already satisfied: xxhash in c:\\users\\bagge\\miniforge-pypy3\\envs\\ds776env\\lib\\site-packages (from datasets->introdl==1.0) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\bagge\\miniforge-pypy3\\envs\\ds776env\\lib\\site-packages (from datasets->introdl==1.0) (0.70.16)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\bagge\\miniforge-pypy3\\envs\\ds776env\\lib\\site-packages (from datasets->introdl==1.0) (3.11.13)\n",
      "Requirement already satisfied: onnxruntime in c:\\users\\bagge\\miniforge-pypy3\\envs\\ds776env\\lib\\site-packages (from gliner->introdl==1.0) (1.21.0)\n",
      "Requirement already satisfied: google-auth<3.0.0dev,>=2.14.1 in c:\\users\\bagge\\miniforge-pypy3\\envs\\ds776env\\lib\\site-packages (from google-genai->introdl==1.0) (2.38.0)\n",
      "Requirement already satisfied: websockets<15.0dev,>=13.0 in c:\\users\\bagge\\miniforge-pypy3\\envs\\ds776env\\lib\\site-packages (from google-genai->introdl==1.0) (14.2)\n",
      "Requirement already satisfied: pillow>=6.0 in c:\\users\\bagge\\miniforge-pypy3\\envs\\ds776env\\lib\\site-packages (from ipycanvas->introdl==1.0) (11.0.0)\n",
      "Requirement already satisfied: comm>=0.1.3 in c:\\users\\bagge\\miniforge-pypy3\\envs\\ds776env\\lib\\site-packages (from ipywidgets->introdl==1.0) (0.2.2)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in c:\\users\\bagge\\miniforge-pypy3\\envs\\ds776env\\lib\\site-packages (from ipywidgets->introdl==1.0) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.12 in c:\\users\\bagge\\miniforge-pypy3\\envs\\ds776env\\lib\\site-packages (from ipywidgets->introdl==1.0) (4.0.13)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.12 in c:\\users\\bagge\\miniforge-pypy3\\envs\\ds776env\\lib\\site-packages (from ipywidgets->introdl==1.0) (3.0.13)\n",
      "Requirement already satisfied: decorator in c:\\users\\bagge\\miniforge-pypy3\\envs\\ds776env\\lib\\site-packages (from IPython->introdl==1.0) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers in c:\\users\\bagge\\miniforge-pypy3\\envs\\ds776env\\lib\\site-packages (from IPython->introdl==1.0) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\bagge\\miniforge-pypy3\\envs\\ds776env\\lib\\site-packages (from IPython->introdl==1.0) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\bagge\\miniforge-pypy3\\envs\\ds776env\\lib\\site-packages (from IPython->introdl==1.0) (0.1.7)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in c:\\users\\bagge\\miniforge-pypy3\\envs\\ds776env\\lib\\site-packages (from IPython->introdl==1.0) (3.0.50)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\bagge\\miniforge-pypy3\\envs\\ds776env\\lib\\site-packages (from IPython->introdl==1.0) (2.19.1)\n",
      "Requirement already satisfied: stack_data in c:\\users\\bagge\\miniforge-pypy3\\envs\\ds776env\\lib\\site-packages (from IPython->introdl==1.0) (0.6.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\bagge\\miniforge-pypy3\\envs\\ds776env\\lib\\site-packages (from matplotlib->introdl==1.0) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\bagge\\miniforge-pypy3\\envs\\ds776env\\lib\\site-packages (from matplotlib->introdl==1.0) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\bagge\\miniforge-pypy3\\envs\\ds776env\\lib\\site-packages (from matplotlib->introdl==1.0) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\bagge\\miniforge-pypy3\\envs\\ds776env\\lib\\site-packages (from matplotlib->introdl==1.0) (1.4.8)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\bagge\\miniforge-pypy3\\envs\\ds776env\\lib\\site-packages (from matplotlib->introdl==1.0) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\bagge\\miniforge-pypy3\\envs\\ds776env\\lib\\site-packages (from matplotlib->introdl==1.0) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\bagge\\miniforge-pypy3\\envs\\ds776env\\lib\\site-packages (from pandas->introdl==1.0) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\bagge\\miniforge-pypy3\\envs\\ds776env\\lib\\site-packages (from pandas->introdl==1.0) (2025.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\bagge\\miniforge-pypy3\\envs\\ds776env\\lib\\site-packages (from scikit-learn->introdl==1.0) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\bagge\\miniforge-pypy3\\envs\\ds776env\\lib\\site-packages (from scikit-learn->introdl==1.0) (3.6.0)\n",
      "Requirement already satisfied: efficientnet-pytorch>=0.6.1 in c:\\users\\bagge\\miniforge-pypy3\\envs\\ds776env\\lib\\site-packages (from segmentation_models_pytorch->introdl==1.0) (0.7.1)\n",
      "Requirement already satisfied: pretrainedmodels>=0.7.1 in c:\\users\\bagge\\miniforge-pypy3\\envs\\ds776env\\lib\\site-packages (from segmentation_models_pytorch->introdl==1.0) (0.7.4)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\bagge\\miniforge-pypy3\\envs\\ds776env\\lib\\site-packages (from segmentation_models_pytorch->introdl==1.0) (1.17.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\bagge\\miniforge-pypy3\\envs\\ds776env\\lib\\site-packages (from spacy->introdl==1.0) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\bagge\\miniforge-pypy3\\envs\\ds776env\\lib\\site-packages (from spacy->introdl==1.0) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\bagge\\miniforge-pypy3\\envs\\ds776env\\lib\\site-packages (from spacy->introdl==1.0) (1.0.12)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\bagge\\miniforge-pypy3\\envs\\ds776env\\lib\\site-packages (from spacy->introdl==1.0) (2.0.11)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\bagge\\miniforge-pypy3\\envs\\ds776env\\lib\\site-packages (from spacy->introdl==1.0) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in c:\\users\\bagge\\miniforge-pypy3\\envs\\ds776env\\lib\\site-packages (from spacy->introdl==1.0) (8.3.4)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\bagge\\miniforge-pypy3\\envs\\ds776env\\lib\\site-packages (from spacy->introdl==1.0) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\bagge\\miniforge-pypy3\\envs\\ds776env\\lib\\site-packages (from spacy->introdl==1.0) (2.5.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\bagge\\miniforge-pypy3\\envs\\ds776env\\lib\\site-packages (from spacy->introdl==1.0) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in c:\\users\\bagge\\miniforge-pypy3\\envs\\ds776env\\lib\\site-packages (from spacy->introdl==1.0) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in c:\\users\\bagge\\miniforge-pypy3\\envs\\ds776env\\lib\\site-packages (from spacy->introdl==1.0) (0.15.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\bagge\\miniforge-pypy3\\envs\\ds776env\\lib\\site-packages (from spacy->introdl==1.0) (78.0.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\bagge\\miniforge-pypy3\\envs\\ds776env\\lib\\site-packages (from spacy->introdl==1.0) (3.5.0)\n",
      "Requirement already satisfied: lightning-utilities>=0.8.0 in c:\\users\\bagge\\miniforge-pypy3\\envs\\ds776env\\lib\\site-packages (from torchmetrics->introdl==1.0) (0.14.0)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in c:\\users\\bagge\\miniforge-pypy3\\envs\\ds776env\\lib\\site-packages (from ultralytics->introdl==1.0) (4.11.0.86)\n",
      "Requirement already satisfied: py-cpuinfo in c:\\users\\bagge\\miniforge-pypy3\\envs\\ds776env\\lib\\site-packages (from ultralytics->introdl==1.0) (9.0.0)\n",
      "Requirement already satisfied: ultralytics-thop>=2.0.0 in c:\\users\\bagge\\miniforge-pypy3\\envs\\ds776env\\lib\\site-packages (from ultralytics->introdl==1.0) (2.0.14)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\bagge\\miniforge-pypy3\\envs\\ds776env\\lib\\site-packages (from anyio<5,>=3.5.0->openai>=1.65.5->introdl==1.0) (3.10)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\bagge\\miniforge-pypy3\\envs\\ds776env\\lib\\site-packages (from aiohttp->datasets->introdl==1.0) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\bagge\\miniforge-pypy3\\envs\\ds776env\\lib\\site-packages (from aiohttp->datasets->introdl==1.0) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\bagge\\miniforge-pypy3\\envs\\ds776env\\lib\\site-packages (from aiohttp->datasets->introdl==1.0) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\bagge\\miniforge-pypy3\\envs\\ds776env\\lib\\site-packages (from aiohttp->datasets->introdl==1.0) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\bagge\\miniforge-pypy3\\envs\\ds776env\\lib\\site-packages (from aiohttp->datasets->introdl==1.0) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\bagge\\miniforge-pypy3\\envs\\ds776env\\lib\\site-packages (from aiohttp->datasets->introdl==1.0) (0.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\bagge\\miniforge-pypy3\\envs\\ds776env\\lib\\site-packages (from aiohttp->datasets->introdl==1.0) (1.18.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\bagge\\miniforge-pypy3\\envs\\ds776env\\lib\\site-packages (from google-auth<3.0.0dev,>=2.14.1->google-genai->introdl==1.0) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\bagge\\miniforge-pypy3\\envs\\ds776env\\lib\\site-packages (from google-auth<3.0.0dev,>=2.14.1->google-genai->introdl==1.0) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\bagge\\miniforge-pypy3\\envs\\ds776env\\lib\\site-packages (from google-auth<3.0.0dev,>=2.14.1->google-genai->introdl==1.0) (4.9)\n",
      "Requirement already satisfied: certifi in c:\\users\\bagge\\miniforge-pypy3\\envs\\ds776env\\lib\\site-packages (from httpx<1,>=0.23.0->openai>=1.65.5->introdl==1.0) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\bagge\\miniforge-pypy3\\envs\\ds776env\\lib\\site-packages (from httpx<1,>=0.23.0->openai>=1.65.5->introdl==1.0) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\bagge\\miniforge-pypy3\\envs\\ds776env\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>=1.65.5->introdl==1.0) (0.14.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in c:\\users\\bagge\\miniforge-pypy3\\envs\\ds776env\\lib\\site-packages (from jedi>=0.16->IPython->introdl==1.0) (0.8.4)\n",
      "Requirement already satisfied: language-data>=1.2 in c:\\users\\bagge\\miniforge-pypy3\\envs\\ds776env\\lib\\site-packages (from langcodes<4.0.0,>=3.2.0->spacy->introdl==1.0) (1.3.0)\n",
      "Requirement already satisfied: munch in c:\\users\\bagge\\miniforge-pypy3\\envs\\ds776env\\lib\\site-packages (from pretrainedmodels>=0.7.1->segmentation_models_pytorch->introdl==1.0) (4.0.0)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\bagge\\miniforge-pypy3\\envs\\ds776env\\lib\\site-packages (from prompt_toolkit<3.1.0,>=3.0.41->IPython->introdl==1.0) (0.2.13)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\bagge\\miniforge-pypy3\\envs\\ds776env\\lib\\site-packages (from pydantic<3,>=1.9.0->openai>=1.65.5->introdl==1.0) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.31.1 in c:\\users\\bagge\\miniforge-pypy3\\envs\\ds776env\\lib\\site-packages (from pydantic<3,>=1.9.0->openai>=1.65.5->introdl==1.0) (2.31.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\bagge\\miniforge-pypy3\\envs\\ds776env\\lib\\site-packages (from pydantic<3,>=1.9.0->openai>=1.65.5->introdl==1.0) (0.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\bagge\\miniforge-pypy3\\envs\\ds776env\\lib\\site-packages (from requests->transformers>=4.40.9->introdl==1.0) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\bagge\\miniforge-pypy3\\envs\\ds776env\\lib\\site-packages (from requests->transformers>=4.40.9->introdl==1.0) (2.3.0)\n",
      "Requirement already satisfied: blis<1.3.0,>=1.2.0 in c:\\users\\bagge\\miniforge-pypy3\\envs\\ds776env\\lib\\site-packages (from thinc<8.4.0,>=8.3.4->spacy->introdl==1.0) (1.2.0)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\bagge\\miniforge-pypy3\\envs\\ds776env\\lib\\site-packages (from thinc<8.4.0,>=8.3.4->spacy->introdl==1.0) (0.1.5)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\bagge\\miniforge-pypy3\\envs\\ds776env\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy->introdl==1.0) (8.1.8)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\bagge\\miniforge-pypy3\\envs\\ds776env\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy->introdl==1.0) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\bagge\\miniforge-pypy3\\envs\\ds776env\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy->introdl==1.0) (13.9.4)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in c:\\users\\bagge\\miniforge-pypy3\\envs\\ds776env\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy->introdl==1.0) (0.21.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in c:\\users\\bagge\\miniforge-pypy3\\envs\\ds776env\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy->introdl==1.0) (7.1.0)\n",
      "Requirement already satisfied: botocore<1.38.0,>=1.37.13 in c:\\users\\bagge\\miniforge-pypy3\\envs\\ds776env\\lib\\site-packages (from boto3->bertviz->introdl==1.0) (1.37.13)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in c:\\users\\bagge\\miniforge-pypy3\\envs\\ds776env\\lib\\site-packages (from boto3->bertviz->introdl==1.0) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.12.0,>=0.11.0 in c:\\users\\bagge\\miniforge-pypy3\\envs\\ds776env\\lib\\site-packages (from boto3->bertviz->introdl==1.0) (0.11.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\bagge\\miniforge-pypy3\\envs\\ds776env\\lib\\site-packages (from jinja2->torch->introdl==1.0) (2.1.5)\n",
      "Requirement already satisfied: coloredlogs in c:\\users\\bagge\\miniforge-pypy3\\envs\\ds776env\\lib\\site-packages (from onnxruntime->gliner->introdl==1.0) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in c:\\users\\bagge\\miniforge-pypy3\\envs\\ds776env\\lib\\site-packages (from onnxruntime->gliner->introdl==1.0) (25.2.10)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\bagge\\miniforge-pypy3\\envs\\ds776env\\lib\\site-packages (from stack_data->IPython->introdl==1.0) (2.1.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\bagge\\miniforge-pypy3\\envs\\ds776env\\lib\\site-packages (from stack_data->IPython->introdl==1.0) (3.0.0)\n",
      "Requirement already satisfied: pure_eval in c:\\users\\bagge\\miniforge-pypy3\\envs\\ds776env\\lib\\site-packages (from stack_data->IPython->introdl==1.0) (0.2.3)\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in c:\\users\\bagge\\miniforge-pypy3\\envs\\ds776env\\lib\\site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy->introdl==1.0) (1.2.1)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in c:\\users\\bagge\\miniforge-pypy3\\envs\\ds776env\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=2.14.1->google-genai->introdl==1.0) (0.6.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\bagge\\miniforge-pypy3\\envs\\ds776env\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy->introdl==1.0) (3.0.0)\n",
      "Requirement already satisfied: wrapt in c:\\users\\bagge\\miniforge-pypy3\\envs\\ds776env\\lib\\site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy->introdl==1.0) (1.17.2)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in c:\\users\\bagge\\miniforge-pypy3\\envs\\ds776env\\lib\\site-packages (from coloredlogs->onnxruntime->gliner->introdl==1.0) (10.0)\n",
      "Requirement already satisfied: pyreadline3 in c:\\users\\bagge\\miniforge-pypy3\\envs\\ds776env\\lib\\site-packages (from humanfriendly>=9.1->coloredlogs->onnxruntime->gliner->introdl==1.0) (3.5.4)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\bagge\\miniforge-pypy3\\envs\\ds776env\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy->introdl==1.0) (0.1.2)\n",
      "Building wheels for collected packages: introdl\n",
      "  Building wheel for introdl (pyproject.toml): started\n",
      "  Building wheel for introdl (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for introdl: filename=introdl-1.0-py3-none-any.whl size=46690 sha256=04667f3efcf3b8d1a4c3e7edc3884b460c3496c150a9e16083514387489faeba\n",
      "  Stored in directory: C:\\Users\\bagge\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-ykyii0_f\\wheels\\f5\\d5\\0f\\11f1d5af64d00defb23fa33cf51b2946a0899888d73571e687\n",
      "Successfully built introdl\n",
      "Installing collected packages: introdl\n",
      "  Attempting uninstall: introdl\n",
      "    Found existing installation: introdl 1.0\n",
      "    Uninstalling introdl-1.0:\n",
      "      Successfully uninstalled introdl-1.0\n",
      "Successfully installed introdl-1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install ../Course_Tools/introdl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running that cell, you should restart the kernel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applications of NER\n",
    "\n",
    "I wasn't really familiar with Named Entity Recognition before building this course.  However, after studying it for a bit I realize it's very similar to object detection and instance segmentation in computer vision where we're trying to \"tag\" individual objects in an image.  Now we're doing it with text.  Now that I know more about it I realize that NER is everywhere:\n",
    "\n",
    "- **Information Extraction from Text**\n",
    "  - Identify names of people, places, organizations, and dates in news articles, legal documents, and academic papers.\n",
    "\n",
    "- **Search and Question Answering**\n",
    "  - Improve retrieval and understanding by recognizing key entities in queries and documents (e.g., “Where was Barack Obama born?”).\n",
    "\n",
    "- **Social Media Monitoring**\n",
    "  - Detect mentions of public figures, brands, products, and locations in tweets, posts, and comments for sentiment analysis or moderation.\n",
    "\n",
    "- **Marketing and Trend Analysis**\n",
    "  - Track mentions of brands, competitors, or topics over time to identify emerging trends and customer interests.\n",
    "\n",
    "- **Content Recommendation**\n",
    "  - Extract entities (e.g., movies, products, places) from reviews and user posts to personalize content or advertisements.\n",
    "\n",
    "- **Customer Support Automation**\n",
    "  - Identify product names, user accounts, and issue types in support chats and emails to assist routing and auto-response systems.\n",
    "\n",
    "- **Financial and Business Intelligence**\n",
    "  - Extract company names, stock tickers, monetary values, and events from reports or articles to support decision-making.\n",
    "\n",
    "- **Medical and Clinical Text Analysis**\n",
    "  - Identify diseases, medications, and procedures in clinical notes for tasks like anonymization, coding, or record analysis.\n",
    "\n",
    "- **Legal and Compliance Monitoring**\n",
    "  - Recognize case names, organizations, and laws in legal documents to support research, auditing, or compliance checks.\n",
    "\n",
    "- **Resume and Job Post Parsing**\n",
    "  - Extract structured information such as skills, education, job titles, and companies to streamline recruitment processes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Chronology of State-of-the-Art Approaches for Named Entity Recognition (NER)**  \n",
    "\n",
    "The evolution of NER closely parallels the evolution of algorithms for text classification.  Early approaches were based on statistical models, then word embeddings and recurrent neural networks, before transformer architectures revolutionized the field since 2017.  \n",
    "\n",
    "Here's a timeline of some of the key advancements in NER:\n",
    "\n",
    "---\n",
    "\n",
    "### **Pre-2010s: Rule-Based Systems and Feature Engineering**  \n",
    "Early NER systems used **hand-crafted rules**, lookup lists (called **gazetteers**), and basic statistical models like **Hidden Markov Models (HMMs)** and **Conditional Random Fields (CRFs)**.  \n",
    "- **HMMs** modeled sequences by predicting the most likely tag (e.g., PERSON, LOCATION) for each word based on probabilities.\n",
    "- **CRFs** improved on HMMs by allowing more flexible features and considering the entire sequence when making predictions.\n",
    "\n",
    "These approaches required heavy manual feature engineering—like marking whether a word is capitalized, its part of speech, or its prefix/suffix.\n",
    "\n",
    "- **1990s–2000s**: Rule-based systems and statistical models dominated tasks like newswire NER.\n",
    "- **2003**: The CoNLL-2003 shared task standardized benchmarks and boosted interest in developing better NER models.\n",
    "\n",
    "---\n",
    "\n",
    "### **2010s: Word Embeddings and Neural Sequence Models**  \n",
    "NER systems improved significantly with the introduction of **word embeddings** like **Word2Vec** and **GloVe**, which represented words in continuous vector space based on context. These embeddings replaced sparse, manual features.\n",
    "\n",
    "- **2013–2015**: **Word2Vec** and **GloVe** made it easier to train neural models for NER.\n",
    "- **2015–2016**: **BiLSTM-CRF** architectures became popular—combining bidirectional LSTMs (which read sentences both forward and backward) with a CRF layer to model dependencies between entity tags.\n",
    "- **2015**: **spaCy** launched as a fast, practical NLP library with built-in NER support, making NER accessible for developers and educators.\n",
    "- **2016–2017**: Character-level embeddings and CNNs were added to improve robustness to spelling variation and rare words.\n",
    "\n",
    "---\n",
    "\n",
    "### **Late 2010s: Contextual Embeddings and Transformers**  \n",
    "NER took a major leap with **contextualized embeddings** from transformer-based models.\n",
    "\n",
    "- **2018**: **ELMo** introduced deep contextualized word representations that vary based on sentence context.\n",
    "- **2018**: **BERT** achieved state-of-the-art NER results by treating NER as a token classification problem using bidirectional transformer layers.\n",
    "- **2019**: **Flair** added character-level contextual embeddings to further improve performance on small or domain-specific datasets.\n",
    "\n",
    "---\n",
    "\n",
    "### **2020s: Prompting and Large Language Models (LLMs)**  \n",
    "Recent NER approaches increasingly use **LLMs** like **GPT-4**, **Claude**, and **Gemini**, which can extract entities using **natural language prompts** instead of token-level supervision.\n",
    "\n",
    "- **2020–2022**: Models like **RoBERTa**, **SpanBERT**, and **LUKE** fine-tuned transformer architectures for better span detection and entity-aware representations.\n",
    "- **spaCy** added support for transformer-based pipelines (e.g., `en_core_web_trf`) to make state-of-the-art NER accessible for production use.\n",
    "- **2023–2025**: Instruction-tuned models like **GLiNER** and general-purpose LLMs now handle **zero-shot or few-shot NER** using prompts like *\"Find all organizations and people in this sentence.\"* These models reduce the need for annotated datasets and allow rapid prototyping for new entity types.\n",
    "\n",
    "  While LLMs offer flexibility and ease of use, they may be less precise than traditional models. Hybrid systems often combine LLMs with structured postprocessing or constrained decoding to improve accuracy.\n",
    "\n",
    "---\n",
    "\n",
    "We'll focus on two of these tools.  We'll fine-tune a BERT model for NER and we'll look at some of the hurdles to using LLMs for NER.  You'll explore both of these topics further in the homework."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's our main import cell before we dive into the rest of the material."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODELS_PATH=C:\\Users\\bagge\\My Drive\\Python_Projects\\DS776_Develop_Project\\models\n",
      "DATA_PATH=C:\\Users\\bagge\\My Drive\\Python_Projects\\DS776_Develop_Project\\data\n",
      "TORCH_HOME=C:\\Users\\bagge\\My Drive\\Python_Projects\\DS776_Develop_Project\\downloads\n",
      "HF_HOME=C:\\Users\\bagge\\My Drive\\Python_Projects\\DS776_Develop_Project\\downloads\n",
      "HF_HUB_CACHE=C:\\Users\\bagge\\My Drive\\Python_Projects\\DS776_Develop_Project\\downloads\n",
      "Successfully logged in to Hugging Face Hub.\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import evaluate # Hugging Face library for evaluation\n",
    "from IPython.display import display\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import (pipeline, AutoTokenizer, AutoModelForTokenClassification, \n",
    "                          TrainingArguments, Trainer, DataCollatorForTokenClassification)\n",
    "\n",
    "# local packages\n",
    "from helpers import (display_ner_html, predict_ner_tags, format_ner_eval_results, \n",
    "                     match_entity_spans, json_extractor, spans_to_bio_tags) \n",
    "from introdl.utils import config_paths_keys, wrap_print_text\n",
    "from introdl.nlp import llm_generate, llm_configure, llm_list_models\n",
    "\n",
    "print = wrap_print_text(print, width=120) # you can specify the wrap width for all print statements\n",
    "\n",
    "paths = config_paths_keys() # import paths and keys\n",
    "MODELS_PATH = paths['MODELS_PATH']\n",
    "DATA_PATH = paths['DATA_PATH']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Dataset - CoNLL2003 for NER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our examples, well use the CoNLL2003 dataset.  It is one of the first widely used benchmarks for Named Entity Recognition (NER). It was introduced as part of the CoNLL-2003 shared task and contains annotated text for four entity types: **PER** (person), **LOC** (location), **ORG** (organization), and **MISC** (miscellaneous). The dataset is derived from Reuters news articles and is structured in the BIO format, making it a standard for evaluating NER models.\n",
    "\n",
    "Multiple versions of the dataset are available in Hugging Face.  We chose \"tomaarsen/conll2003\" because the NER tags are available in BIO format and because the list of possible labels is easy to extract."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Possible BIO tags ['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load CoNLL2003 dataset (this is not the most well known version of teh dataset, but it is the one that is easiest to load with the datasets library)\n",
    "dataset = load_dataset(\"tomaarsen/conll2003\")\n",
    "BIO_tags_list = dataset[\"train\"].features[\"ner_tags\"].feature.names\n",
    "print(\"Possible BIO tags\", BIO_tags_list)\n",
    "\n",
    "# delete the pos_tags and chunk_tags columns, as we don't need them\n",
    "for split in dataset.keys():\n",
    "    dataset[split] = dataset[split].remove_columns([\"pos_tags\", \"chunk_tags\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each sample in the dataset consists of a single sentence or headline.  Here is how it's stored:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '12', 'document_id': 1, 'sentence_id': 12, 'tokens': ['Only', 'France', 'and', 'Britain', 'backed', 'Fischler',\n",
      "\"'s\", 'proposal', '.'], 'ner_tags': [0, 5, 0, 5, 0, 1, 0, 0, 0]}\n"
     ]
    }
   ],
   "source": [
    "print(dataset[\"train\"][12])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the tokens are the words in sentence split up by whitespace and punctuation.  The ner_tags correspond to indices of the entity tags in our list.  The next bit of code also shows you how to get the BIO tags corresponding to each token:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tokens</th>\n",
       "      <th>NER Tags (IDs)</th>\n",
       "      <th>BIO Tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Only</td>\n",
       "      <td>0</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>France</td>\n",
       "      <td>5</td>\n",
       "      <td>B-LOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>and</td>\n",
       "      <td>0</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Britain</td>\n",
       "      <td>5</td>\n",
       "      <td>B-LOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>backed</td>\n",
       "      <td>0</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Fischler</td>\n",
       "      <td>1</td>\n",
       "      <td>B-PER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>'s</td>\n",
       "      <td>0</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>proposal</td>\n",
       "      <td>0</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>.</td>\n",
       "      <td>0</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Tokens  NER Tags (IDs) BIO Tags\n",
       "0      Only               0        O\n",
       "1    France               5    B-LOC\n",
       "2       and               0        O\n",
       "3   Britain               5    B-LOC\n",
       "4    backed               0        O\n",
       "5  Fischler               1    B-PER\n",
       "6        's               0        O\n",
       "7  proposal               0        O\n",
       "8         .               0        O"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Extract tokens and ner_tags from dataset[\"train\"][12]\n",
    "tokens = dataset[\"train\"][12][\"tokens\"]\n",
    "ner_tags = dataset[\"train\"][12][\"ner_tags\"]\n",
    "\n",
    "# Map ner_tags to their corresponding BIO tags using label_list\n",
    "bio_tags = [BIO_tags_list[tag] for tag in ner_tags]\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({\"Tokens\": tokens, \"NER Tags (IDs)\": ner_tags, \"BIO Tags\": bio_tags})\n",
    "\n",
    "# Display the DataFrame\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[spaCy is a whole ecosystem](https://spacy.io/) of tools for NLP that we won't really dive into much in this course, but it's worth a look if you're going to be working in this area.  They provide some great tools for visualization of tagged text.  We've use their package to make a little function called `display_ner_html` which takes lists of tokens, tag IDs, and the list of labels to produce HTML visualizations of the tags.  The function is in helper.py if you're curious.  Here's how we can use it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div style=\"\n",
       "        line-height: 1.6;\n",
       "        max-width: 120ch;\n",
       "        white-space: normal;\n",
       "        word-wrap: break-word;\n",
       "        font-family: 'Segoe UI', sans-serif;\n",
       "    \"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Only \n",
       "<mark class=\"entity\" style=\"background: #66c2a5; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    France\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">B-LOC</span>\n",
       "</mark>\n",
       " and \n",
       "<mark class=\"entity\" style=\"background: #66c2a5; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Britain\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">B-LOC</span>\n",
       "</mark>\n",
       " backed \n",
       "<mark class=\"entity\" style=\"background: #e78ac3; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Fischler\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">B-PER</span>\n",
       "</mark>\n",
       " 's proposal .</div></div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# tokens and ner_tags were defined in the previous code cell\n",
    "\n",
    "display_ner_html(tokens, ner_tags, BIO_tags_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div style=\"\n",
       "        line-height: 1.6;\n",
       "        max-width: 120ch;\n",
       "        white-space: normal;\n",
       "        word-wrap: break-word;\n",
       "        font-family: 'Segoe UI', sans-serif;\n",
       "    \"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #66c2a5; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Germany\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">B-LOC</span>\n",
       "</mark>\n",
       " 's representative to the \n",
       "<mark class=\"entity\" style=\"background: #8da0cb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    European Union\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">B-ORG</span>\n",
       "</mark>\n",
       " 's veterinary committee \n",
       "<mark class=\"entity\" style=\"background: #e78ac3; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Werner Zwingmann\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">B-PER</span>\n",
       "</mark>\n",
       " said on Wednesday consumers should buy sheepmeat from countries other than \n",
       "<mark class=\"entity\" style=\"background: #66c2a5; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Britain\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">B-LOC</span>\n",
       "</mark>\n",
       " until the scientific advice was clearer .</div></div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# here's another example\n",
    "display_ner_html(dataset[\"train\"][4][\"tokens\"], dataset[\"train\"][4][\"ner_tags\"], BIO_tags_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tune DistilBERT for ConNLL2003"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to fine-tune a BERT model so that it can provide similar tagging for new text.  First we'll load a model and its tokenizer.\n",
    "`distilbert-base-cased` is a smaller, faster, and lighter version of BERT that retains 97% of its language understanding capabilities while being 40% smaller. It is case-sensitive, meaning it distinguishes between \"Apple\" and \"apple\" which is useful for NER tasks. It was trained using masked language modeling on the same data as BERT, including the English Wikipedia and BookCorpus, but with a reduced architecture to improve efficiency. \n",
    "\n",
    "Note that we make use of `AutoModelForTokenClassification` which adds a classification head to the backbone the same way we did for transfer learning applications in image classification.  The backbone uses pretrained weights while the classification head weights are randomly initialized and learned during fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "# Load tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-cased\")\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"distilbert-base-cased\", num_labels=len(BIO_tags_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "One of the main issues we'll need to deal with is to map the BIO tags to the tokens that are produced by tokenizer that comes with our selected BERT model.  That tokenizer will break some of our words into subwords.  For those subwords we'll introduce an ID of -100 that tells the model not to predict tags for those tokens.\n",
    "\n",
    "The function, `tokenize_and_align_labels` below takes care of aligning the ID tags from the input sequence in the dataset to the output tokens in the tokenizer.  We've included some comments in the code if you want to study it, or you can use an AI to help you walk through the details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to align labels with tokens\n",
    "def tokenize_and_align_labels(examples):\n",
    "    # Tokenize the input text (list of tokens) while keeping track of word-to-token alignment\n",
    "    tokenized_inputs = tokenizer(examples[\"tokens\"], truncation=True, is_split_into_words=True)\n",
    "    \n",
    "    # Initialize a list to store the aligned labels for each example\n",
    "    labels = []\n",
    "    \n",
    "    # Iterate over each example in the batch\n",
    "    for i, label in enumerate(examples[\"ner_tags\"]):\n",
    "        # Get the word-to-token mapping for the current example\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "        \n",
    "        # Initialize variables to track the previous word index and the label IDs\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        \n",
    "        # Iterate over the word IDs corresponding to the tokens\n",
    "        for word_idx in word_ids:\n",
    "            if word_idx is None:\n",
    "                # If the token is a special token (e.g., [CLS], [SEP]), ignore it by assigning -100\n",
    "                label_ids.append(-100)\n",
    "            elif word_idx != previous_word_idx:\n",
    "                # If the token corresponds to a new word, assign the label of that word\n",
    "                label_ids.append(label[word_idx])\n",
    "            else:\n",
    "                # If the token is part of the same word (e.g., subword tokens), ignore it by assigning -100\n",
    "                label_ids.append(-100)\n",
    "            \n",
    "            # Update the previous word index to the current one\n",
    "            previous_word_idx = word_idx\n",
    "        \n",
    "        # Append the aligned label IDs for the current example\n",
    "        labels.append(label_ids)\n",
    "    \n",
    "    # Add the aligned labels to the tokenized inputs\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    \n",
    "    # Return the tokenized inputs with aligned labels\n",
    "    return tokenized_inputs\n",
    "\n",
    "# Tokenize datasets\n",
    "tokenized_datasets = dataset.map(tokenize_and_align_labels, batched=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell demonstrates how our tokenizer works the alignment function to get the tokenization expected by the model and to introduce IDs of -100 for each of the subwords introduced by the tokenizer.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before model tokenization:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div style=\"\n",
       "        line-height: 1.6;\n",
       "        max-width: 120ch;\n",
       "        white-space: normal;\n",
       "        word-wrap: break-word;\n",
       "        font-family: 'Segoe UI', sans-serif;\n",
       "    \"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">He said a proposal last month by \n",
       "<mark class=\"entity\" style=\"background: #8da0cb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    EU\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">B-ORG</span>\n",
       "</mark>\n",
       " Farm Commissioner \n",
       "<mark class=\"entity\" style=\"background: #e78ac3; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Franz Fischler\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">B-PER</span>\n",
       "</mark>\n",
       " to ban sheep brains , spleens and spinal cords from the human and animal food chains was a highly specific and precautionary move to protect human health .</div></div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After model tokenization:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div style=\"\n",
       "        line-height: 1.6;\n",
       "        max-width: 120ch;\n",
       "        white-space: normal;\n",
       "        word-wrap: break-word;\n",
       "        font-family: 'Segoe UI', sans-serif;\n",
       "    \"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #cccccc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    [CLS]\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">IGNORE</span>\n",
       "</mark>\n",
       " He said a proposal last month by \n",
       "<mark class=\"entity\" style=\"background: #8da0cb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    EU\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">B-ORG</span>\n",
       "</mark>\n",
       " Farm Commissioner \n",
       "<mark class=\"entity\" style=\"background: #e78ac3; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Franz Fi\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">B-PER</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #cccccc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    ##sch\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">IGNORE</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #cccccc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    ##ler\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">IGNORE</span>\n",
       "</mark>\n",
       " to ban sheep brains , s \n",
       "<mark class=\"entity\" style=\"background: #cccccc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    ##ple\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">IGNORE</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #cccccc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    ##ens\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">IGNORE</span>\n",
       "</mark>\n",
       " and spinal cord \n",
       "<mark class=\"entity\" style=\"background: #cccccc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    ##s\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">IGNORE</span>\n",
       "</mark>\n",
       " from the human and animal food chains was a highly specific and pre \n",
       "<mark class=\"entity\" style=\"background: #cccccc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    ##ca\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">IGNORE</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #cccccc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    ##ution\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">IGNORE</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #cccccc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    ##ary\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">IGNORE</span>\n",
       "</mark>\n",
       " move to protect human health . \n",
       "<mark class=\"entity\" style=\"background: #cccccc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    [SEP]\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">IGNORE</span>\n",
       "</mark>\n",
       "</div></div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get the example\n",
    "example = dataset[\"train\"][7]\n",
    "\n",
    "# Wrap in a batch of one for compatibility with tokenize_and_align_labels\n",
    "batch = {\"tokens\": [example[\"tokens\"]], \"ner_tags\": [example[\"ner_tags\"]]}\n",
    "\n",
    "# Apply the tokenization and alignment function\n",
    "tokenized = tokenize_and_align_labels(batch)\n",
    "\n",
    "# Extract and display results\n",
    "tokens = tokenizer.convert_ids_to_tokens(tokenized[\"input_ids\"][0])\n",
    "labels = tokenized[\"labels\"][0]\n",
    "\n",
    "print((\"Before model tokenization:\\n\"))\n",
    "display_ner_html(dataset[\"train\"][7][\"tokens\"], dataset[\"train\"][7][\"ner_tags\"], BIO_tags_list)\n",
    "print((\"\\nAfter model tokenization:\\n\"))\n",
    "display_ner_html(tokens, labels, BIO_tags_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that the tokenizer divided some of the original words into subwords which get assigned an ID of -100 to be ignored by the model.  During training those tokens are ignored by the loss function and the outputs corresponding to those tokens are ignored during model evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we fine-tune the model we define a custom metrics function that does two things:\n",
    "1. Uses the `seqeval` package to evaluate entire entity spans (e.g, e.g., `B-LOC`, `I-LOC`, etc. forming `\"New York\"`) instead of evaluating individual labels as we'd do with the scikit-learn metrics.\n",
    "2. Ignores the tokens with IDs of -100 for the evaluation metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load seqeval metric\n",
    "metric = evaluate.load(\"seqeval\")\n",
    "\n",
    "# Note if you have a different list of possible tags, you'll need to change the default value of label_list\n",
    "def compute_metrics(p, label_list=BIO_tags_list):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    true_predictions = [\n",
    "        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    return metric.compute(predictions=true_predictions, references=true_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the actual fine-tuning we use a similar setup to what we did for text classification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bagge\\miniforge-pypy3\\envs\\DS776env\\Lib\\site-packages\\transformers\\training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "C:\\Users\\bagge\\AppData\\Local\\Temp\\ipykernel_32992\\3846245178.py:21: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2634' max='2634' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2634/2634 01:22, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Loc</th>\n",
       "      <th>Misc</th>\n",
       "      <th>Org</th>\n",
       "      <th>Per</th>\n",
       "      <th>Overall Precision</th>\n",
       "      <th>Overall Recall</th>\n",
       "      <th>Overall F1</th>\n",
       "      <th>Overall Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.056200</td>\n",
       "      <td>0.057373</td>\n",
       "      <td>{'precision': 0.9320021586616298, 'recall': 0.9401197604790419, 'f1': 0.9360433604336044, 'number': 1837}</td>\n",
       "      <td>{'precision': 0.7926565874730022, 'recall': 0.7960954446854663, 'f1': 0.7943722943722944, 'number': 922}</td>\n",
       "      <td>{'precision': 0.8468531468531468, 'recall': 0.9030574198359433, 'f1': 0.8740526885600866, 'number': 1341}</td>\n",
       "      <td>{'precision': 0.9754846066134549, 'recall': 0.9288816503800217, 'f1': 0.9516129032258064, 'number': 1842}</td>\n",
       "      <td>0.902734</td>\n",
       "      <td>0.905924</td>\n",
       "      <td>0.904326</td>\n",
       "      <td>0.983860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.011700</td>\n",
       "      <td>0.047674</td>\n",
       "      <td>{'precision': 0.9544468546637744, 'recall': 0.9580838323353293, 'f1': 0.95626188535724, 'number': 1837}</td>\n",
       "      <td>{'precision': 0.83991462113127, 'recall': 0.8535791757049892, 'f1': 0.8466917697686928, 'number': 922}</td>\n",
       "      <td>{'precision': 0.8945022288261516, 'recall': 0.8978374347501864, 'f1': 0.8961667286937105, 'number': 1341}</td>\n",
       "      <td>{'precision': 0.9647314161692893, 'recall': 0.9652551574375678, 'f1': 0.9649932157394844, 'number': 1842}</td>\n",
       "      <td>0.926131</td>\n",
       "      <td>0.930495</td>\n",
       "      <td>0.928308</td>\n",
       "      <td>0.987851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.012400</td>\n",
       "      <td>0.045236</td>\n",
       "      <td>{'precision': 0.9591503267973857, 'recall': 0.9586281981491562, 'f1': 0.9588891913966784, 'number': 1837}</td>\n",
       "      <td>{'precision': 0.8459915611814346, 'recall': 0.8698481561822126, 'f1': 0.8577540106951872, 'number': 922}</td>\n",
       "      <td>{'precision': 0.9022222222222223, 'recall': 0.9082774049217002, 'f1': 0.9052396878483836, 'number': 1341}</td>\n",
       "      <td>{'precision': 0.965386695511087, 'recall': 0.9690553745928339, 'f1': 0.967217556217827, 'number': 1842}</td>\n",
       "      <td>0.930303</td>\n",
       "      <td>0.936722</td>\n",
       "      <td>0.933501</td>\n",
       "      <td>0.988688</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2634, training_loss=0.06490828401084506, metrics={'train_runtime': 82.5699, 'train_samples_per_second': 510.15, 'train_steps_per_second': 31.9, 'total_flos': 525319502290632.0, 'train_loss': 0.06490828401084506, 'epoch': 3.0})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir= MODELS_PATH / \"distilbert-ner\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    "    report_to=\"none\",\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "# Data collator\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer)\n",
    "\n",
    "# Trainer setup\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='216' max='216' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [216/216 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set evaluation results:\n",
      "{'eval_loss': 0.1198493242263794, 'eval_LOC': {'precision': 0.9148681055155875, 'recall': 0.9148681055155875, 'f1':\n",
      "0.9148681055155875, 'number': 1668}, 'eval_MISC': {'precision': 0.7110266159695817, 'recall': 0.7991452991452992, 'f1':\n",
      "0.7525150905432596, 'number': 702}, 'eval_ORG': {'precision': 0.8554710356933879, 'recall': 0.8801926550270921, 'f1':\n",
      "0.8676557863501483, 'number': 1661}, 'eval_PER': {'precision': 0.960551033187226, 'recall': 0.9486703772418058, 'f1':\n",
      "0.95457373988799, 'number': 1617}, 'eval_overall_precision': 0.8820058997050148, 'eval_overall_recall':\n",
      "0.8999645892351275, 'eval_overall_f1': 0.8908947506791691, 'eval_overall_accuracy': 0.9785291267362981, 'eval_runtime':\n",
      "1.7902, 'eval_samples_per_second': 1928.783, 'eval_steps_per_second': 120.654, 'epoch': 3.0}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Evaluate on test set\n",
    "results = trainer.evaluate(tokenized_datasets[\"test\"])\n",
    "print(\"\\nTest set evaluation results:\")\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's some ugly output!  Let's put it in a data frame with some formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Entity</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Number</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LOC</td>\n",
       "      <td>0.9149</td>\n",
       "      <td>0.9149</td>\n",
       "      <td>0.9149</td>\n",
       "      <td>1668.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MISC</td>\n",
       "      <td>0.7110</td>\n",
       "      <td>0.7991</td>\n",
       "      <td>0.7525</td>\n",
       "      <td>702.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ORG</td>\n",
       "      <td>0.8555</td>\n",
       "      <td>0.8802</td>\n",
       "      <td>0.8677</td>\n",
       "      <td>1661.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PER</td>\n",
       "      <td>0.9606</td>\n",
       "      <td>0.9487</td>\n",
       "      <td>0.9546</td>\n",
       "      <td>1617.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Overall</td>\n",
       "      <td>0.8820</td>\n",
       "      <td>0.9000</td>\n",
       "      <td>0.8909</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9785</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Entity  Precision  Recall      F1  Number  Accuracy\n",
       "0      LOC     0.9149  0.9149  0.9149  1668.0       NaN\n",
       "1     MISC     0.7110  0.7991  0.7525   702.0       NaN\n",
       "2      ORG     0.8555  0.8802  0.8677  1661.0       NaN\n",
       "3      PER     0.9606  0.9487  0.9546  1617.0       NaN\n",
       "4  Overall     0.8820  0.9000  0.8909     NaN    0.9785"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_results = format_ner_eval_results(results)\n",
    "display(df_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's better!  You can think of f1 as a balanced version of accuracy.  We can see that the model does a great job on identifying people and is also good at identifying locations and organizations.  It doesn't do quite as well as identifying miscellaneous entities (but I'm not sure what those are supposed to be either ...)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also use the model to do inference by making predictions on new text.  The function below is also included in the helpers.py file, but we include it here so you can study it and see how it works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_ner_tags(text, model, tokenizer):\n",
    "    \"\"\"\n",
    "    Tokenizes and predicts NER tags for the given text using a Hugging Face model.\n",
    "\n",
    "    Args:\n",
    "        text (str): Input sentence (e.g., \"Barack Obama was born in Hawaii\").\n",
    "        model: A Hugging Face token classification model (e.g., DistilBERT).\n",
    "        tokenizer: The tokenizer corresponding to the model.\n",
    "\n",
    "    Returns:\n",
    "        tokens (List[str]): Original word tokens from the input text.\n",
    "        predicted_tag_ids (List[int]): One predicted tag index per word (subwords/specials skipped).\n",
    "    \"\"\"\n",
    "\n",
    "    # Step 1: Split the input text into whitespace-separated words\n",
    "    words = text.split()\n",
    "\n",
    "    # Step 2: Tokenize the list of words and retain word alignment\n",
    "    inputs = tokenizer(words, return_tensors=\"pt\", is_split_into_words=True).to(model.device)\n",
    "\n",
    "    # Step 3: Get model predictions\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    # Step 4: Convert logits to predicted label indices\n",
    "    predictions = torch.argmax(outputs.logits, dim=2)[0].cpu().numpy()\n",
    "\n",
    "    # Step 5: Get word IDs for each token\n",
    "    word_ids = inputs.word_ids(batch_index=0)\n",
    "\n",
    "    # Step 6: Extract one prediction per word (first subword only)\n",
    "    predicted_tag_ids = []\n",
    "    seen_words = set()\n",
    "    for token_idx, word_idx in enumerate(word_ids):\n",
    "        if word_idx is not None and word_idx not in seen_words:\n",
    "            predicted_tag_ids.append(int(predictions[token_idx]))\n",
    "            seen_words.add(word_idx)\n",
    "        # skip subwords and special tokens\n",
    "\n",
    "    # Step 7: Return the original words and corresponding predicted tags\n",
    "    return words, predicted_tag_ids\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll apply it to some example text we copied from the internet (about GPT-4o's new image generation capability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['It’s', 'only', 'been', 'a', 'day', 'since', 'ChatGPT’s', 'new', 'AI', 'image', 'generator', 'went', 'live,', 'and',\n",
      "'social', 'media', 'feeds', 'are', 'already', 'flooded', 'with', 'AI-generated', 'memes', 'in', 'the', 'style', 'of',\n",
      "'Studio', 'Ghibli,', 'the', 'cult-favorite', 'Japanese', 'animation', 'studio', 'behind', 'blockbuster', 'films',\n",
      "'such', 'as', '“My', 'Neighbor', 'Totoro”', 'and', '“Spirited', 'Away.”', 'In', 'the', 'last', '24', 'hours,', 'we’ve',\n",
      "'seen', 'AI-generated', 'images', 'representing', 'Studio', 'Ghibli', 'versions', 'of', 'Elon', 'Musk,', '“The', 'Lord',\n",
      "'of', 'the', 'Rings“,', 'and', 'President', 'Donald', 'Trump.', 'OpenAI', 'CEO', 'Sam', 'Altman', 'even', 'seems', 'to',\n",
      "'have', 'made', 'his', 'new', 'profile', 'picture', 'a', 'Studio', 'Ghibli-style', 'image,', 'presumably', 'made',\n",
      "'with', 'GPT-4o’s', 'native', 'image', 'generator.', 'Users', 'seem', 'to', 'be', 'uploading', 'existing', 'images',\n",
      "'and', 'pictures', 'into', 'ChatGPT', 'and', 'asking', 'the', 'chatbot', 'to', 're-create', 'it', 'in', 'new',\n",
      "'styles.'] [0, 0, 0, 0, 0, 0, 3, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 3, 4, 0, 0, 7, 0, 0, 0, 0,\n",
      "0, 0, 0, 7, 8, 8, 0, 7, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 8, 0, 0, 1, 2, 7, 8, 8, 8, 8, 0, 0, 1, 2, 3, 0, 1, 2, 0, 0,\n",
      "0, 0, 0, 0, 0, 0, 0, 0, 7, 8, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "example_text = \"\"\"\n",
    "It’s only been a day since ChatGPT’s new AI image generator went live, and social media feeds are already flooded with AI-generated memes in the style of Studio Ghibli, the cult-favorite Japanese animation studio behind blockbuster films such as “My Neighbor Totoro” and “Spirited Away.”\n",
    "\n",
    "In the last 24 hours, we’ve seen AI-generated images representing Studio Ghibli versions of Elon Musk, “The Lord of the Rings“, and President Donald Trump. OpenAI CEO Sam Altman even seems to have made his new profile picture a Studio Ghibli-style image, presumably made with GPT-4o’s native image generator. Users seem to be uploading existing images and pictures into ChatGPT and asking the chatbot to re-create it in new styles.\n",
    "\"\"\"\n",
    "\n",
    "tokens, tags = predict_ner_tags(example_text, model, tokenizer)\n",
    "print(tokens,tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, the raw output is kind of difficult to interpret, but we can easily visualize it with `display_ner_html`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div style=\"\n",
       "        line-height: 1.6;\n",
       "        max-width: 120ch;\n",
       "        white-space: normal;\n",
       "        word-wrap: break-word;\n",
       "        font-family: 'Segoe UI', sans-serif;\n",
       "    \"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">It’s only been a day since \n",
       "<mark class=\"entity\" style=\"background: #8da0cb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    ChatGPT’s\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">B-ORG</span>\n",
       "</mark>\n",
       " new \n",
       "<mark class=\"entity\" style=\"background: #fc8d62; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    AI\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">B-MISC</span>\n",
       "</mark>\n",
       " image generator went live, and social media feeds are already flooded with \n",
       "<mark class=\"entity\" style=\"background: #fc8d62; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    AI-generated\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">B-MISC</span>\n",
       "</mark>\n",
       " memes in the style of \n",
       "<mark class=\"entity\" style=\"background: #8da0cb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Studio Ghibli,\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">B-ORG</span>\n",
       "</mark>\n",
       " the cult-favorite \n",
       "<mark class=\"entity\" style=\"background: #fc8d62; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Japanese\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">B-MISC</span>\n",
       "</mark>\n",
       " animation studio behind blockbuster films such as \n",
       "<mark class=\"entity\" style=\"background: #fc8d62; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    “My Neighbor Totoro”\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">B-MISC</span>\n",
       "</mark>\n",
       " and \n",
       "<mark class=\"entity\" style=\"background: #fc8d62; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    “Spirited Away.”\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">B-MISC</span>\n",
       "</mark>\n",
       " In the last 24 hours, we’ve seen AI-generated images representing \n",
       "<mark class=\"entity\" style=\"background: #fc8d62; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Studio Ghibli\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">B-MISC</span>\n",
       "</mark>\n",
       " versions of \n",
       "<mark class=\"entity\" style=\"background: #e78ac3; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Elon Musk,\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">B-PER</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #fc8d62; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    “The Lord of the Rings“,\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">B-MISC</span>\n",
       "</mark>\n",
       " and President \n",
       "<mark class=\"entity\" style=\"background: #e78ac3; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Donald Trump.\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">B-PER</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #8da0cb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    OpenAI\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">B-ORG</span>\n",
       "</mark>\n",
       " CEO \n",
       "<mark class=\"entity\" style=\"background: #e78ac3; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Sam Altman\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">B-PER</span>\n",
       "</mark>\n",
       " even seems to have made his new profile picture a \n",
       "<mark class=\"entity\" style=\"background: #fc8d62; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Studio Ghibli-style\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">B-MISC</span>\n",
       "</mark>\n",
       " image, presumably made with \n",
       "<mark class=\"entity\" style=\"background: #fc8d62; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    GPT-4o’s\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">B-MISC</span>\n",
       "</mark>\n",
       " native image generator. Users seem to be uploading existing images and pictures into \n",
       "<mark class=\"entity\" style=\"background: #8da0cb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    ChatGPT\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">B-ORG</span>\n",
       "</mark>\n",
       " and asking the chatbot to re-create it in new styles.</div></div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_ner_html(tokens, tags, BIO_tags_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That seems pretty amazing for entity recognition on text the model has never seen!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NER by Zero-Shot LLM Prompting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we'll explore using LLMs for NER.  LLMs can do this quite well, but there are some differences to be aware of though.  LLMs are naturally better at extracting spans (the relevant words for each identified entity) or structured output, not token-level labeling, because:\n",
    "\n",
    "* The process text holistically, not token-by-token.\n",
    "* There's no inherent token alignment.\n",
    "* They can hallucinate or skip tokens when generating lists.\n",
    "\n",
    "When we use an LLM to extract entities, we'll get lists of strings (also called spans in this context) for each entity type.  You must prompt carefully to get the LLM to return only exact matching strings for each entity type.  You also may need to explain, or give examples of, each entity type since the LLM can't learn these meanings from a corpus of labeled text.  Finally, to evaluate metrics without having token level classification you'll have to tokenize the identified strings and compare these to tokens from the text to identify matches, then compare the LLM predicted entity to the BIO tags for that entity.  It may help to use \"fuzzy\" or inexact matching since the LLM may adjust spellings in its identified strings.\n",
    "\n",
    "We'll use `llm_generate` as we've done previously.    Here's the list of models that are easy to use with `llm_generate`.  You can adjust the code below to use other models, or the Groq or Together.AI APIs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available models:\n",
      " llama-3p2-3B => HuggingFace: unsloth/Llama-3.2-3B-Instruct-unsloth-bnb-4bit\n",
      " llama-3p1-8B => HuggingFace: unsloth/Meta-Llama-3.1-8B-Instruct-bnb-4bit\n",
      " mistral-7B => HuggingFace: unsloth/mistral-7b-instruct-v0.3-bnb-4bit\n",
      " qwen-2p5-3B => HuggingFace: unsloth/Qwen2.5-3B-Instruct-bnb-4bit\n",
      " qwen-2p5-7B => HuggingFace: unsloth/Qwen2.5-7B-Instruct-bnb-4bit\n",
      " gemini-flash-lite => needs GEMINI_API_KEY\n",
      " gemini-flash => needs GEMINI_API_KEY\n",
      " gpt-4o => needs OPENAI_API_KEY\n",
      " gpt-4o-mini => needs OPENAI_API_KEY\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<zip at 0x19384c0d8c0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_list_models()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using an LLM for NER - The Basics\n",
    "\n",
    "We'll start by crafting a prompt and asking a local model to identify the CoNLL entities (PER, LOC, ORG, MISC) in the example text from the last section.  We're going to specify the entity types in the prompt and try to get the model to produce JSON ouput.  JSON is output that's been formatted like a Python dictionary.  Let's see what happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Loading model: unsloth/Meta-Llama-3.1-8B-Instruct-bnb-4bit (this may take a while)...\n",
      "🟢 Model unsloth/Meta-Llama-3.1-8B-Instruct-bnb-4bit loaded successfully.\n",
      "\n",
      "system\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 Jul 2024\n",
      "\n",
      "You are a helpful assistant for named entity recognition. You return entity spans in JSON.user\n",
      "\n",
      "Extract the following named entities from the text below, if they appear:\n",
      "- PER (Person)\n",
      "- ORG (Organization)\n",
      "- LOC (Location)\n",
      "- MISC (Miscellaneous)\n",
      "\n",
      "Only include named entities that are explicitly mentioned in the text — do not infer or guess.\n",
      "Return each entity **exactly as it appears in the text**, preserving casing and punctuation.\n",
      "\n",
      "Return the result as a JSON object in the format:\n",
      "{{\n",
      "  \"PER\": [...],\n",
      "  \"ORG\": [...],\n",
      "  \"LOC\": [...],\n",
      "  \"MISC\": [...]\n",
      "}}\n",
      "\n",
      "Return only the JSON object, nothing else.\n",
      "\n",
      "Text: It’s only been a day since ChatGPT’s new AI image generator went live, and social media feeds\n",
      "are already flooded with AI-generated memes in the style of Studio Ghibli, the cult-favorite\n",
      "Japanese animation studio behind blockbuster films such as “My Neighbor Totoro” and “Spirited Away.”\n",
      "\n",
      "In the last 24 hours, we’ve seen AI-generated images representing Studio Ghibli versions of Elon Musk,\n",
      "“The Lord of the Rings“, and President Donald Trump. OpenAI CEO Sam Altman even seems to have made his\n",
      "new profile picture a Studio Ghibli-style image, presumably made with GPT-4o’s native image generator.\n",
      "Users seem to be uploading existing images and pictures into ChatGPT and asking the chatbot to re-create\n",
      "it in new styles.\n",
      "The Entities JSON:assistant\n",
      "\n",
      "{\"PER\":[\"ChatGPT\", \"Elon Musk\", \"Sam Altman\", \"Donald Trump\"], \"ORG\":[\"Studio Ghibli\", \"OpenAI\"], \"LOC\":[], \"MISC\":[]}\n"
     ]
    }
   ],
   "source": [
    "llm_config = llm_configure(\"llama-3p1-8B\")\n",
    "\n",
    "# System instruction for the model\n",
    "system_instruct = \"You are a helpful assistant for named entity recognition. You return entity spans in JSON.\"\n",
    "\n",
    "# Example Text\n",
    "example_text = \"\"\"It’s only been a day since ChatGPT’s new AI image generator went live, and social media feeds \n",
    "are already flooded with AI-generated memes in the style of Studio Ghibli, the cult-favorite \n",
    "Japanese animation studio behind blockbuster films such as “My Neighbor Totoro” and “Spirited Away.”\n",
    "\n",
    "In the last 24 hours, we’ve seen AI-generated images representing Studio Ghibli versions of Elon Musk, \n",
    "“The Lord of the Rings“, and President Donald Trump. OpenAI CEO Sam Altman even seems to have made his \n",
    "new profile picture a Studio Ghibli-style image, presumably made with GPT-4o’s native image generator. \n",
    "Users seem to be uploading existing images and pictures into ChatGPT and asking the chatbot to re-create \n",
    "it in new styles.\"\"\"\n",
    "\n",
    "# Prompt for CoNLL2003-style entity extraction\n",
    "prompt = \"\"\"\n",
    "Extract the following named entities from the text below, if they appear:\n",
    "- PER (Person)\n",
    "- ORG (Organization)\n",
    "- LOC (Location)\n",
    "- MISC (Miscellaneous)\n",
    "\n",
    "Only include named entities that are explicitly mentioned in the text — do not infer or guess. \n",
    "Return each entity **exactly as it appears in the text**, preserving casing and punctuation.\n",
    "\n",
    "Return the result as a JSON object in the format:\n",
    "{{\n",
    "  \"PER\": [...],\n",
    "  \"ORG\": [...],\n",
    "  \"LOC\": [...],\n",
    "  \"MISC\": [...]\n",
    "}}\n",
    "\n",
    "Return only the JSON object, nothing else.\n",
    "\n",
    "Text: \"\"\" + example_text + \" \\nThe Entities JSON:\"\n",
    "\n",
    "response = llm_generate(llm_config, prompt, system_prompt = system_instruct, search_strategy='deterministic', remove_input_prompt=False)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note some things about the output:\n",
    "* `llm_generate` may fail to remove the prompt from the output. We forced it to keep it above by passing `remove_input_prompt = False`, but sometimes it fails because our cleaning algorithm doesn't correctly detect the input prompt in the output.  You should generally use `remove_input_prompt=True` or just leave it out since it defaults to True.\n",
    "* It mis-identified \"ChatGPT\" as a person.\n",
    "* It also returned the the span as \"ChatGPT\" instead of \"ChatGPT's\" as it occurs in the text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can fix the first issue by passing a `split_string` to `llm_generate` which will delete all the text up to the string.  We might be able to fix the second issue by providing examples (few-shot prompting) or more careful instructions to the LLM.  The third issue is why we'll need to use some inexact matching to match predicted spans with the input text.  \n",
    "\n",
    "First let's see how to get rid of that input prompt if necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"PER\":[\"ChatGPT\", \"Elon Musk\", \"Sam Altman\", \"Donald Trump\"], \"ORG\":[\"Studio Ghibli\", \"OpenAI\"], \"LOC\":[], \"MISC\":[]}\n"
     ]
    }
   ],
   "source": [
    "response = llm_generate(llm_config, prompt, system_prompt = system_instruct, \n",
    "                        search_strategy='deterministic', split_string='JSON:assistant')\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's better.  You may not need the split_string with some LLMs (particularly the API-based LLMs) or you may need to adjust it for different models.  \n",
    "\n",
    "Finally, the output is still a string, but we'd like to load that string as an actual dictionary. We can use `json.loads` to load the JSON formatted string as a dictionary in Python.  Some LLMs, like Gemini, will return the output with Markdown formatting like this:\n",
    "\n",
    "<pre>\n",
    "```json\n",
    "{\"PER\":[\"ChatGPT\", \"Elon Musk\", \"Sam Altman\", \"Donald Trump\"], \"ORG\":[\"Studio Ghibli\", \"OpenAI\"], \"LOC\":[], \"MISC\":[]}\n",
    "```\n",
    "</pre>\n",
    "\n",
    "So we may need to strip those extra characters away before using `json.loads`.  Here's a little function to do both of those things.  It's also in helpers.py:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def json_extractor(text):\n",
    "    # Extract the JSON object from the response\n",
    "    try:\n",
    "        text = text.strip(\"```json\").strip(\"```\").strip()\n",
    "        json_object = json.loads(text)\n",
    "    except json.JSONDecodeError:\n",
    "        json_object = {\"error\": \"Could not parse JSON\"}\n",
    "    return json_object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, to see it in action:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PER': ['ChatGPT', 'Elon Musk', 'Sam Altman', 'Donald Trump'],\n",
       " 'ORG': ['Studio Ghibli', 'OpenAI'],\n",
       " 'LOC': [],\n",
       " 'MISC': []}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entities = json_extractor(response)\n",
    "entities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the Predicted Entities in the Original Text\n",
    "\n",
    "Now we still need to figure out where each of the entities identified by the LLM appear in the text.  In NER we call this finding the span of each entity - it means identifing the position of each entity in the text.  We'll use two helper functions (both are in `helpers.py`) to help us do this:\n",
    "\n",
    "1. `clean_token` removes any punctuation from a token.\n",
    "2. `match_entity_spans` searches for each entity identified in our JSON output and returns a tuple with (entity_type, start_index, end_index) where the indices are the positions in the list of tokens.  We make use of fuzzy text matching as implemented in the `rapidfuzz` package.  You can learn more about fuzzy string matching and the package in the [RapidFuzz Documentation](https://rapidfuzz.github.io/RapidFuzz/).\n",
    "\n",
    "I encourage you to look at the `helpers.py` file to see how these functions are implemented and to study how they work.  We imported `match_entity_spans` near the beginning of this notebook.  \n",
    "\n",
    "To better understand what `match_entity_spans` does, we'll split our example text into a list of tokens, then search for the spans for each entity identified by our LLM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('PER', 6, 7),\n",
       " ('PER', 104, 105),\n",
       " ('PER', 59, 61),\n",
       " ('PER', 72, 74),\n",
       " ('PER', 68, 70),\n",
       " ('ORG', 27, 29),\n",
       " ('ORG', 55, 57),\n",
       " ('ORG', 70, 71)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = example_text.split()\n",
    "spans = match_entity_spans(entities, tokens)\n",
    "spans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have another helper function, `spans_to_bio_tags` that will convert these spans into BIO tag IDs corresonding to the list of tokens for visualization or evaluation.  Because we want the IDs for each tag, we need to pass our list of possible tags.  Below we generate the BIO tags IDs (one for each token in our example text), then visualize the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div style=\"\n",
       "        line-height: 1.6;\n",
       "        max-width: 120ch;\n",
       "        white-space: normal;\n",
       "        word-wrap: break-word;\n",
       "        font-family: 'Segoe UI', sans-serif;\n",
       "    \"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">It’s only been a day since \n",
       "<mark class=\"entity\" style=\"background: #e78ac3; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    ChatGPT’s\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">B-PER</span>\n",
       "</mark>\n",
       " new AI image generator went live, and social media feeds are already flooded with AI-generated memes in the style of \n",
       "<mark class=\"entity\" style=\"background: #8da0cb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Studio Ghibli,\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">B-ORG</span>\n",
       "</mark>\n",
       " the cult-favorite Japanese animation studio behind blockbuster films such as “My Neighbor Totoro” and “Spirited Away.” In the last 24 hours, we’ve seen AI-generated images representing \n",
       "<mark class=\"entity\" style=\"background: #8da0cb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Studio Ghibli\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">B-ORG</span>\n",
       "</mark>\n",
       " versions of \n",
       "<mark class=\"entity\" style=\"background: #e78ac3; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Elon Musk,\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">B-PER</span>\n",
       "</mark>\n",
       " “The Lord of the Rings“, and President \n",
       "<mark class=\"entity\" style=\"background: #e78ac3; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Donald Trump.\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">B-PER</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #8da0cb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    OpenAI\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">B-ORG</span>\n",
       "</mark>\n",
       " CEO \n",
       "<mark class=\"entity\" style=\"background: #e78ac3; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Sam Altman\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">B-PER</span>\n",
       "</mark>\n",
       " even seems to have made his new profile picture a Studio Ghibli-style image, presumably made with GPT-4o’s native image generator. Users seem to be uploading existing images and pictures into \n",
       "<mark class=\"entity\" style=\"background: #e78ac3; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    ChatGPT\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">B-PER</span>\n",
       "</mark>\n",
       " and asking the chatbot to re-create it in new styles.</div></div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tags = spans_to_bio_tags(tokens, spans, BIO_tags_list)\n",
    "display_ner_html(tokens, tags, BIO_tags_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the LLM is misidentifying \"ChatGPT\" as a person, that's still pretty impressive to be able to identify most of the entities in the text despite not being trained for that task!\n",
    "\n",
    "To summarize the steps we followed to generate BIO tags for an input text using an LLM:\n",
    "1.  Prompt and LLM to identify the desired entities in JSON format.\n",
    "2.  Strip the LLM output and load the JSON output.\n",
    "3.  Find the spans of the identified entities among tokens from the original text (the tokens are based on whitespace)\n",
    "4.  Use the spans to generate BIO tag ID for each input token. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automating the LLM NER Pipeline\n",
    "\n",
    "Here we build a function where we can input a nested list of tokens and get out a nested list of BIO tag IDs.  The inputs will be like this\n",
    "\n",
    "```python\n",
    "tokens = [ [\"It's\", \"only\", \"been\", \"a\", \"day\", \"since\", \"ChatGPT's\", \"new\", \"AI\"],\n",
    "           [\"In\", \"the\", \"last\", \"24\", \"hours\"] ]\n",
    "```\n",
    "\n",
    "The outputs will be \n",
    "```python\n",
    "tags = [ [0,0,0,0,0,0,1,0,0],[0,0,0,0,0]]\n",
    "```\n",
    "\n",
    "Where 0 is the ID for the 'O' tag, and 1 is the ID for the 'PER' tag.   \n",
    "\n",
    "The rest of the function relies on a prompt template where the input text formed from the tokens will be included to replace \"{text}\" in the template.  Other variables are similar to those we use in our previous text classification example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_ner_extractor(llm_config,\n",
    "                      tokens,\n",
    "                      system_prompt,\n",
    "                      prompt_template,\n",
    "                      labels_list,\n",
    "                      batch_size=1,\n",
    "                      estimate_cost=False,\n",
    "                      rate_limit=None,\n",
    "                      split_string=None,\n",
    "                      return_raw = False):\n",
    "    \"\"\"\n",
    "    Extract named entities using a Large Language Model (LLM) in zero-shot fashion.\n",
    "\n",
    "    Args:\n",
    "        llm_config (ModelConfig): Configuration for the LLM.\n",
    "        tokens (list of list of str): Nested list of tokens for each text.\n",
    "        system_prompt (str): System prompt guiding the LLM behavior.\n",
    "        prompt_template (str): Template to construct the user prompt for each text.\n",
    "        labels_list (list of str): List of possible BIO tags.\n",
    "        batch_size (int, optional): Batch size for local LLMs. Defaults to 1.\n",
    "        estimate_cost (bool, optional): Estimate LLM cost. Defaults to False.\n",
    "        rate_limit (int, optional): Throttle requests for API models. Defaults to None.\n",
    "        split_string (str, optional): String to split the LLM output. Defaults to None.\n",
    "        return_raw (bool, optional): Whether to return raw LLM outputs. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        list of list of int: Nested list of BIO tag IDs for each token in the input.\n",
    "    \"\"\"\n",
    "\n",
    "    texts = [\" \".join(token) for token in tokens]\n",
    "\n",
    "    user_prompts = [prompt_template.format(text=text) for text in texts]\n",
    "\n",
    "    raw_outputs = llm_generate(llm_config,\n",
    "                               user_prompts,\n",
    "                               system_prompt=system_prompt,\n",
    "                               search_strategy='deterministic',\n",
    "                               batch_size=batch_size,\n",
    "                               estimate_cost=estimate_cost,\n",
    "                               rate_limit=rate_limit,\n",
    "                               split_string=split_string)\n",
    "    \n",
    "    if return_raw:\n",
    "        return raw_outputs\n",
    "    else:\n",
    "        parsed_outputs = []\n",
    "        for output in raw_outputs:\n",
    "            try:\n",
    "                output = output.strip(\"```json\").strip(\"```\").strip()\n",
    "                parsed_outputs.append(json.loads(output))\n",
    "            except json.JSONDecodeError:\n",
    "                parsed_outputs.append({\"error\": \"Could not parse JSON\", \"raw_output\": output})\n",
    "\n",
    "        # identify the spans of the entities, but only if the JSON was successfully parsed \n",
    "        # if the JSON was not parsed we should get an empty list of spans for that text\n",
    "        spans = []\n",
    "        for entities, tokens in zip(parsed_outputs, tokens):\n",
    "            if \"error\" in entities:\n",
    "                spans.append([])\n",
    "            else:\n",
    "                spans.append(match_entity_spans(entities, tokens))\n",
    "        # now map the spans to BIO tags\n",
    "        tags = []\n",
    "        for token, span in zip(tokens, spans):\n",
    "            tags.append(spans_to_bio_tags(token, span, labels_list))\n",
    "\n",
    "        return tags\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: CRICKET - LEICESTERSHIRE TAKE OVER AT TOP AFTER INNINGS VICTORY .\n",
      "The Entities JSON:\n",
      "{'PER': [], 'ORG': ['LEICESTERSHIRE'], 'LOC': [], 'MISC': []}\n",
      "\n",
      "\n",
      "Text: LONDON 1996-08-30\n",
      "The Entities JSON:\n",
      "{'PER': [], 'ORG': [], 'LOC': ['LONDON'], 'MISC': []}\n",
      "\n",
      "\n",
      "Text: West Indian all-rounder Phil Simmons took four for 38 on Friday as Leicestershire beat Somerset by an innings and\n",
      "39 runs in two days to take over at the head of the county championship .\n",
      "The Entities JSON:\n",
      "{'PER': ['Phil Simmons'], 'ORG': ['Leicestershire', 'Somerset'], 'LOC': [], 'MISC': []}\n",
      "\n",
      "\n",
      "Text: Their stay on top , though , may be short-lived as title rivals Essex , Derbyshire and Surrey all closed in on\n",
      "victory while Kent made up for lost time in their rain-affected match against Nottinghamshire .\n",
      "The Entities JSON:\n",
      "{'PER': [], 'ORG': ['Essex', 'Derbyshire', 'Surrey', 'Kent', 'Nottinghamshire'], 'LOC': [], 'MISC': []}\n",
      "\n",
      "\n",
      "Text: After bowling Somerset out for 83 on the opening morning at Grace Road , Leicestershire extended their first\n",
      "innings by 94 runs before being bowled out for 296 with England discard Andy Caddick taking three for 83 .\n",
      "The Entities JSON:\n",
      "{'PER': ['Andy Caddick'], 'ORG': ['Somerset', 'Leicestershire', 'England'], 'LOC': ['Grace Road'], 'MISC': []}\n",
      "\n",
      "\n",
      "Text: Trailing by 213 , Somerset got a solid start to their second innings before Simmons stepped in to bundle them out\n",
      "for 174 .\n",
      "The Entities JSON:\n",
      "{'PER': ['Simmons'], 'ORG': ['Somerset'], 'LOC': [], 'MISC': []}\n",
      "\n",
      "\n",
      "Text: Essex , however , look certain to regain their top spot after Nasser Hussain and Peter Such gave them a firm grip\n",
      "on their match against Yorkshire at Headingley .\n",
      "The Entities JSON:\n",
      "{'PER': ['Nasser Hussain', 'Peter Such'], 'ORG': ['Essex', 'Yorkshire'], 'LOC': ['Headingley'], 'MISC': []}\n",
      "\n",
      "\n",
      "Text: Hussain , considered surplus to England 's one-day requirements , struck 158 , his first championship century of\n",
      "the season , as Essex reached 372 and took a first innings lead of 82 .\n",
      "The Entities JSON:\n",
      "{'PER': ['Hussain'], 'ORG': ['England', 'Essex'], 'LOC': [], 'MISC': []}\n",
      "\n",
      "\n",
      "Text: By the close Yorkshire had turned that into a 37-run advantage but off-spinner Such had scuttled their hopes ,\n",
      "taking four for 24 in 48 balls and leaving them hanging on 119 for five and praying for rain .\n",
      "The Entities JSON:\n",
      "{'PER': ['Such'], 'ORG': ['Yorkshire'], 'LOC': [], 'MISC': []}\n",
      "\n",
      "\n",
      "Text: At the Oval , Surrey captain Chris Lewis , another man dumped by England , continued to silence his critics as he\n",
      "followed his four for 45 on Thursday with 80 not out on Friday in the match against Warwickshire .\n",
      "The Entities JSON:\n",
      "{'PER': ['Chris Lewis'], 'ORG': ['Surrey', 'England', 'Warwickshire'], 'LOC': ['Oval'], 'MISC': []}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "llm_config = llm_configure('gemini-flash-lite')\n",
    "\n",
    "# Extract N examples from the validation split of CoNLL2003\n",
    "N = 100\n",
    "texts = [' '.join(tokens) for tokens in dataset[\"validation\"][\"tokens\"][:N]]\n",
    "\n",
    "# System instruction for the model\n",
    "system_instruct = \"You are a helpful assistant for named entity recognition. You return entity spans in JSON.\"\n",
    "\n",
    "# Prompt template adapted for CoNLL2003-style entity extraction\n",
    "prompt_template = \"\"\"\n",
    "Extract the following named entities from the text below, if they appear:\n",
    "- PER (Person)\n",
    "- ORG (Organization)\n",
    "- LOC (Location)\n",
    "- MISC (Miscellaneous)\n",
    "\n",
    "Only include named entities that are explicitly mentioned in the text — do not infer or guess. \n",
    "Return each entity **exactly as it appears in the text**, preserving casing and punctuation.\n",
    "\n",
    "Return the result as a JSON object in the format:\n",
    "{{\n",
    "  \"PER\": [...],\n",
    "  \"ORG\": [...],\n",
    "  \"LOC\": [...],\n",
    "  \"MISC\": [...]\n",
    "}}\n",
    "\n",
    "Return only the JSON object, nothing else.\n",
    "\n",
    "Text: {text}\n",
    "The Entities JSON:\n",
    "\"\"\"\n",
    "\n",
    "# Used to split off the assistant output from the JSON (if needed)\n",
    "split_string = \"JSON:assistant\"\n",
    "\n",
    "# Call the LLM-based NER extractor\n",
    "predictions = llm_ner_extractor(\n",
    "    llm_config,\n",
    "    texts,\n",
    "    system_instruct,\n",
    "    prompt_template,\n",
    "    batch_size=10,\n",
    "    estimate_cost=False,\n",
    "    rate_limit=None,\n",
    "    split_string=split_string\n",
    ")\n",
    "\n",
    "# Display the first few predictions for inspection\n",
    "for i, text in enumerate(texts[:10]):\n",
    "    print(f\"Text: {text}\")\n",
    "    print(\"The Entities JSON:\")\n",
    "    print(predictions[i])\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ACTOR': {'precision': np.float64(1.0), 'recall': np.float64(0.918918918918919), 'f1': np.float64(0.9577464788732395), 'number': np.int64(37)}, 'CHARACTER': {'precision': np.float64(0.5), 'recall': np.float64(0.16666666666666666), 'f1': np.float64(0.25), 'number': np.int64(6)}, 'DIRECTOR': {'precision': np.float64(0.9411764705882353), 'recall': np.float64(0.8421052631578947), 'f1': np.float64(0.8888888888888888), 'number': np.int64(19)}, 'GENRE': {'precision': np.float64(0.8235294117647058), 'recall': np.float64(0.42424242424242425), 'f1': np.float64(0.5599999999999999), 'number': np.int64(33)}, 'TITLE': {'precision': np.float64(0.625), 'recall': np.float64(0.47619047619047616), 'f1': np.float64(0.5405405405405405), 'number': np.int64(21)}, 'YEAR': {'precision': np.float64(1.0), 'recall': np.float64(0.7916666666666666), 'f1': np.float64(0.8837209302325582), 'number': np.int64(24)}, 'overall_precision': np.float64(0.8952380952380953), 'overall_recall': np.float64(0.6714285714285714), 'overall_f1': np.float64(0.7673469387755103), 'overall_accuracy': 0.9175027870680045}\n"
     ]
    }
   ],
   "source": [
    "from evaluate import load\n",
    "import re\n",
    "\n",
    "# ----------------------------------------\n",
    "# Helper function to normalize text\n",
    "# This removes punctuation and makes everything lowercase\n",
    "def normalize(text):\n",
    "    return re.sub(r'\\W+', '', text.lower())\n",
    "\n",
    "# ----------------------------------------\n",
    "# Convert span-level entity predictions (from LLM) into token-level IOB tags\n",
    "# Inputs:\n",
    "#   - tokens: list of words in the sentence\n",
    "#   - predicted_entities: dictionary from LLM output, e.g. {'TITLE': ['The Matrix']}\n",
    "# Output:\n",
    "#   - list of IOB tags aligned to the tokens, e.g. ['O', 'B-TITLE', 'I-TITLE', 'O']\n",
    "def span_to_token_tags(tokens, predicted_entities):\n",
    "    tags = [\"O\"] * len(tokens)  # Initialize all tokens with 'O' (outside any entity)\n",
    "    lowered_tokens = [normalize(tok) for tok in tokens]  # Normalize tokens for fuzzy matching\n",
    "\n",
    "    # Loop over each entity type (e.g. TITLE, ACTOR)\n",
    "    for entity_type, spans in predicted_entities.items():\n",
    "        for span in spans:\n",
    "            # Normalize each word in the entity span for matching\n",
    "            norm_span_tokens = [normalize(w) for w in str(span).split()]\n",
    "            span_len = len(norm_span_tokens)\n",
    "\n",
    "            # Slide over the token sequence and look for a matching span\n",
    "            for i in range(len(tokens) - span_len + 1):\n",
    "                # If tokens match the span, assign IOB tags\n",
    "                if lowered_tokens[i:i+span_len] == norm_span_tokens:\n",
    "                    tags[i] = f\"B-{entity_type}\"  # Beginning of entity\n",
    "                    for j in range(1, span_len):\n",
    "                        tags[i+j] = f\"I-{entity_type}\"  # Inside of entity\n",
    "                    break  # Stop searching after first match\n",
    "\n",
    "    return tags\n",
    "\n",
    "# ----------------------------------------\n",
    "# Load the seqeval metric (used for NER evaluation)\n",
    "seqeval = load(\"seqeval\")\n",
    "\n",
    "true_tags = []  # Ground-truth IOB tags for each example\n",
    "pred_tags = []  # LLM-predicted IOB tags for each example\n",
    "\n",
    "# Evaluate on all predictions\n",
    "N = len(predictions)\n",
    "\n",
    "for i in range(N):\n",
    "    example = dataset[\"valid\"][i]\n",
    "    tokens = example[\"tokens\"]\n",
    "    pred_entities = predictions[i]  # LLM output (JSON dict with spans)\n",
    "\n",
    "    # Convert integer tag IDs to IOB tag strings using label_list\n",
    "    true_iob = [label_list[tag_id] for tag_id in example[\"ner_tags\"]]\n",
    "\n",
    "    # Convert LLM's predicted spans to IOB tag sequence\n",
    "    pred_iob = span_to_token_tags(tokens, pred_entities)\n",
    "\n",
    "    # Add to the overall evaluation list\n",
    "    true_tags.append(true_iob)\n",
    "    pred_tags.append(pred_iob)\n",
    "\n",
    "# ----------------------------------------\n",
    "# Compute token-level precision, recall, F1 using seqeval\n",
    "results = seqeval.compute(predictions=pred_tags, references=true_tags)\n",
    "\n",
    "# Print the evaluation results\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ACTOR': {'precision': np.float64(1.0), 'recall': np.float64(0.918918918918919), 'f1': np.float64(0.9577464788732395), 'number': np.int64(37)}, 'CHARACTER': {'precision': np.float64(0.5), 'recall': np.float64(0.16666666666666666), 'f1': np.float64(0.25), 'number': np.int64(6)}, 'DIRECTOR': {'precision': np.float64(0.9411764705882353), 'recall': np.float64(0.8421052631578947), 'f1': np.float64(0.8888888888888888), 'number': np.int64(19)}, 'GENRE': {'precision': np.float64(0.8235294117647058), 'recall': np.float64(0.42424242424242425), 'f1': np.float64(0.5599999999999999), 'number': np.int64(33)}, 'TITLE': {'precision': np.float64(0.625), 'recall': np.float64(0.47619047619047616), 'f1': np.float64(0.5405405405405405), 'number': np.int64(21)}, 'YEAR': {'precision': np.float64(1.0), 'recall': np.float64(0.7916666666666666), 'f1': np.float64(0.8837209302325582), 'number': np.int64(24)}, 'overall_precision': np.float64(0.8952380952380953), 'overall_recall': np.float64(0.6714285714285714), 'overall_f1': np.float64(0.7673469387755103), 'overall_accuracy': 0.9175027870680045}\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "from rapidfuzz import fuzz\n",
    "\n",
    "def robust_normalize(text):\n",
    "    # Lowercase and remove punctuation only from the beginning and end.\n",
    "    return text.lower().strip(string.punctuation)\n",
    "\n",
    "def improved_span_to_token_tags_fuzzy_adjusted(tokens, predicted_entities, threshold=90):\n",
    "    \"\"\"\n",
    "    Convert span-level entity predictions into token-level IOB tags using fuzzy matching\n",
    "    and additional adjustments to handle trailing \"s\" issues.\n",
    "    \n",
    "    Args:\n",
    "        tokens (list of str): List of tokens in the sentence.\n",
    "        predicted_entities (dict): Dictionary mapping entity types to a list of span strings.\n",
    "        threshold (int): Fuzzy matching threshold (0-100). Default is 90.\n",
    "    \n",
    "    Returns:\n",
    "        list of str: IOB tags aligned with the tokens.\n",
    "    \"\"\"\n",
    "    tags = [\"O\"] * len(tokens)\n",
    "    lowered_tokens = [robust_normalize(tok) for tok in tokens]\n",
    "    \n",
    "    # Process each entity type (e.g., 'TITLE', 'ACTOR', etc.)\n",
    "    for entity_type, spans in predicted_entities.items():\n",
    "        for span in spans:\n",
    "            norm_span_tokens = [robust_normalize(w) for w in str(span).split()]\n",
    "            span_len = len(norm_span_tokens)\n",
    "            span_str = \" \".join(norm_span_tokens)\n",
    "            found_any = False\n",
    "            \n",
    "            # Slide over token windows of the same length as the span\n",
    "            for i in range(len(tokens) - span_len + 1):\n",
    "                window_tokens = lowered_tokens[i:i+span_len]\n",
    "                window_str = \" \".join(window_tokens)\n",
    "                \n",
    "                # Compute the base fuzzy matching score.\n",
    "                score = fuzz.ratio(span_str, window_str)\n",
    "                scores = [score]\n",
    "                \n",
    "                # Check alternative: if window ends with an \"s\", try removing it.\n",
    "                if window_str.endswith(\"s\"):\n",
    "                    alt_window = window_str[:-1]\n",
    "                    scores.append(fuzz.ratio(span_str, alt_window))\n",
    "                \n",
    "                # Check alternative: if span ends with an \"s\", try removing it.\n",
    "                if span_str.endswith(\"s\"):\n",
    "                    alt_span = span_str[:-1]\n",
    "                    scores.append(fuzz.ratio(alt_span, window_str))\n",
    "                \n",
    "                # Check alternative: if both end with an \"s\", remove from both.\n",
    "                if window_str.endswith(\"s\") and span_str.endswith(\"s\"):\n",
    "                    alt_window = window_str[:-1]\n",
    "                    alt_span = span_str[:-1]\n",
    "                    scores.append(fuzz.ratio(alt_span, alt_window))\n",
    "                \n",
    "                max_score = max(scores)\n",
    "                \n",
    "                if max_score >= threshold:\n",
    "                    tags[i] = f\"B-{entity_type}\"\n",
    "                    for j in range(1, span_len):\n",
    "                        tags[i+j] = f\"I-{entity_type}\"\n",
    "                    found_any = True\n",
    "                    # Continue looping to allow multiple occurrences\n",
    "            \n",
    "            if not found_any:\n",
    "                print(f\"Warning: Could not align span '{span}' for entity type '{entity_type}' in tokens: {tokens}\")\n",
    "    \n",
    "    return tags\n",
    "\n",
    "\n",
    "def evaluate_ner_predictions(dataset, predictions, label_list):\n",
    "    seqeval = load(\"seqeval\")\n",
    "    true_tags = []\n",
    "    pred_tags = []\n",
    "\n",
    "    for example, pred_entity_dict in zip(dataset, predictions):\n",
    "        tokens = example[\"tokens\"]\n",
    "        true_iob = [label_list[i] for i in example[\"ner_tags\"]]\n",
    "        pred_iob = span_to_token_tags(tokens, pred_entity_dict)\n",
    "\n",
    "        true_tags.append(true_iob)\n",
    "        pred_tags.append(pred_iob)\n",
    "\n",
    "    return seqeval.compute(predictions=pred_tags, references=true_tags)\n",
    "\n",
    "results = evaluate_ner_predictions(dataset[\"valid\"].select(range(N)), predictions, label_list)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zero-Shot NER with GliNER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d59f1633a6744e2bcfdea9423dfd0ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bagge\\miniforge-pypy3\\envs\\DS776env\\Lib\\site-packages\\transformers\\convert_slow_tokenizer.py:561: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"HF_HUB_DISABLE_SYMLINKS_WINDOWS\"] = \"1\"\n",
    "\n",
    "from gliner import GLiNER\n",
    "\n",
    "# Load the GLiNER model (you can also try gliner_medium-v2.1 or gliner_large-v2.1)\n",
    "model = GLiNER.from_pretrained(\"urchade/gliner_medium-v2.1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define your NER schema — use Title Case or lower case (recommended by GLiNER authors)\n",
    "labels = [\"Actor\", \"Character\", \"Director\", \"Genre\", \"Title\", \"Year\"]\n",
    "\n",
    "# Sample input texts (you can also loop over your dataset)\n",
    "N = 100\n",
    "texts = [' '.join(tokens) for tokens in dataset[\"valid\"][\"tokens\"][0:N] ]\n",
    "gliner_raw = model.batch_predict_entities(texts, labels)\n",
    "gliner_predictions = gliner_to_entity_dicts(gliner_raw)\n",
    "gliner_results = evaluate_ner_predictions(dataset[\"valid\"], gliner_predictions, label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ACTOR': {'precision': np.float64(0.8157894736842105),\n",
       "  'recall': np.float64(0.8378378378378378),\n",
       "  'f1': np.float64(0.8266666666666665),\n",
       "  'number': np.int64(37)},\n",
       " 'CHARACTER': {'precision': np.float64(0.2),\n",
       "  'recall': np.float64(0.5),\n",
       "  'f1': np.float64(0.28571428571428575),\n",
       "  'number': np.int64(6)},\n",
       " 'DIRECTOR': {'precision': np.float64(0.6666666666666666),\n",
       "  'recall': np.float64(0.7368421052631579),\n",
       "  'f1': np.float64(0.7),\n",
       "  'number': np.int64(19)},\n",
       " 'GENRE': {'precision': np.float64(0.56),\n",
       "  'recall': np.float64(0.42424242424242425),\n",
       "  'f1': np.float64(0.4827586206896552),\n",
       "  'number': np.int64(33)},\n",
       " 'TITLE': {'precision': np.float64(1.0),\n",
       "  'recall': np.float64(0.23809523809523808),\n",
       "  'f1': np.float64(0.3846153846153846),\n",
       "  'number': np.int64(21)},\n",
       " 'YEAR': {'precision': np.float64(0.8695652173913043),\n",
       "  'recall': np.float64(0.8333333333333334),\n",
       "  'f1': np.float64(0.851063829787234),\n",
       "  'number': np.int64(24)},\n",
       " 'overall_precision': np.float64(0.6850393700787402),\n",
       " 'overall_recall': np.float64(0.6214285714285714),\n",
       " 'overall_f1': np.float64(0.6516853932584269),\n",
       " 'overall_accuracy': 0.8561872909698997}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gliner_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50ff5207a5b24b0483202eddbd043275",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bagge\\miniforge-pypy3\\envs\\DS776env\\Lib\\site-packages\\transformers\\convert_slow_tokenizer.py:561: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from gliner import GLiNER, GLiNERConfig\n",
    "from gliner.training import Trainer, TrainingArguments\n",
    "from gliner.data_processing.collator import DataCollator\n",
    "from gliner.data_processing import WordsSplitter, GLiNERDataset\n",
    "from transformers import AutoTokenizer\n",
    "from datasets import DatasetDict\n",
    "import re\n",
    "\n",
    "# --------------------------\n",
    "# 1. Set up model + config\n",
    "# --------------------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_id = \"urchade/gliner_small\"\n",
    "model = GLiNER.from_pretrained(model_id)\n",
    "tokenizer = model.data_processor.transformer_tokenizer\n",
    "config = model.config\n",
    "words_splitter = WordsSplitter()\n",
    "\n",
    "dataset = load_dataset(\"hobbes99/mit-movie-ner-simplified\")\n",
    "label_list = dataset[\"train\"].features[\"ner_tags\"].feature.names\n",
    "\n",
    "# --------------------------\n",
    "# 2. Extract entity types\n",
    "# --------------------------\n",
    "entity_types = sorted(set(label[2:] for label in label_list if label != \"O\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_iob_to_gliner_format(example, label_list):\n",
    "    tokens = example[\"tokens\"]\n",
    "    tags = example[\"ner_tags\"]\n",
    "    \n",
    "    spans = []\n",
    "    i = 0\n",
    "    while i < len(tags):\n",
    "        tag = tags[i]\n",
    "        if tag == 0:  # \"O\"\n",
    "            i += 1\n",
    "            continue\n",
    "        label = label_list[tag]\n",
    "        if label.startswith(\"B-\"):\n",
    "            label_name = label[2:]\n",
    "            start = i\n",
    "            end = i\n",
    "            i += 1\n",
    "            while i < len(tags) and label_list[tags[i]] == f\"I-{label_name}\":\n",
    "                end = i\n",
    "                i += 1\n",
    "            spans.append([start, end, label_name])\n",
    "        else:\n",
    "            i += 1  # skip stray I- just in case\n",
    "\n",
    "    return {\n",
    "        \"tokenized_text\": tokens,\n",
    "        \"ner\": spans\n",
    "    }\n",
    "\n",
    "# Convert Hugging Face datasets to plain Python lists of dictionaries\n",
    "train_dataset = [\n",
    "    convert_iob_to_gliner_format(example, label_list)\n",
    "    for example in dataset[\"train\"]\n",
    "]\n",
    "\n",
    "valid_dataset = [\n",
    "    convert_iob_to_gliner_format(example, label_list)\n",
    "    for example in dataset[\"valid\"]\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d267198d52643a18144235585e2f7f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3645' max='3645' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3645/3645 09:33, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>2.888200</td>\n",
       "      <td>8.950000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.020400</td>\n",
       "      <td>7.190355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.883800</td>\n",
       "      <td>5.591519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.893100</td>\n",
       "      <td>4.774380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.888200</td>\n",
       "      <td>4.225507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.801500</td>\n",
       "      <td>4.288225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.817800</td>\n",
       "      <td>3.958858</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3645, training_loss=1.150873778124732, metrics={'train_runtime': 573.9006, 'train_samples_per_second': 50.81, 'train_steps_per_second': 6.351, 'total_flos': 0.0, 'train_loss': 1.150873778124732, 'epoch': 3.0})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from gliner import GLiNER, GLiNERConfig\n",
    "from gliner.training import Trainer, TrainingArguments\n",
    "from gliner.data_processing.collator import DataCollator\n",
    "from gliner.data_processing import WordsSplitter\n",
    "import torch\n",
    "\n",
    "# 1. Device and Model Setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_id = \"urchade/gliner_small\"\n",
    "model = GLiNER.from_pretrained(model_id)\n",
    "tokenizer = model.data_processor.transformer_tokenizer\n",
    "config = model.config\n",
    "words_splitter = WordsSplitter()\n",
    "\n",
    "# 2. Data Collator (for tokenization and batching)\n",
    "data_collator = DataCollator(\n",
    "    config=config,\n",
    "    tokenizer=tokenizer,\n",
    "    words_splitter=words_splitter,\n",
    "    prepare_labels=True\n",
    ")\n",
    "\n",
    "# 3. Epoch Calculation\n",
    "batch_size = 8\n",
    "num_steps = 500\n",
    "num_epochs = max(3, num_steps // max(1, len(train_dataset) // batch_size))\n",
    "\n",
    "# 4. Training Arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"gliner-movies\",\n",
    "    learning_rate=5e-6,\n",
    "    weight_decay=0.01,\n",
    "    others_lr=1e-5,\n",
    "    others_weight_decay=0.01,\n",
    "    lr_scheduler_type=\"linear\",\n",
    "    warmup_ratio=0.1,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    focal_loss_alpha=0.75,\n",
    "    focal_loss_gamma=2,\n",
    "    num_train_epochs=num_epochs,\n",
    "    eval_strategy=\"steps\",  # updated from deprecated evaluation_strategy\n",
    "    save_steps=100,\n",
    "    save_total_limit=2,\n",
    "    dataloader_num_workers=0,\n",
    "    use_cpu=not torch.cuda.is_available(),\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "# 5. Trainer Initialization (removed deprecated tokenizer)\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=valid_dataset,\n",
    "    data_collator=data_collator,\n",
    "    # no tokenizer needed anymore\n",
    ")\n",
    "\n",
    "# 6. Train\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def gliner_to_entity_dicts(gliner_output):\n",
    "    \"\"\"\n",
    "    Convert GLiNER's output format (list of {'text', 'label'}) per sample\n",
    "    into a dict of label -> list of strings for each example.\n",
    "    \"\"\"\n",
    "    all_entity_dicts = []\n",
    "    for entities in gliner_output:\n",
    "        ent_dict = defaultdict(list)\n",
    "        for e in entities:\n",
    "            ent_dict[e[\"label\"]].append(e[\"text\"])\n",
    "        all_entity_dicts.append(dict(ent_dict))\n",
    "    return all_entity_dicts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea37c8056b0c471e99308bd795606865",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bagge\\miniforge-pypy3\\envs\\DS776env\\Lib\\site-packages\\transformers\\convert_slow_tokenizer.py:561: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ACTOR': {'f1': np.float64(0.8641975308641975),\n",
      "           'number': np.int64(37),\n",
      "           'precision': np.float64(0.7954545454545454),\n",
      "           'recall': np.float64(0.9459459459459459)},\n",
      " 'CHARACTER': {'f1': np.float64(0.3157894736842105),\n",
      "               'number': np.int64(6),\n",
      "               'precision': np.float64(0.23076923076923078),\n",
      "               'recall': np.float64(0.5)},\n",
      " 'DIRECTOR': {'f1': np.float64(0.7142857142857143),\n",
      "              'number': np.int64(19),\n",
      "              'precision': np.float64(0.6521739130434783),\n",
      "              'recall': np.float64(0.7894736842105263)},\n",
      " 'GENRE': {'f1': np.float64(0.7222222222222221),\n",
      "           'number': np.int64(33),\n",
      "           'precision': np.float64(0.6666666666666666),\n",
      "           'recall': np.float64(0.7878787878787878)},\n",
      " 'TITLE': {'f1': np.float64(0.5500000000000002),\n",
      "           'number': np.int64(21),\n",
      "           'precision': np.float64(0.5789473684210527),\n",
      "           'recall': np.float64(0.5238095238095238)},\n",
      " 'YEAR': {'f1': np.float64(0.8461538461538461),\n",
      "          'number': np.int64(24),\n",
      "          'precision': np.float64(0.7857142857142857),\n",
      "          'recall': np.float64(0.9166666666666666)},\n",
      " 'overall_accuracy': 0.8907469342251951,\n",
      " 'overall_f1': np.float64(0.7320261437908497),\n",
      " 'overall_precision': np.float64(0.6746987951807228),\n",
      " 'overall_recall': np.float64(0.8)}\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from gliner import GLiNER\n",
    "\n",
    "# 1. Load fine-tuned model WITHOUT trying to load tokenizer from disk\n",
    "model_path = Path(\"gliner-movies/checkpoint-3645\")\n",
    "model = GLiNER.from_pretrained(str(model_path), load_tokenizer=False)\n",
    "\n",
    "# 2. Reuse the tokenizer from the original base model\n",
    "# This must match the one used during training\n",
    "base_model_id = \"urchade/gliner_small\"\n",
    "base_model = GLiNER.from_pretrained(base_model_id)\n",
    "model.data_processor.transformer_tokenizer = base_model.data_processor.transformer_tokenizer\n",
    "\n",
    "# 3. Reuse the words splitter too (optional, but best for consistency)\n",
    "model.data_processor.words_splitter = base_model.data_processor.words_splitter\n",
    "\n",
    "# 4. Define labels from your original `label_list`\n",
    "labels = sorted(list(set(label[2:] for label in label_list if label != \"O\")))\n",
    "\n",
    "# 5. Prepare input texts\n",
    "N = 100\n",
    "texts = [' '.join(tokens) for tokens in dataset[\"valid\"][\"tokens\"][:N]]\n",
    "\n",
    "# 6. Predict with batch_predict_entities\n",
    "gliner_raw = model.batch_predict_entities(texts, labels)\n",
    "\n",
    "# 7. Convert to standard format for evaluation\n",
    "gliner_predictions = gliner_to_entity_dicts(gliner_raw)\n",
    "\n",
    "# 8. Evaluate\n",
    "from datasets import Dataset\n",
    "\n",
    "# Convert sliced subset to a proper Dataset object\n",
    "valid_subset = Dataset.from_dict(dataset[\"valid\"][:N])\n",
    "\n",
    "gliner_results = evaluate_ner_predictions(valid_subset, gliner_predictions, label_list)\n",
    "\n",
    "\n",
    "# Optional: print results\n",
    "from pprint import pprint\n",
    "pprint(gliner_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'start': 17, 'end': 29, 'label': 'ACTOR'}]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gliner_predictions[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### 6. **Run Zero-Shot LLM Prompting (e.g., GPT-4 or Claude)**\n",
    "\n",
    "```python\n",
    "import openai\n",
    "\n",
    "def ner_with_gpt(text, system_prompt=None):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt or \"You are an assistant that extracts named entities.\"},\n",
    "        {\"role\": \"user\", \"content\": f\"Extract all named entities (actor, character, director, genre, title) from the following sentence:\\n\\n{text}\"}\n",
    "    ]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-4\",  # Or \"gpt-3.5-turbo\"\n",
    "        messages=messages,\n",
    "        temperature=0,\n",
    "    )\n",
    "    return response['choices'][0]['message']['content']\n",
    "```\n",
    "\n",
    "Test it on a few examples and show extracted entities. Let students compare accuracy/coverage with fine-tuned output.\n",
    "\n",
    "---\n",
    "\n",
    "### 7. **Run GliNER (Zero/Few-shot)**\n",
    "\n",
    "```python\n",
    "from gliner import GLiNER\n",
    "\n",
    "gliner_model = GLiNER.from_pretrained(\"urchade/gliner_index\")\n",
    "labels = [\"actor\", \"character\", \"director\", \"genre\", \"title\"]\n",
    "\n",
    "gliner_model.predict(\"The film was directed by Christopher Nolan and stars Christian Bale.\", labels)\n",
    "```\n",
    "\n",
    "Let students vary the label set or add new entity types.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## 📌 Add Step: 7. Fine-Tune GLiNER\n",
    "\n",
    "GLiNER expects training data in a specific format:\n",
    "```python\n",
    "{\n",
    "    \"text\": \"A movie description\",\n",
    "    \"entities\": [{\"label\": \"director\", \"text\": \"Quentin Tarantino\"}, ...]\n",
    "}\n",
    "```\n",
    "\n",
    "### 🔹 Prepare MIT Movie Data for GLiNER Fine-Tuning\n",
    "\n",
    "```python\n",
    "from datasets import DatasetDict\n",
    "\n",
    "# Map ID to label name\n",
    "label_names = dataset[\"train\"].features[\"ner_tags\"].feature.names\n",
    "\n",
    "def convert_to_gliner_format(example):\n",
    "    tokens = example[\"tokens\"]\n",
    "    tags = example[\"ner_tags\"]\n",
    "    text = \" \".join(tokens)\n",
    "    entities = []\n",
    "    current_entity = []\n",
    "    current_label = None\n",
    "\n",
    "    for token, tag in zip(tokens, tags):\n",
    "        tag_name = label_names[tag]\n",
    "        if tag_name.startswith(\"B-\"):\n",
    "            if current_entity:\n",
    "                entities.append({\"label\": current_label, \"text\": \" \".join(current_entity)})\n",
    "            current_label = tag_name[2:]\n",
    "            current_entity = [token]\n",
    "        elif tag_name.startswith(\"I-\") and current_label:\n",
    "            current_entity.append(token)\n",
    "        else:\n",
    "            if current_entity:\n",
    "                entities.append({\"label\": current_label, \"text\": \" \".join(current_entity)})\n",
    "            current_entity = []\n",
    "            current_label = None\n",
    "\n",
    "    if current_entity:\n",
    "        entities.append({\"label\": current_label, \"text\": \" \".join(current_entity)})\n",
    "\n",
    "    return {\"text\": text, \"entities\": entities}\n",
    "\n",
    "gliner_train = dataset[\"train\"].map(convert_to_gliner_format)\n",
    "gliner_test = dataset[\"test\"].map(convert_to_gliner_format)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 Fine-Tune GLiNER\n",
    "\n",
    "```python\n",
    "from gliner import GLiNERTrainer\n",
    "\n",
    "gliner_model_ft = GLiNER.from_pretrained(\"urchade/gliner_index\")\n",
    "\n",
    "trainer = GLiNERTrainer(\n",
    "    model=gliner_model_ft,\n",
    "    train_data=gliner_train,\n",
    "    eval_data=gliner_test,\n",
    "    output_dir=\"./gliner_movie_ft\",\n",
    "    batch_size=16,\n",
    "    lr=5e-5,\n",
    "    num_epochs=3,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 Evaluate Fine-Tuned GLiNER\n",
    "\n",
    "```python\n",
    "results = trainer.evaluate()\n",
    "print(results)\n",
    "```\n",
    "\n",
    "Or test on custom text:\n",
    "\n",
    "```python\n",
    "gliner_model_ft.predict(\"The movie was directed by James Cameron and stars Sigourney Weaver.\", labels)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 📊 Step 8: Compare All Methods\n",
    "\n",
    "Update your comparison table:\n",
    "\n",
    "| Sentence | Fine-Tuned DistilBERT | GPT-4 | GliNER Zero-shot | GliNER Fine-tuned |\n",
    "|----------|------------------------|-------|-------------------|-------------------|\n",
    "| ...      | ...                    | ...   | ...               | ...               |\n",
    "\n",
    "Encourage students to analyze:\n",
    "- Which method catches more entities?\n",
    "- Which is more accurate?\n",
    "- How does GliNER behave with new/changed label sets?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4950ae558a434a65a4463ee34b574223",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bagge\\miniforge-pypy3\\envs\\DS776env\\Lib\\site-packages\\huggingface_hub\\file_download.py:142: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\bagge\\My Drive\\Python_Projects\\DS776_Develop_Project\\downloads\\hub\\models--bert-base-cased. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e492bdba03eb430b9935de99fcb4174c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70e3854cdb2348418832c4b04f13d246",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a46c04fc3559486eb2ac95cec6878b4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d32da7220ce6472d85374838c78a2a04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bagge\\miniforge-pypy3\\envs\\DS776env\\Lib\\site-packages\\huggingface_hub\\file_download.py:142: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\bagge\\My Drive\\Python_Projects\\DS776_Develop_Project\\downloads\\hub\\models--xlm-roberta-base. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2127eb565a6a45ec9bd6798d276f84e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/615 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ed310f2d7f74543b14e936451ce4ec1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa7beceb95454566abc749bbe4920578",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.10M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "bert_model_name = \"bert-base-cased\"\n",
    "xlmr_model_name = \"xlm-roberta-base\"\n",
    "bert_tokenizer = AutoTokenizer.from_pretrained(bert_model_name)\n",
    "xlmr_tokenizer = AutoTokenizer.from_pretrained(xlmr_model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens from BERT tokenizer:\n",
      "['[CLS]', 'Jack', 'Spa', '##rrow', 'loves', 'New', 'York', '!', '[SEP]']\n",
      "\n",
      "Tokens from XLM-R tokenizer:\n",
      "['<s>', '▁Jack', '▁Spar', 'row', '▁love', 's', '▁New', '▁York', '!', '</s>']\n"
     ]
    }
   ],
   "source": [
    "text = \"Jack Sparrow loves New York!\"\n",
    "bert_tokens = bert_tokenizer(text).tokens()\n",
    "xlmr_tokens = xlmr_tokenizer(text).tokens()\n",
    "\n",
    "print(\"Tokens from BERT tokenizer:\")\n",
    "print(bert_tokens)  \n",
    "print(\"\\nTokens from XLM-R tokenizer:\")\n",
    "print(xlmr_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DS776env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
