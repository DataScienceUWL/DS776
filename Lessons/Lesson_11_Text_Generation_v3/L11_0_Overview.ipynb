{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Lesson 11: Text Generation and Decoding Strategies\n\n### Topics\n* Overview of transformer-based text generation\n* Decoding strategies: Greedy search, beam search, top-k sampling, and nucleus sampling\n* Using LLM APIs (OpenAI chat completions via OpenRouter) for text generation\n* Building custom API helper functions\n* Working with larger quantized models (30B-70B parameters)\n* Applications of text generation in NLP\n\n### Outcomes\n\n1. **Explain Text Generation Basics**: Describe how transformer models like GPT-2 generate text, and identify common applications of text generation, such as chatbots, content creation, and automated summarization.\n   \n2. **Use Decoding Strategies**: Implement and compare different decoding methods (e.g., greedy search, beam search, top-k sampling, nucleus sampling) to observe how each affects text generation quality.\n\n3. **Use LLM APIs via OpenRouter**: Access remote language models through standardized OpenAI-compatible APIs, managing API keys securely with environment variables, and understanding the trade-offs between local and API-based generation.\n\n4. **Build Custom API Helper Functions**: Create reusable Python functions for text generation that wrap API calls, handle errors gracefully, and provide a simplified interface for common tasks.\n\n5. **Work with Larger Quantized Models**: Load and use 30B-70B parameter models efficiently on GPU servers using 4-bit quantization, understanding memory management and performance trade-offs between model sizes.\n\n6. **Evaluate Generated Text**: Assess the quality of generated text, discussing trade-offs in coherence, creativity, and relevance with different decoding strategies and model sizes.\n\n7. **Identify Real-World Applications**: Explain practical uses of text generation in industries like customer service, media, and content creation, understanding the strengths and limitations of transformer-based text generation.\n\n### Readings and Videos\n* Read *Chapter 5: Text Generation* and pages 148-156 about metrics in *Natural Language Processing with Transformers*\n* **Course Notebooks with Videos**: Open each notebook in the Lesson_11 directory and watch the embedded videos in the recommended order.\n\n### Assessments\n1. Complete the reading quiz in Canvas (10 points).\n2. Complete the exercises in your homework notebook in CoCalc (40 points).\n\n### Homework Ideas\n\n1. **Experiment with Different Decoding Methods**: In a notebook, students can use a model like GPT-2 to generate text using various decoding strategies (e.g., beam search, top-k sampling, nucleus sampling). They should document the output quality for each method, comparing coherence, relevance, and creativity.\n\n2. **Build API Helper Functions**: Guide students to create custom helper functions that wrap the OpenAI API (via OpenRouter) for text generation tasks. They should implement proper error handling, support for different models, and configurable generation parameters.\n\n3. **Compare Model Sizes**: Have students compare text generation quality and speed across different model sizes (3B, 8B, 70B parameters). They should analyze trade-offs in accuracy, creativity, and computational cost for different use cases.\n\n4. **Build a Simple Response Generator**: Guide students to create a basic chatbot or response generator using either API-based or local pre-trained text generation models. They can experiment with prompt variations and decoding strategies to create engaging and contextually relevant responses for specific user inputs.\n\n5. **Analyze Decoding Trade-offs**: Have students experiment with decoding hyperparameters (e.g., beam width, top-k values, temperature) on a small dataset. They can analyze and document how adjustments affect the generated text's diversity, accuracy, and readability, providing insights into the practical trade-offs of each decoding strategy."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}