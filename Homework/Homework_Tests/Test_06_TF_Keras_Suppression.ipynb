{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Test 06: TensorFlow/Keras Suppression\n",
    "\n",
    "**Purpose:** Verify that transformers correctly ignores TensorFlow and Keras, preventing import errors and warnings.\n",
    "\n",
    "**Background:**\n",
    "- CoCalc has Keras 3 installed, which is incompatible with transformers' TF backend\n",
    "- Without suppression, `from transformers import ...` can trigger TF/Keras import errors\n",
    "- The auto_update script sets environment variables to prevent this\n",
    "\n",
    "**Expected Results:**\n",
    "- `TRANSFORMERS_NO_TF=1` should be set\n",
    "- `USE_TF=NO` should be set  \n",
    "- `TF_CPP_MIN_LOG_LEVEL=3` should be set\n",
    "- Importing transformers should NOT trigger any TF/Keras errors\n",
    "\n",
    "**Run this on:** Both CoCalc base and Compute Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DS776 Environment Setup & Package Update\n",
    "# Configures storage paths for proper cleanup/sync, then updates introdl if needed\n",
    "# If this cell fails, see Lessons/Course_Tools/AUTO_UPDATE_SYSTEM.md for help\n",
    "%run ../../Lessons/Course_Tools/auto_update_introdl.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check TF/Keras suppression environment variables\n",
    "import os\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"TF/KERAS SUPPRESSION ENVIRONMENT VARIABLES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "suppress_vars = {\n",
    "    'TRANSFORMERS_NO_TF': '1',\n",
    "    'USE_TF': 'NO',\n",
    "    'TF_CPP_MIN_LOG_LEVEL': '3',\n",
    "}\n",
    "\n",
    "all_good = True\n",
    "for var, expected in suppress_vars.items():\n",
    "    value = os.environ.get(var, 'NOT SET')\n",
    "    if value == expected:\n",
    "        status = \"OK\"\n",
    "    elif value == 'NOT SET':\n",
    "        status = \"WARNING: Not set\"\n",
    "        all_good = False\n",
    "    else:\n",
    "        status = f\"WARNING: Expected '{expected}', got '{value}'\"\n",
    "        all_good = False\n",
    "    print(f\"{var}: {value} [{status}]\")\n",
    "\n",
    "print()\n",
    "if all_good:\n",
    "    print(\"RESULT: All suppression variables configured correctly!\")\n",
    "else:\n",
    "    print(\"RESULT: Some suppression variables not set correctly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test: Import transformers without TF/Keras errors\n",
    "print(\"=\" * 60)\n",
    "print(\"TEST: Import transformers (should not trigger TF/Keras errors)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "import warnings\n",
    "import sys\n",
    "from io import StringIO\n",
    "\n",
    "# Capture any warnings during import\n",
    "captured_warnings = []\n",
    "def warning_handler(message, category, filename, lineno, file=None, line=None):\n",
    "    captured_warnings.append(str(message))\n",
    "\n",
    "old_showwarning = warnings.showwarning\n",
    "warnings.showwarning = warning_handler\n",
    "\n",
    "# Capture stderr for any TF messages\n",
    "old_stderr = sys.stderr\n",
    "sys.stderr = StringIO()\n",
    "\n",
    "try:\n",
    "    # This import would fail or produce warnings without suppression\n",
    "    from transformers import AutoModel, AutoTokenizer, pipeline\n",
    "    import_success = True\n",
    "    import_error = None\n",
    "except Exception as e:\n",
    "    import_success = False\n",
    "    import_error = str(e)\n",
    "finally:\n",
    "    stderr_output = sys.stderr.getvalue()\n",
    "    sys.stderr = old_stderr\n",
    "    warnings.showwarning = old_showwarning\n",
    "\n",
    "# Report results\n",
    "if import_success:\n",
    "    print(\"PASS: transformers imported successfully\")\n",
    "    print(f\"  - AutoModel: {AutoModel}\")\n",
    "    print(f\"  - AutoTokenizer: {AutoTokenizer}\")\n",
    "    print(f\"  - pipeline: {pipeline}\")\n",
    "else:\n",
    "    print(f\"FAIL: transformers import failed\")\n",
    "    print(f\"  Error: {import_error}\")\n",
    "\n",
    "# Check for TF/Keras related warnings\n",
    "tf_warnings = [w for w in captured_warnings if 'tensorflow' in w.lower() or 'keras' in w.lower() or 'tf' in w.lower()]\n",
    "if tf_warnings:\n",
    "    print(f\"\\nWARNING: {len(tf_warnings)} TF/Keras related warnings captured:\")\n",
    "    for w in tf_warnings[:5]:  # Show first 5\n",
    "        print(f\"  - {w[:100]}...\" if len(w) > 100 else f\"  - {w}\")\n",
    "else:\n",
    "    print(\"\\nPASS: No TF/Keras warnings during import\")\n",
    "\n",
    "# Check stderr for TF messages\n",
    "if stderr_output.strip():\n",
    "    tf_stderr = [line for line in stderr_output.split('\\n') if line.strip()]\n",
    "    if tf_stderr:\n",
    "        print(f\"\\nStderr output ({len(tf_stderr)} lines):\")\n",
    "        for line in tf_stderr[:5]:\n",
    "            print(f\"  {line[:100]}\")\n",
    "else:\n",
    "    print(\"PASS: No stderr output during import\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test: Verify transformers is NOT using TensorFlow backend\n",
    "print(\"=\" * 60)\n",
    "print(\"TEST: Verify transformers backend configuration\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "import transformers\n",
    "\n",
    "# Check if TF is being used\n",
    "try:\n",
    "    from transformers.utils import is_tf_available, is_torch_available\n",
    "    \n",
    "    torch_available = is_torch_available()\n",
    "    tf_available = is_tf_available()\n",
    "    \n",
    "    print(f\"PyTorch available: {torch_available}\")\n",
    "    print(f\"TensorFlow available: {tf_available}\")\n",
    "    \n",
    "    if torch_available and not tf_available:\n",
    "        print(\"\\nPASS: transformers is using PyTorch only (TF disabled)\")\n",
    "    elif torch_available and tf_available:\n",
    "        print(\"\\nWARNING: Both PyTorch and TF are available\")\n",
    "        print(\"  This may cause issues but imports should still work\")\n",
    "    elif not torch_available:\n",
    "        print(\"\\nWARNING: PyTorch not available!\")\n",
    "except ImportError as e:\n",
    "    print(f\"Could not check backend availability: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test: Load a model to verify everything works end-to-end\n",
    "print(\"=\" * 60)\n",
    "print(\"TEST: Load a small model (functional test)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "try:\n",
    "    from transformers import AutoTokenizer\n",
    "    \n",
    "    # Use a tiny model for quick testing\n",
    "    model_name = \"prajjwal1/bert-tiny\"\n",
    "    print(f\"Loading tokenizer for: {model_name}\")\n",
    "    \n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    \n",
    "    # Quick tokenization test\n",
    "    test_text = \"Hello, this is a test.\"\n",
    "    tokens = tokenizer(test_text, return_tensors=\"pt\")\n",
    "    \n",
    "    print(f\"\\nPASS: Tokenizer loaded and working\")\n",
    "    print(f\"  Input: '{test_text}'\")\n",
    "    print(f\"  Token IDs: {tokens['input_ids'].tolist()[0][:10]}...\")\n",
    "    print(f\"  Attention mask shape: {tokens['attention_mask'].shape}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"FAIL: Could not load model\")\n",
    "    print(f\"  Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "If all tests passed:\n",
    "- TF/Keras suppression environment variables are set correctly\n",
    "- transformers imports without triggering TF/Keras errors\n",
    "- transformers is configured to use PyTorch backend\n",
    "- Models can be loaded and used normally\n",
    "\n",
    "**Why this matters:**\n",
    "- CoCalc has Keras 3.x installed which is incompatible with transformers' TF support\n",
    "- Without suppression, students would see confusing TF/Keras import errors\n",
    "- The auto_update script sets these variables early to prevent issues"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
