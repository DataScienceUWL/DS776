{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **10-Question Multiple-Choice Reading Quiz for Chapter 2: \"Text Classification\"**\n",
    "\n",
    "---\n",
    "\n",
    "#### **1. What is the primary goal of text classification?**  \n",
    "A. To assign predefined labels to pieces of text based on their content.  \n",
    "B. To predict the next token in a sequence.  \n",
    "C. To identify named entities like people and locations.  \n",
    "D. To generate summaries of long documents.  \n",
    "**Answer**: A  \n",
    "\n",
    "---\n",
    "\n",
    "#### **2. What is a major challenge in creating a text classification dataset?**  \n",
    "A. Deciding the number of model layers required.  \n",
    "B. Ensuring the dataset has balanced class distributions.  \n",
    "C. Using beam search for generating labels.  \n",
    "D. Selecting the proper decoding strategy.  \n",
    "**Answer**: B  \n",
    "\n",
    "---\n",
    "\n",
    "#### **3. What is the purpose of tokenization in text classification?**  \n",
    "A. To summarize long texts.  \n",
    "B. To label tokens with predefined categories.  \n",
    "C. To split text into smaller units like words or subwords for processing.  \n",
    "D. To translate text into another language.  \n",
    "**Answer**: C  \n",
    "\n",
    "---\n",
    "\n",
    "#### **4. What is Byte Pair Encoding (BPE) used for in NLP?**  \n",
    "A. Reducing vocabulary size by creating subword representations.  \n",
    "B. Translating text into byte streams.  \n",
    "C. Increasing the modelâ€™s ability to handle numerical data.  \n",
    "D. Eliminating out-of-vocabulary words.  \n",
    "**Answer**: A  \n",
    "\n",
    "---\n",
    "\n",
    "#### **5. How do transformers act as feature extractors for text classification tasks?**  \n",
    "A. By embedding words in a fixed-size vector space.  \n",
    "B. By replacing the need for tokenization.  \n",
    "C. By capturing contextual relationships between tokens in the input text.  \n",
    "D. By directly predicting the classification label from raw text.  \n",
    "**Answer**: C  \n",
    "\n",
    "---\n",
    "\n",
    "#### **6. What is fine-tuning in the context of transformers?**  \n",
    "A. Selecting the best decoding strategy for text generation.  \n",
    "B. Modifying the pre-trained model to adapt it to a specific task or dataset.  \n",
    "C. Training a transformer model from scratch for a specific task.  \n",
    "D. Reducing the size of the transformer model for efficiency.  \n",
    "**Answer**: B  \n",
    "\n",
    "---\n",
    "\n",
    "#### **7. Which metric is commonly used to evaluate text classification models?**  \n",
    "A. ROUGE score  \n",
    "B. Perplexity  \n",
    "C. BLEU score  \n",
    "D. F1-score  \n",
    "**Answer**: D  \n",
    "\n",
    "---\n",
    "\n",
    "#### **8. What is the main advantage of subword tokenization methods like WordPiece?**  \n",
    "A. They improve the speed of training.  \n",
    "B. They can handle out-of-vocabulary words by breaking them into smaller units.  \n",
    "C. They reduce the size of the transformer model.  \n",
    "D. They eliminate the need for training a tokenizer.  \n",
    "**Answer**: B  \n",
    "\n",
    "---\n",
    "\n",
    "#### **9. What should you do if a text classification dataset has imbalanced classes?**  \n",
    "A. Add more layers to the transformer model.  \n",
    "B. Switch to an extractive summarization task instead.  \n",
    "C. Perform class balancing by oversampling underrepresented classes or undersampling overrepresented classes.  \n",
    "D. Use subword tokenization to split text.  \n",
    "**Answer**: C  \n",
    "\n",
    "---\n",
    "\n",
    "#### **10. Which tokenization approach is generally NOT used in text classification tasks?**  \n",
    "A. Byte-level tokenization  \n",
    "B. Word tokenization  \n",
    "C. Subword tokenization  \n",
    "D. Character tokenization  \n",
    "**Answer**: A  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
