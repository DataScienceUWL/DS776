{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oxford-IIIT Pet Dataset Faster R-CNN Training and Evaluation Notebook\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "# 1. Setup and Imports\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "from torchvision.datasets import OxfordIIITPet\n",
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from torchvision.ops import box_iou\n",
    "import random\n",
    "\n",
    "# 2. Define Device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# 3. Load the Dataset with Transformations\n",
    "class CustomPetDataset(OxfordIIITPet):\n",
    "    def __init__(self, root, target_types, transform=None, download=False, downsample_ratio=1.0):\n",
    "        super().__init__(root=root, target_types=target_types, transform=transform, download=download)\n",
    "        \n",
    "        # Downsample dataset if specified\n",
    "        if downsample_ratio < 1.0:\n",
    "            self.indices = random.sample(range(len(self)), int(len(self) * downsample_ratio))\n",
    "        else:\n",
    "            self.indices = list(range(len(self)))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sample_idx = self.indices[idx]\n",
    "        image, target = super().__getitem__(sample_idx)\n",
    "        \n",
    "        # Adjust the target dictionary to match Faster R-CNN format\n",
    "        target = {\n",
    "            \"boxes\": target['bbox'].unsqueeze(0),  # Each image has one box, convert to 2D array\n",
    "            \"labels\": torch.tensor([target['category'] + 1])  # +1 to account for background class\n",
    "        }\n",
    "        \n",
    "        return image, target\n",
    "\n",
    "# Define transformations\n",
    "transform = T.ToTensor()\n",
    "\n",
    "# Load the dataset with all classes\n",
    "downsample_ratio = 1.0  # Optionally adjust this to a smaller portion for quicker demo\n",
    "dataset = CustomPetDataset(root='./data', target_types=['category', 'bbox'], transform=transform, download=True, downsample_ratio=downsample_ratio)\n",
    "\n",
    "# Split dataset into train and validation sets\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True, collate_fn=lambda x: tuple(zip(*x)))\n",
    "val_loader = DataLoader(val_dataset, batch_size=2, shuffle=False, collate_fn=lambda x: tuple(zip(*x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oxford-IIIT Pet Dataset Faster R-CNN Training and Evaluation Notebook\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "# 1. Setup and Imports\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "from torchvision.datasets import OxfordIIITPet\n",
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from torchvision.ops import box_iou\n",
    "import numpy as np\n",
    "import random\n",
    "from PIL import Image\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Load the Dataset with Transformations and Bounding Box Calculation\n",
    "class CustomPetDataset(OxfordIIITPet):\n",
    "    def __init__(self, root, transform=None, download=False, downsample_ratio=1.0):\n",
    "        super().__init__(root=root, target_types=[\"category\", \"segmentation\"], transform=transform, download=download)\n",
    "        \n",
    "        # Downsample dataset if specified\n",
    "        if downsample_ratio < 1.0:\n",
    "            self.indices = random.sample(range(len(self)), int(len(self) * downsample_ratio))\n",
    "        else:\n",
    "            self.indices = list(range(len(self)))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sample_idx = self.indices[idx]\n",
    "        image, target = super().__getitem__(sample_idx)\n",
    "        \n",
    "        # Calculate bounding box from segmentation mask\n",
    "        mask = target[\"segmentation\"]\n",
    "        mask_array = np.array(mask)\n",
    "        non_zero_coords = np.argwhere(mask_array)\n",
    "        y_min, x_min = non_zero_coords.min(axis=0)\n",
    "        y_max, x_max = non_zero_coords.max(axis=0)\n",
    "        bbox = [x_min, y_min, x_max, y_max]\n",
    "        \n",
    "        # Prepare the target dictionary\n",
    "        target = {\n",
    "            \"boxes\": torch.tensor([bbox], dtype=torch.float32),  # Wrap bbox in a list to match expected shape\n",
    "            \"labels\": torch.tensor([target[\"category\"] + 1])  # +1 to account for background class\n",
    "        }\n",
    "        \n",
    "        return image, target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Define and Configure the Faster R-CNN Model\n",
    "num_classes = 38  # 37 pet breeds + 1 background class\n",
    "model = fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "model.roi_heads.box_predictor = torch.nn.Linear(in_features, num_classes)\n",
    "model.to(device)\n",
    "\n",
    "# Define optimizer and OneCycleLR scheduler\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
    "steps_per_epoch = len(train_loader)\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=0.005, steps_per_epoch=steps_per_epoch, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Training and Validation Loop\n",
    "num_epochs = 10\n",
    "model_save_path = \"faster_rcnn_pets.pth\"\n",
    "for epoch in range(num_epochs):\n",
    "    # Training\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for images, targets in train_loader:\n",
    "        images = [image.to(device) for image in images]\n",
    "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss_dict = model(images, targets)\n",
    "        losses = sum(loss for loss in loss_dict.values())\n",
    "        train_loss += losses.item()\n",
    "        \n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "    \n",
    "    train_loss /= len(train_loader)\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}], Train Loss: {train_loss:.4f}\")\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for images, targets in val_loader:\n",
    "            images = [image.to(device) for image in images]\n",
    "            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "            loss_dict = model(images, targets)\n",
    "            val_loss += sum(loss for loss in loss_dict.values()).item()\n",
    "    \n",
    "    val_loss /= len(val_loader)\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}], Validation Loss: {val_loss:.4f}\")\n",
    "\n",
    "# Save the model after training\n",
    "torch.save(model.state_dict(), model_save_path)\n",
    "print(\"Model saved successfully.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload the Model for Evaluation\n",
    "model.load_state_dict(torch.load(model_save_path))\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Compute Metrics on the Validation Set with IoU-based Matching\n",
    "def calculate_metrics(model, data_loader, device, iou_threshold=0.5, confidence_threshold=0.5):\n",
    "    all_true_labels = []\n",
    "    all_pred_labels = []\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for images, targets in data_loader:\n",
    "            images = [image.to(device) for image in images]\n",
    "            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "            # Get predictions\n",
    "            predictions = model(images)\n",
    "            \n",
    "            for pred, target in zip(predictions, targets):\n",
    "                # Filter predictions by confidence threshold\n",
    "                keep = pred['scores'] >= confidence_threshold\n",
    "                pred_boxes = pred['boxes'][keep]\n",
    "                pred_labels = pred['labels'][keep]\n",
    "\n",
    "                # Get ground truth boxes and labels\n",
    "                true_boxes = target['boxes']\n",
    "                true_labels = target['labels']\n",
    "\n",
    "                if len(pred_boxes) > 0 and len(true_boxes) > 0:\n",
    "                    # Compute IoU between each predicted box and each true box\n",
    "                    iou_matrix = box_iou(pred_boxes, true_boxes)\n",
    "                    \n",
    "                    # Match predictions with ground truth based on IoU\n",
    "                    for i, pred_label in enumerate(pred_labels):\n",
    "                        # Find the best-matching ground truth box for this prediction\n",
    "                        max_iou, max_iou_idx = iou_matrix[i].max(0)\n",
    "                        \n",
    "                        # Check if IoU is above threshold, and if so, it's a valid match\n",
    "                        if max_iou >= iou_threshold:\n",
    "                            all_pred_labels.append(pred_label.item())\n",
    "                            all_true_labels.append(true_labels[max_iou_idx].item())\n",
    "                            \n",
    "                            # Set the matched true box IoU to zero to prevent re-matching\n",
    "                            iou_matrix[:, max_iou_idx] = 0\n",
    "                        else:\n",
    "                            # If no match is found, count as false positive\n",
    "                            all_pred_labels.append(pred_label.item())\n",
    "                            all_true_labels.append(0)  # Background/false class\n",
    "                else:\n",
    "                    # No ground truth or predictions: count as all false negatives or false positives\n",
    "                    all_pred_labels.extend(pred_labels.cpu().numpy())\n",
    "                    all_true_labels.extend([0] * len(pred_labels))  # Background/false class for unmatched preds\n",
    "                    all_true_labels.extend(true_labels.cpu().numpy())\n",
    "                    all_pred_labels.extend([0] * len(true_labels))  # Background/false class for unmatched truths\n",
    "\n",
    "    # Calculate precision, recall, and F1-score\n",
    "    precision = precision_score(all_true_labels, all_pred_labels, average='weighted')\n",
    "    recall = recall_score(all_true_labels, all_pred_labels, average='weighted')\n",
    "    f1 = f1_score(all_true_labels, all_pred_labels, average='weighted')\n",
    "\n",
    "    print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}\")\n",
    "\n",
    "# Run metrics calculation on the validation set\n",
    "calculate_metrics(model, val_loader, device)\n",
    "\n",
    "# 7. Visualize Predictions on Validation Samples\n",
    "def plot_sample(image, target, prediction=None):\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(8, 8))\n",
    "    \n",
    "    # Display image\n",
    "    ax.imshow(image.permute(1, 2, 0).cpu().numpy())\n",
    "    \n",
    "    # Plot true boxes in blue\n",
    "    true_boxes = target[\"boxes\"].cpu().numpy()\n",
    "    for box in true_boxes:\n",
    "        x_min, y_min, x_max, y_max = box\n",
    "        ax.add_patch(plt.Rectangle((x_min, y_min), x_max - x_min, y_max - y_min,\n",
    "                                   fill=False, color=\"blue\", linewidth=2))\n",
    "\n",
    "    # Plot predicted boxes in red if provided\n",
    "    if prediction:\n",
    "        pred_boxes = prediction[\"boxes\"].cpu().numpy()\n",
    "        for box in pred_boxes:\n",
    "            x_min, y_min, x_max, y_max = box\n",
    "            ax.add_patch(plt.Rectangle((x_min, y_min), x_max - x_min, y_max - y_min,\n",
    "                                       fill=False, color=\"red\", linewidth=2))\n",
    "    \n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "# Test on random validation samples\n",
    "with torch.no_grad():\n",
    "    for images, targets in random.sample(list(val_loader), 3):\n",
    "        images = [image.to(device) for image in images]\n",
    "        predictions = model(images)\n",
    "        \n",
    "        for img, target, pred in zip(images, targets, predictions):\n",
    "           \n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
