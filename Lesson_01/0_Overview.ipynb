{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lesson 1\n",
    "\n",
    "### Outcomes\n",
    "\n",
    "1. **Understand deep learning fundamentals**, including the structure of neural networks.\n",
    "2. **Utilize PyTorch datasets and data loaders** to efficiently handle and preprocess data for training deep learning models.\n",
    "3. **Develop and train basic fully connected neural networks** in PyTorch, applying optimization techniques and appropriate loss functions.\n",
    "4. **Evaluate model performance** by plotting loss functions and other metrics.\n",
    "5. **Make predictions for new data** by applying a trained neural network to new inputs.\n",
    "\n",
    "### Primary Materials\n",
    "\n",
    "* **Course Intro Notebook / Video** (Still to come)\n",
    "\n",
    "* **(Optional) Review Neural Networks from DS740**\n",
    "\n",
    "    * You might want to review the first 14 slides of the [Lesson on Neural networks in DS740](https://media.uwex.edu/content/ds/ds740_r23/ds740_artificial-neural-networks.sbproj/).  We're covering similar material this week.  Don't review the material about neural networks in R since we'll be using Python.\n",
    "\n",
    "* **Readings from Inside Deep Learning (IDL)**\n",
    "\n",
    "    * **Chapter 1: The Mechanics of Learning**\n",
    "        - **Read Sections 1.2, 1.4, and 1.5**. Skim the other sections. No need to understand the detailed code or the backpropagation algorithm, but ensure you understand how the gradient is used in training.\n",
    "\n",
    "    * **Chapter 2: Fully Connected Networks*\n",
    "        - **Section 2.1**: Focus on understanding the training loop structure and process. Skip the code details but grasp the concept.\n",
    "            - Don’t worry about the math notation at the bottom of page 40. It's shorthand for a fully connected linear layer. If you want to learn more about matrix multiplication see the videos listed under Auxiliary Materials below.\n",
    "        - **Section 2.2**: Understand how activation functions introduce nonlinearity into networks.\n",
    "        - **Section 2.3**: Grasp the basics of softmax and cross-entropy, especially how the loss function changes for classification tasks. An example will be explained in a notebook and video.\n",
    "        - **Section 2.4**: Note the key concepts; they will be reinforced in video lectures.\n",
    "        - **Section 2.5**: Understand the importance of batch training, particularly for large datasets that won’t fit in memory.\n",
    "\n",
    "* **Course Notebooks with Videos**  Open each of the notebooks included the lesson folder and watch the embedded video.  You can read along and work through the code examples as you want.  The notebooks for this lesson are in the Lesson_01 directory.  The notebooks are numbered in the order they should be used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auxillary Materials\n",
    "\n",
    "#### Background Mathematics\n",
    "\n",
    "If you want to understand the theory of building and training neural networks you likely need some background in multivariate calculus and linear algebra.  To work with and apply neural networks you can by with just a little math.  \n",
    "\n",
    "* **Matrices, Vectors, and Gradients.** Having some idea about matrices, vectors and gradients is a good idea.  Dr. Anne Hsu has recorded some helpful videos on many topics related to introductory deep learning:\n",
    "    * [Matrices and Vectors](https://www.youtube.com/watch?v=sM2Mm6aT_HI)\n",
    "    * [Derivatives and Gradients 1](https://www.youtube.com/watch?v=Fiw0_w4AykA)\n",
    "    * [Derivatives and Gradients 2](https://www.youtube.com/watch?v=qORZmKCB0g8)\n",
    "    * [Playlist for entire Intro to Deep Learning](https://www.youtube.com/@drannehsu/playlists)\n",
    "\n",
    "* **Mathematics for Machine Learning and Data Science.** This specialization includes linear algebra, calculus, and probability and statistics.  It's too much to pick up for a quick introduction but would be terrific for a deeper dive:\n",
    "    * [Coursera three course specialization](https://www.coursera.org/specializations/mathematics-for-machine-learning-and-data-science?)\n",
    "\n",
    "#### Other Deep Learning Resources:\n",
    "\n",
    "* **Deep Learning Basics: Introduction and Overview**  Lex Fridman is a well known podcast host for AI and Data Science.  Here he gives an [introductory lecture](https://youtu.be/O5xeyoRL95U?si=SrM7RLWB_iBPMiK4) for MIT's public deep learning class.  Since it was recorded in 2019 it doesn't include the latest on transformer architectures that are driving the current boom in AI (ChatGPT, etc.), it's still a really nice introduction that discusses many applications of deep learning.  Watch this if you want a good overview.  I also recommend his podcast.\n",
    "\n",
    "* **Neural Networks and Deep Learning.** Andrew Ng is a big name in AI and I love listening to him.  This [playlist](https://www.youtube.com/playlist?list=PLkDaE6sCZn6Ec-XTbcX1uRg2_u4xOEky0) is all the videos from the first course of his Deep Learning Specialization on Coursera.  This is a really great resource for a deep learning introduction.\n",
    "\n",
    "* **Introduction to Deep Learning from MIT**  [Free public course](http://introtodeeplearning.com/) updated annually.  The beginning lecture is very accessible.\n",
    "\n",
    "* **Activation Functions** There are more than the three activation functions we discussed in our video.  [All the Activation Functions](https://dublog.net/blog/all-the-activations/) is a quick summary of most of activation functions used in deep learning.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### Programming and PyTorch Resources\n",
    "\n",
    "* **Object-Oriented Programming** It helps to have a basic familiarity with classes, inheritance, and methods for finding your way around in PyTorch.  [Real Python has a great tutorial](https://realpython.com/python3-object-oriented-programming/) on the basics of OOP with many code examples that you can either read or watch (40 minutes).\n",
    "\n",
    "* **PyTorch Tutorials** The [official PyTorch tutorials](https://pytorch.org/tutorials/) are quite good.  For Lesson 1 the tutorials on tensors (both [written](https://pytorch.org/tutorials/beginner/basics/tensorqs_tutorial.html) and on [YouTube](https://pytorch.org/tutorials/beginner/introyt/tensors_deeper_tutorial.html)) and on [Datasets & DataLoaders](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html) might be of interest.  The [Build the Neural Network tutorial](https://pytorch.org/tutorials/beginner/basics/buildmodel_tutorial.html) also breaks down the ingredients in a fully connected network. \n",
    "\n",
    "\n",
    "* **PyTorch Documentation** This often isn't as useful as the tutorials, but you can find information about [everything PyTorch here](https://pytorch.org/docs/stable/index.html).  One nugget that might be helpful for Lesson 1 is the the [documentation for torch.Tensor](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html) which shows the available data types.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "UWL-DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
