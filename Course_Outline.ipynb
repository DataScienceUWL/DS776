{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Course Syllabus\n",
    "\n",
    "## Course Objectives: ##\n",
    "- Understand the conceptual framework of deep learning models/applications but maybe not all the details.\n",
    "- Be able to utilize pretrained and foundational models, perhaps with finetuning.\n",
    "- Be able to manage a simple deep learning workflow:  build and split dataset, train or fine tune model, save model, load model, inference, warm restarts, possibly monitoring experiments, possibly deployments\n",
    "- Assessing Model Performance and Limitations (Data Bias)\n",
    "- Computer Vision Applications.  NLP Applications.\n",
    "\n",
    "## Textbooks and Other Resources\n",
    "\n",
    "### Required Books\n",
    "- \"Inside Deep Learning: Math, Algorithms, Models\" by Edward Raff (2022)\n",
    "- \"Natural Language Processing with Transformers, Revised Edition\" by Tunstall, et al (2022)\n",
    "\n",
    "###  Free Online Books\n",
    "- (Dive Into Deep Learning)[https://d2l.ai/]  Shows how to code in multiple frameworks, but you'll need to use their packages to get things up and running easily.  \n",
    "- (Understanding Deep Learning)[https://udlbook.github.io/udlbook/]  Explains a lot of the mathematical details about various deep learning models.  Great pictures.  It isn't light reading.\n",
    "- (Deep Learning)[https://www.deeplearningbook.org/]  From MIT.  Good book for the first half of the class.\n",
    "\n",
    "### Other Comprehensive Resources:\n",
    "- **Hugging Face Documentation:** [Hugging Face Transformers](https://huggingface.co/transformers/)\n",
    "- **PyTorch Documentation:** [PyTorch](https://pytorch.org/docs/stable/index.html)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Week 1: Introduction to Deep Learning and Fully Connected Networks\n",
    "\n",
    "## Objectives\n",
    "1. **Implement Basic Deep Learning Workflow in PyTorch**\n",
    "   - Prepare Data (Datasets, DataLoaders, batching)\n",
    "   - Configure Model (Classes and OOP, PyTorch building blocks)\n",
    "   - Train Model (train_simple_network)\n",
    "   - Evaluate Model (metrics)\n",
    "   - Make Predictions on New Data (write a predict function)\n",
    "\n",
    "2.  **Regression and Classification Basics**\n",
    "   - Similarities and Differences in NN's and Loss Functions\n",
    "\n",
    "## Readings and Videos\n",
    "* Read Chapters 1-2 of IDL\n",
    "* Review first half of DS740 NN Storybook\n",
    "* (NOT DONE YET) How to use course notebooks.\n",
    "* Notebooks\n",
    "   * Nonlinear_Regression_1D\n",
    "   * Classification_2D\n",
    "\n",
    "## Assessments\n",
    "1. Reading Quiz in Canvas\n",
    "2. Submit notebook for classifying spiral points.\n",
    "\n",
    "## Auxiliary Resources\n",
    "1.  Some Deep Learning Big Picture Video - [Deep Learning Basics: Introduction and Overview](https://www.youtube.com/watch?v=O5xeyoRL95U)\n",
    "2.  Linear Algebra Resources\n",
    "3.  [Introduction to PyTorch Tensors - PyTorch Documentation](https://pytorch.org/tutorials/beginner/introyt/tensors_deeper_tutorial.html) \n",
    "\n",
    "\n",
    "- [MIT 6.S191: Introduction to Deep Learning](https://www.youtube.com/watch?v=5tvmMX8r_OM) - Lecture series from MIT's introductory deep learning course.  Low level, begins with deep fake of Obama introducing class (from 2020). Newer video from 2021.  Look to see what the newest version of this intro video.  Great intro level to NN, Loss Functions, Training, and Overfitting.\n",
    "- [Deep Learning Crash Course for Beginners](https://www.youtube.com/watch?v=VyWAvY2CF9c) - A comprehensive introduction to deep learning basics.  This 90 minute video is a good summary of most of weeks 1-7.  I could copy the style of this video or just assign bits of it.  DON'T USE THIS ONE, but consider integrating or copying it's style.\n",
    "\n",
    "- [Introduction to Deep Learning - MIT OpenCourseWare](https://ocw.mit.edu/courses/6-s191-introduction-to-deep-learning-january-iap-2020/) - Free course material including lecture videos and notes.\n",
    "\n",
    "- [Visual Guide to NN](https://jalammar.github.io/visual-interactive-guide-basics-neural-networks/)By the Illustrated Transformer guy. (All his stuff is great)\n",
    "- [DeepLearningAI - NNs and DL playlist](https://www.youtube.com/watch?v=CS4cs9xVecg&list=PLkDaE6sCZn6Ec-XTbcX1uRg2_u4xOEky0&ab_channel=DeepLearningAI) Andrew Ng videos - use some of these\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 2: Convolutional Neural Networks (CNNs)\n",
    "\n",
    "## Objectives / Topics\n",
    "\n",
    "1. **Image Data Representation**: Grayscale, RGB, channels, Numpy vs PyTorch.\n",
    "2. **Convolutional Kernels**: fixed kernels (color and edge detectors) vs learnable kernels, receptive fields, Conv2D in PyTorch, kernel size, padding, stride\n",
    "3. **Feature Maps and Size Calculation**:  formula for output size, different levels of features\n",
    "4. **Pooling Layers:** max vs average, dimensionality reduction, improved translational invariance, pooling vs stride > 1\n",
    "\n",
    "## Readings and Videos\n",
    "\n",
    "* Notebook for Image Representation\n",
    "* MNIST_FC notebook\n",
    "* Read Chapter 3 in IDL\n",
    "* Output Sizes Notebook\n",
    "* Andrew Ng video(s) on convolutions\n",
    "* MNIST_CNN Notebook (include brief CNN Explainer Video)\n",
    "\n",
    "## Assessments\n",
    "\n",
    "* Canvas Quiz for reading and output size calculations\n",
    "* Build and test a couple of networks for FashionMNIST.  Try LeNet5.  Try \"SmallCNN\" as follows.\n",
    "    * What are the most common misclassifications?  Do they make sense?\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 3: Optimization and Regularization Techniques\n",
    "\n",
    "## Topics:\n",
    "* Overfitting\n",
    "* Optimizers\n",
    "* Regularization\n",
    "* Splitting Data\n",
    "* Data Augmentation\n",
    "* Learning Rate Schedulers\n",
    "\n",
    "**Objectives:**\n",
    "\n",
    "1. **Overfitting:** What is it?  What are common approaches to preventing it?  Why is a common problem in deep learning?\n",
    "2. **Optimizers:** Learn about alternatives to SGD.  Adaptive learning rates.  Momentum.\n",
    "3. **Regularization:** L2 and L1 regulurization.  L2 is built into many optimizers.  L1 needs a term added to loss function.\n",
    "4. **Learning Rate Schedulers:** What do they do?  General advice.\n",
    "5. **Data Augmentation:** What is it?  Why is it helpful?  How to choose augmentations.\n",
    "\n",
    "\n",
    "## Readings and Videos\n",
    "* IDL 5.1-5.3\n",
    "* Resizing and Augmentation Notebook\n",
    "* CIFAR 10 Notebook (split into smaller parts, mention Optuna here)\n",
    "* Augmentation Notebook.\n",
    "\n",
    "**Assessments:**\n",
    "- Quiz on optimization and regularization\n",
    "- Homework: Experiment with different optimization, regularization, and augmentation for CNN on FashionMNIST.\n",
    "\n",
    "**Textbook Support:**\n",
    "- IDL end of Chapter 3.  IDL 5.1-5.3\n",
    "\n",
    "**Video Lectures:**\n",
    "- [Optimization Techniques in Deep Learning](https://www.youtube.com/watch?v=G_wG9tCVA3k) - Explanation of various optimization algorithms.\n",
    "- [Regularization in Deep Learning](https://www.youtube.com/watch?v=ZLUtucsaE5g) - Detailed lecture on regularization methods.\n",
    "\n",
    "**Tutorials:**\n",
    "- [PyTorch Optimization Techniques](https://www.youtube.com/watch?v=t9aUoUnwhvI) - Implementing different optimization algorithms in PyTorch.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 4: Advanced CNNs and Transfer Learning\n",
    "\n",
    "## Objectives:\n",
    "\n",
    "Batch Normalization, Residual Connections, Skip Connections, Transfer Learning (head only vs fine-tuning)\n",
    "\n",
    "1.  **Batch Normalization**  What's the point of normalization in general?  Experiment with batch normalization and training CNN.  Show for CIFAR10.\n",
    "\n",
    "2.  **Residual Connections**  Help forward and backward propogation of info in network.  Smooths loss surface. Allows deeper networks and improved training.\n",
    "\n",
    "3.  **Skip Connections**  Similar to residual connections, but results from parallel paths are concatenated before sending to next layers.\n",
    "\n",
    "4.  **Transfer Learning**  Work through an example showing tuning only the head vs finetuning all layers.\n",
    "\n",
    "## Readings and Videos\n",
    "- IDL 6.1-6.5, 13.1-13.2\n",
    "\n",
    "## Assessments\n",
    "- Quiz on advanced CNN architectures\n",
    "- Homework: Compare the performance of different CNN architectures on a chosen dataset\n",
    "- Quiz on transfer learning\n",
    "- Homework: Apply transfer learning to a custom dataset\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 5: Object Detection and Segmentation\n",
    "\n",
    "### **Week Overview: Object Detection (Chapter 8)**\n",
    "\n",
    "**Objective:** This week focuses on introducing key concepts and techniques in object detection, such as image segmentation, transposed convolutions, and bounding box-based detection using Faster R-CNN. Students will gain a thorough understanding of object detection models and implement them using PyTorch.\n",
    "\n",
    "### **Lecture Breakdown:**\n",
    "\n",
    "1. **Lecture 1: Fundamentals of Object Detection and Image Segmentation**\n",
    "   - **Topics Covered:**\n",
    "     - Overview of object detection and its real-world applications.\n",
    "     - Introduction to image segmentation as a foundational task.\n",
    "     - Pixel-wise classification and creating segmentation masks.\n",
    "     - Building segmentation models using U-Net architecture.\n",
    "   - **Jupyter Notebook 1:** Implement a simple U-Net for image segmentation on a dataset like the PASCAL VOC dataset.\n",
    "     - **Learning Goal:** Understand per-pixel classification and learn to build a basic segmentation model using transposed convolutions.\n",
    "\n",
    "2. **Lecture 2: Bounding Boxes and Object Detection with Faster R-CNN**\n",
    "   - **Topics Covered:**\n",
    "     - Transition from pixel-wise predictions to bounding box predictions.\n",
    "     - Understanding and implementing Faster R-CNN for detecting objects in images.\n",
    "     - Working with region proposals and applying bounding boxes to locate objects.\n",
    "   - **Jupyter Notebook 2:** Implement a basic object detection pipeline using Faster R-CNN with PyTorch’s built-in functionalities.\n",
    "     - **Learning Goal:** Gain hands-on experience with region proposal-based object detection and bounding box predictions.\n",
    "\n",
    "3. **Lecture 3: Advanced Object Detection Techniques and Filtering Results**\n",
    "   - **Topics Covered:**\n",
    "     - Strategies for suppressing overlapping bounding boxes (Non-Max Suppression).\n",
    "     - Reducing false positives in detection models.\n",
    "     - Understanding and utilizing pretrained object detection models for faster and more accurate results.\n",
    "   - **Jupyter Notebook 3:** Fine-tune a pretrained Faster R-CNN model and perform detection on custom images.\n",
    "     - **Learning Goal:** Learn to adapt pretrained models for custom tasks and implement post-processing techniques to refine detections.\n",
    "\n",
    "### **Assignment: Implementing a Custom Object Detector**\n",
    "\n",
    "**Title:** \"Building an Object Detector with U-Net and Faster R-CNN\"\n",
    "\n",
    "- **Description:** \n",
    "  The assignment tasks students to implement and train two models—one for segmentation and another for object detection. First, they will build a segmentation model using U-Net to identify objects at a pixel level. Then, they will implement and fine-tune a Faster R-CNN model for bounding box-based detection.\n",
    "\n",
    "- **Requirements:**\n",
    "  - **Image Segmentation Model:** Train a U-Net to segment objects in a dataset like PASCAL VOC or a simpler dataset. Visualize segmentation masks and calculate accuracy metrics.\n",
    "  - **Object Detection Model:** Implement or fine-tune a Faster R-CNN using a dataset with bounding box annotations. Evaluate and visualize the results, highlighting detected objects.\n",
    "  - Submit a report explaining the approaches taken for segmentation and detection, including challenges faced and how results were refined.\n",
    "\n",
    "- **Learning Outcomes:** \n",
    "  - Develop a deeper understanding of segmentation and object detection tasks.\n",
    "  - Gain experience with both custom and pretrained models for different detection tasks.\n",
    "  - Understand and implement post-processing techniques to improve object detection results.\n",
    "\n",
    "### **Resources Needed:**\n",
    "- **Lecture Videos:** Pre-recorded videos covering theoretical concepts and code walkthroughs.\n",
    "- **Jupyter Notebooks:** Detailed code for U-Net and Faster R-CNN implementations.\n",
    "- **Assignment Data:** Example datasets like PASCAL VOC or a custom dataset with both segmentation masks and bounding box annotations.\n",
    "\n",
    "This plan provides a comprehensive introduction to object detection, emphasizing hands-on experience with segmentation and bounding box-based detection using widely used architectures.\n",
    "\n",
    "**Textbook Support:**\n",
    "- **Chapter 8 - Object Detection and Segmentation**:\n",
    "  - Segmentation (Section 8.1).\n",
    "  - Image segmentation with U-Net.\n",
    "  - Object detection with bounding boxes (Section 8.4).\n",
    "  - Implementation of Faster R-CNN.\n",
    "\n",
    "**Video Lectures:**\n",
    "- [PyTorch Image Segmentation Tutorial with U-NET: everything from scratch baby](https://www.youtube.com/watch?v=IHq1t7NxS8k)\n",
    "- [Implement and Train U-NET From Scratch for Image Segmentation - PyTorch](https://www.youtube.com/watch?v=HS3Q_90hnDg)\n",
    "\n",
    "**Tutorials:**\n",
    "- **Image Segmentation with U-Net**:\n",
    "  - [PyImageSearch U-Net Tutorial](https://pyimagesearch.com/2019/08/12/u-net-image-segmentation-in-keras/)\n",
    "- **Object Detection with Faster R-CNN**:\n",
    "  - [PyTorch Faster R-CNN Tutorial](https://pytorch.org/tutorials/intermediate/torchvision_tutorial.html)\n",
    "\n",
    "These resources and activities are designed to provide a comprehensive understanding of object detection and segmentation, supported by practical implementations and real-world applications.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 6- Generative Adversarial Networks (GANS)\n",
    "\n",
    "## Objectives / Topics\n",
    "\n",
    "1. **Understand the Basics of GANs:** \n",
    "   Learn the core components of a GAN—generator and discriminator—and understand their adversarial relationship and the training dynamics using loss functions.\n",
    "\n",
    "2. **Implement a Basic GAN:** \n",
    "   Write code to build and train a simple GAN model on a small dataset (like MNIST) to solidify fundamental concepts.\n",
    "\n",
    "3. **Explore Advanced GAN Variants:** \n",
    "   Study the architecture and design principles of a Deep Convolutional GAN (DCGAN) to improve image generation quality. Understand key challenges like mode collapse and learn solutions.\n",
    "\n",
    "4. **Experiment with Conditional GANs (CGANs):** \n",
    "   Extend the basic GAN to include class labels, allowing conditional image generation based on specific attributes or classes in the CIFAR-10 dataset.\n",
    "\n",
    "5. **Hands-on Assignment with DCGAN:** \n",
    "   Implement a DCGAN from scratch using PyTorch to generate images from the CIFAR-10 dataset, focusing on tuning hyperparameters, addressing training issues, and evaluating generated samples.\n",
    "\n",
    "## Readings and Videos\n",
    "\n",
    "**Read Chapter 9 IDL**\n",
    "\n",
    "The focus will be on introducing GANs, their architecture, key challenges like mode collapse, and advanced variations such as Deep Convolutional GANs (DCGAN). The plan includes three lecture videos with accompanying Jupyter notebooks and an assignment that leverages GANs to generate CIFAR-10 images.\n",
    "\n",
    "### **Lecture Breakdown:**\n",
    "1. **Lecture 1: Introduction to GANs**\n",
    "   - **Topics:** \n",
    "     - What are GANs?\n",
    "     - Architecture of a GAN (Generator and Discriminator)\n",
    "     - Adversarial training dynamics and loss functions.\n",
    "   - **Jupyter Notebook 1:** Implement a basic GAN to generate simple shapes (like digits using the MNIST dataset).\n",
    "     - **Learning Goal:** Students will understand the adversarial training loop and basic implementation of a GAN model in PyTorch.\n",
    "\n",
    "2. **Lecture 2: Advanced GAN Techniques and DCGAN**\n",
    "   - **Topics:** \n",
    "     - Addressing Mode Collapse and instability in GANs.\n",
    "     - Deep Convolutional GAN (DCGAN) architecture.\n",
    "     - Understanding generator and discriminator designs with convolutional layers.\n",
    "   - **Jupyter Notebook 2:** Build a DCGAN to generate images from the CIFAR-10 dataset.\n",
    "     - **Learning Goal:** Students will learn to extend GANs with convolutional networks to produce more complex images.\n",
    "\n",
    "3. **Lecture 3: Conditional GANs and Exploring Latent Space**\n",
    "   - **Topics:** \n",
    "     - Conditional GANs (CGANs): Adding control over generated samples.\n",
    "     - Latent space interpolation and visualizing generated images.\n",
    "   - **Jupyter Notebook 3:** Implement a CGAN to conditionally generate images based on class labels from CIFAR-10.\n",
    "     - **Learning Goal:** Students will learn how to incorporate labels into the generation process and explore the latent space.\n",
    "\n",
    "### **Assignment: Implementing DCGAN on CIFAR-10**\n",
    "**Title:** \"Creating Your Own DCGAN to Generate CIFAR-10 Images\"\n",
    "\n",
    "- **Description:** \n",
    "  The assignment asks students to implement a Deep Convolutional GAN (DCGAN) from scratch using PyTorch. They will train the model on the CIFAR-10 dataset to generate realistic-looking images. They should experiment with hyperparameters and discuss how they address issues such as mode collapse or training instability.\n",
    "\n",
    "- **Requirements:**\n",
    "  - Implement both generator and discriminator models using convolutional layers.\n",
    "  - Include training loops with appropriate loss functions.\n",
    "  - Submit generated images after 5, 20, and 50 epochs to showcase model improvement.\n",
    "  - Write a short report (500 words) discussing the challenges faced and results achieved.\n",
    "\n",
    "- **Learning Outcomes:** \n",
    "  - Develop proficiency in implementing GANs using PyTorch.\n",
    "  - Gain experience in training and tuning a DCGAN on a moderately complex dataset.\n",
    "  - Understand and address common issues in GAN training, such as mode collapse and unstable gradients.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Week 7: Introduction to NLP Basics\n",
    "- **Objectives**: Introduce the fundamentals of NLP, emphasizing text processing and classic NLP tasks.\n",
    "- **Topics**:\n",
    "  - Text preprocessing: Tokenization, stopword removal, stemming, and lemmatization.\n",
    "  - Basic NLP tasks: Text classification, sentiment analysis, and named entity recognition (NER).\n",
    "  - Practical: Hands-on practice using libraries like NLTK, spaCy, and Hugging Face's tokenizers.\n",
    "- **Assignment**: Implement basic text classification or sentiment analysis using traditional ML models (like Logistic Regression or Naive Bayes).\n",
    "- **Resources**:\n",
    "  - **NLTK Book (Chapter 1-3)**: [http://www.nltk.org/book/](http://www.nltk.org/book/)\n",
    "  - **spaCy Documentation**: [https://spacy.io/usage/spacy-101](https://spacy.io/usage/spacy-101)\n",
    "  - **Hugging Face Course (Section 1)**: [https://huggingface.co/course/chapter1](https://huggingface.co/course/chapter1)\n",
    "\n",
    "### Week 8: Word Embeddings and Representation Learning\n",
    "- **Objectives**: Understand how words are represented numerically in NLP models.\n",
    "- **Topics**:\n",
    "  - Word embeddings: Word2Vec, GloVe, and FastText.\n",
    "  - Limitations of traditional embeddings.\n",
    "  - Introduction to contextual embeddings and the shift towards transformers.\n",
    "- **Practical**: Hands-on session on creating and visualizing word embeddings using Word2Vec or GloVe.\n",
    "- **Assignment**: Compare the effectiveness of traditional word embeddings in a classification or NER task.\n",
    "- **Resources**:\n",
    "  - **Word2Vec Tutorial by Chris McCormick**: [https://mccormickml.com/2016/04/19/word2vec-tutorial-the-skip-gram-model/](https://mccormickml.com/2016/04/19/word2vec-tutorial-the-skip-gram-model/)\n",
    "  - **GloVe Project Page**: [https://nlp.stanford.edu/projects/glove/](https://nlp.stanford.edu/projects/glove/)\n",
    "  - **Towards Data Science - Word Embeddings**: [https://towardsdatascience.com/deep-learning-based-word-embeddings-df7cf53d72dd](https://towardsdatascience.com/deep-learning-based-word-embeddings-df7cf53d72dd)\n",
    "\n",
    "### Week 9: Transition to Transformers and Self-Attention Mechanism\n",
    "- **Objectives**: Understand the limitations of traditional RNN-based models and why transformers are used.\n",
    "- **Topics**:\n",
    "  - Overview of self-attention and multi-head attention mechanisms.\n",
    "  - Structure of the Transformer model (encoder-decoder architecture).\n",
    "  - Advantages over RNNs and CNNs in NLP tasks.\n",
    "- **Practical**: Hands-on implementation of self-attention on a small dataset to visualize attention weights.\n",
    "- **Assignment**: Implement a simplified version of self-attention or visualize attention weights on a text dataset.\n",
    "- **Resources**:\n",
    "  - **The Illustrated Transformer**: [https://jalammar.github.io/illustrated-transformer/](https://jalammar.github.io/illustrated-transformer/)\n",
    "  - **Attention Is All You Need Paper**: [https://arxiv.org/abs/1706.03762](https://arxiv.org/abs/1706.03762)\n",
    "  - **Stanford CS224n Lecture Videos**: [https://www.youtube.com/playlist?list=PLoROMvodv4rOhcuXMZkNm7j3fVwBBY42z](https://www.youtube.com/playlist?list=PLoROMvodv4rOhcuXMZkNm7j3fVwBBY42z)\n",
    "\n",
    "### Week 10: Introduction to Pre-trained Transformers and Fine-Tuning (BERT, RoBERTa)\n",
    "- **Objectives**: Familiarize students with popular pre-trained transformer models and fine-tuning approaches.\n",
    "- **Topics**:\n",
    "  - Overview of BERT, RoBERTa, and their variants.\n",
    "  - Fine-tuning pre-trained models for specific NLP tasks.\n",
    "  - Introduction to transfer learning in NLP.\n",
    "- **Practical**: Hands-on fine-tuning of a BERT model for text classification or sentiment analysis using Hugging Face’s Transformers library.\n",
    "- **Assignment**: Fine-tune a BERT-based model on a custom or public text dataset and evaluate its performance.\n",
    "- **Resources**:\n",
    "  - **Hugging Face Transformers Course (Chapters 2-3)**: [https://huggingface.co/course/chapter3](https://huggingface.co/course/chapter3)\n",
    "  - **BERT Explained by Jay Alammar**: [https://jalammar.github.io/bert-explained/](https://jalammar.github.io/bert-explained/)\n",
    "  - **Google’s BERT Paper**: [https://arxiv.org/abs/1810.04805](https://arxiv.org/abs/1810.04805)\n",
    "\n",
    "### Week 11: Advanced NLP Tasks with Transformers\n",
    "- **Objectives**: Explore more complex NLP tasks using transformers.\n",
    "- **Topics**:\n",
    "  - Question Answering (QA) with BERT and other transformer models.\n",
    "  - Named Entity Recognition (NER) with transformers.\n",
    "  - Sequence-to-sequence tasks like summarization and translation (introduction to T5 or BART).\n",
    "- **Practical**: Fine-tuning a QA model using the SQuAD dataset and exploring NER tasks.\n",
    "- **Assignment**: Choose one advanced NLP task (QA, NER, summarization) and fine-tune a transformer model to perform it.\n",
    "- **Resources**:\n",
    "  - **Question Answering with Transformers (Hugging Face Blog)**: [https://huggingface.co/blog/how-to-train](https://huggingface.co/blog/how-to-train)\n",
    "  - **Sequence-to-Sequence Models (Medium)**: [https://towardsdatascience.com/transformer-models-for-seq2seq-39928f2dbe6e](https://towardsdatascience.com/transformer-models-for-seq2seq-39928f2dbe6e)\n",
    "  - **Fine-tuning with SQuAD Dataset (Colab Notebook)**: [https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/question_answering.ipynb](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/question_answering.ipynb)\n",
    "\n",
    "### Week 12: Transformers in Action – Practical Applications and Advanced Techniques\n",
    "- **Objectives**: Wrap up with hands-on projects and exposure to state-of-the-art advancements.\n",
    "- **Topics**:\n",
    "  - Introduction to GPT-3, DALL-E, and recent transformer-based architectures (like DeBERTa, T5, etc.).\n",
    "  - Ethical considerations and real-world applications of large-scale language models.\n",
    "  - Project planning and development guidance.\n",
    "- **Practical**: Start a mini-project using Hugging Face models or an end-to-end task using transfer learning.\n",
    "- **Assignment**: Complete the mini-project and prepare a report showcasing the task, model choice, results, and future improvements.\n",
    "- **Resources**:\n",
    "  - **GPT-3 and Beyond (OpenAI Blog)**: [https://openai.com/research/gpt-3](https://openai.com/research/gpt-3)\n",
    "  - **Hugging Face Inference API**: [https://huggingface.co/inference-api](https://huggingface.co/inference-api)\n",
    "  - **Ethics and AI (Stanford Encyclopedia of Philosophy)**: [https://plato.stanford.edu/entries/ethics-ai/](https://plato.stanford.edu/entries/ethics-ai/)\n",
    "\n",
    "### Key Tips:\n",
    "- **Emphasize Practice**: Each week should have hands-on coding sessions using Jupyter notebooks, focusing on applying what was learned in lectures.\n",
    "- **Use Pre-trained Models**: Hugging Face Transformers library offers easy access to a wide variety of pre-trained models. Encourage students to experiment with fine-tuning rather than building models from scratch.\n",
    "- **Encourage Experimentation**: Motivate students to try different tasks and datasets beyond the assignments, helping them explore and understand the flexibility of transformers.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 2 NLP - Anatomy of Transformers (Self-Attention)\n",
    "\n",
    "## Objectives / Topics\n",
    "\n",
    "## Readings / Videos\n",
    "* NLP Book Chapter 3\n",
    "* Notebook about Math Sequences from MTH 480\n",
    "* Animated Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Week 7: Introduction to Transformers and Attention Mechanisms\n",
    "\n",
    "**Objectives:**\n",
    "\n",
    "1. **Principles of Attention Mechanisms**:\n",
    "   - Understand the theoretical foundations and principles of attention mechanisms in neural networks.\n",
    "   - Learn how attention mechanisms improve the performance of neural networks by allowing the model to focus on relevant parts of the input data.\n",
    "\n",
    "2. **Transformer Architecture**:\n",
    "   - Comprehend the architecture of transformer models, including components such as multi-head attention, positional encoding, and feed-forward networks.\n",
    "   - Explore the advantages of transformers over traditional RNNs and CNNs, particularly in handling sequential data and long-range dependencies.\n",
    "\n",
    "3. **Applications of Transformers**:\n",
    "   - Discover the various applications of transformer models in computer vision and natural language processing.\n",
    "   - Learn about specific use cases such as image classification, language translation, and text summarization using transformers.\n",
    "\n",
    "4. **Hands-on Implementation**:\n",
    "   - Implement a simple transformer model using PyTorch.\n",
    "   - Apply attention mechanisms within a convolutional neural network (CNN) and evaluate their impact on performance.\n",
    "\n",
    "5. **Sequence-to-Sequence Learning**:\n",
    "   - Understand the sequence-to-sequence (Seq2Seq) paradigm and its application in tasks like machine translation and arithmetic prediction.\n",
    "   - Implement a Seq2Seq example to predict sums of three or four-digit numbers, demonstrating the practical use of transformers in handling sequential data.\n",
    "\n",
    "These learning objectives aim to provide a thorough understanding of attention mechanisms and transformer models, along with practical skills in implementing and applying these concepts using PyTorch.\n",
    "\n",
    "**Lecture Topics:**\n",
    "- Introduction to attention mechanisms\n",
    "- Overview of transformer architecture\n",
    "- Applications of transformers in computer vision\n",
    "- Sequence to Sequence example - predicting sums of three or four digit numbers\n",
    "\n",
    "**Activities:**\n",
    "- Implementing attention mechanisms in a CNN\n",
    "- Exploring transformer-based models for image classification\n",
    "\n",
    "**Assessments:**\n",
    "- Quiz on attention mechanisms and transformers\n",
    "- Homework: Implement a transformer model for image classification\n",
    "\n",
    "**Textbook Support:**\n",
    "- Chapter 12: Transformers\n",
    "\n",
    "**Video Lectures:**\n",
    "- [Attention Mechanisms in Neural Networks](https://www.youtube.com/watch?v=Wwkvz-_6XAo) - Introduction to attention mechanisms.\n",
    "- [Transformers Explained](https://www.youtube.com/watch?v=U0s0f995w14) - Detailed video on transformer architecture.\n",
    "\n",
    "**Tutorials:**\n",
    "- [Implementing Attention Mechanisms](https://www.youtube.com/watch?v=BR9h47Jtqyw) - Coding attention mechanisms in neural networks.\n",
    "\n",
    "**Other Resources:**\n",
    "- [The Illustrated Transformer](https://jalammar.github.io/illustrated-transformer/)\n",
    "\n",
    "---\n",
    "#### Week 8: Introduction to Hugging Face and Transformers\n",
    "\n",
    "**Objectives:**\n",
    "\n",
    "1. **Introduction to Hugging Face Library**:\n",
    "   - Understand the purpose and features of the Hugging Face library.\n",
    "   - Explore the different components and tools provided by Hugging Face for natural language processing (NLP) tasks.\n",
    "\n",
    "2. **Pre-trained Transformer Models**:\n",
    "   - Learn about pre-trained transformer models and their advantages in NLP applications.\n",
    "   - Understand how to leverage pre-trained models for various tasks, reducing the need for extensive training from scratch.\n",
    "\n",
    "3. **Implementing Transformer Models with Hugging Face**:\n",
    "   - Gain hands-on experience in implementing a simple transformer model using the Hugging Face library.\n",
    "   - Learn how to fine-tune a pre-trained transformer model on a specific dataset to improve its performance for a particular task.\n",
    "\n",
    "4. **Exploring Hugging Face Documentation and Tutorials**:\n",
    "   - Navigate and utilize the Hugging Face documentation to understand the usage of different functions and classes.\n",
    "   - Follow tutorials to build practical skills in working with the Hugging Face library.\n",
    "\n",
    "**Lecture Topics:**\n",
    "- Overview of Hugging Face library\n",
    "- Pre-trained transformer models\n",
    "\n",
    "**Activities:**\n",
    "- Exploring Hugging Face documentation and tutorials\n",
    "- Implementing a simple transformer model using Hugging Face\n",
    "\n",
    "**Assessments:**\n",
    "\n",
    "1. **Quiz on Hugging Face Basics**:\n",
    "   - Assess students' understanding of the Hugging Face library's components, tools, and functionalities.\n",
    "   - Include questions on the advantages of using pre-trained transformer models and the process of fine-tuning them.\n",
    "\n",
    "2. **Homework: Fine-tune a Pre-trained Transformer Model Using Hugging Face**:\n",
    "   - Provide a dataset and instructions for fine-tuning a pre-trained transformer model using the Hugging Face library.\n",
    "   - Evaluate the students' ability to apply the concepts learned in class to customize a model for a specific task and assess its performance.\n",
    "\n",
    "**Textbook Support:**\n",
    "- Chapter 1: Hello Transformers\n",
    "- Chapter 2: Text Classification\n",
    "\n",
    "**Video Lectures:**\n",
    "- [Introduction to Hugging Face Transformers](https://www.youtube.com/watch?v=kXg8iE0pBwE) - Overview of Hugging Face library.\n",
    "- [Using Pre-trained Models in Hugging Face](https://www.youtube.com/watch?v=M1CBQS9xHB8) - Tutorial on leveraging pre-trained models.\n",
    "\n",
    "**Online Courses:**\n",
    "- [Hugging Face Course](https://huggingface.co/course/chapter1) - Free course on transformers and Hugging Face library.\n",
    "\n",
    "---\n",
    "\n",
    "#### Week 9: Advanced Transformer Models for NLP\n",
    "\n",
    "**Lecture Topics:**\n",
    "- BERT, GPT, and other advanced transformer models\n",
    "- Applications of transformers in NLP\n",
    "\n",
    "**Activities:**\n",
    "- Fine-tuning BERT for text classification\n",
    "- Implementing a text generation model using GPT\n",
    "\n",
    "**Assessments:**\n",
    "- Quiz on advanced transformer models\n",
    "- Homework: Experiment with different transformer models for a specific NLP task\n",
    "\n",
    "**Textbook Support:**\n",
    "- Chapter 3: Transformer Anatomy\n",
    "- Chapter 5: Text Generation\n",
    "\n",
    "**Video Lectures:**\n",
    "- [BERT Explained](https://www.youtube.com/watch?v=8kLLg54h7fQ) - Detailed explanation of BERT model.\n",
    "- [GPT-3: Language Models are Few-Shot Learners](https://www.youtube.com/watch?v=zmv5MIlksg8) - Overview of GPT-3.\n",
    "\n",
    "**Tutorials:**\n",
    "- [Fine-Tuning BERT for Text Classification](https://www.youtube.com/watch?v=ehjewW0e1a8) - Step-by-step guide to fine-tuning BERT.\n",
    "\n",
    "\n",
    "#### Week 10: NLP Applications and Transfer Learning with Transformers\n",
    "\n",
    "**Objectives:**\n",
    "\n",
    "1. **Understanding Transfer Learning in NLP**:\n",
    "   - Comprehend the concept of transfer learning and its significance in natural language processing (NLP).\n",
    "   - Learn how pre-trained transformer models can be fine-tuned for specific NLP tasks to improve performance and reduce training time.\n",
    "\n",
    "2. **Applications of Transformers in NLP**:\n",
    "   - Explore various NLP tasks where transformers are applied, such as sentiment analysis, named entity recognition (NER), text classification, and more.\n",
    "   - Understand the benefits and challenges of using transformers in different NLP applications.\n",
    "\n",
    "3. **Sentiment Analysis with Transformers**:\n",
    "   - Implement a sentiment analysis model using pre-trained transformers and the Hugging Face library.\n",
    "   - Learn how to preprocess data, fine-tune the model, and evaluate its performance on a sentiment analysis task.\n",
    "\n",
    "4. **Named Entity Recognition (NER) Using Hugging Face Models**:\n",
    "   - Understand the principles of named entity recognition and its importance in extracting structured information from text.\n",
    "   - Implement an NER model using Hugging Face's pre-trained transformers and fine-tune it for a specific dataset.\n",
    "\n",
    "**Lecture Topics:**\n",
    "- Transfer learning in NLP\n",
    "- Applications of transformers in various NLP tasks\n",
    "\n",
    "**Activities:**\n",
    "- Sentiment analysis with transformers\n",
    "- Named entity recognition using Hugging Face models\n",
    "\n",
    "**Assessments:**\n",
    "1. **Quiz on NLP Applications**:\n",
    "   - Assess students' understanding of the concepts and applications of transformers in various NLP tasks.\n",
    "   - Include questions on transfer learning, sentiment analysis, named entity recognition, and other NLP applications discussed in the lectures.\n",
    "\n",
    "2. **Homework: Develop an NLP Application Using Hugging Face**:\n",
    "   - **Assignment Details**:\n",
    "     - Provide students with a dataset for an NLP task such as sentiment analysis, named entity recognition, or text classification.\n",
    "     - Instruct students to choose an appropriate pre-trained transformer model from the Hugging Face library.\n",
    "     - Guide students through the process of fine-tuning the chosen model on the provided dataset, including data preprocessing, model training, and evaluation.\n",
    "     - Require students to submit a report detailing their approach, the model's performance metrics, and any challenges encountered during the implementation.\n",
    "\n",
    "   - **Evaluation Criteria**:\n",
    "     - **Correctness**: Ensure the students have correctly implemented the fine-tuning process and the model functions as expected.\n",
    "     - **Performance**: Evaluate the performance of the model based on metrics appropriate for the task (e.g., accuracy, F1 score, precision, recall).\n",
    "     - **Clarity**: Assess the clarity and comprehensiveness of the report, including explanations of the chosen approach, data preprocessing steps, and evaluation results.\n",
    "     - **Innovation**: Give additional credit for innovative approaches or optimizations that improve the model's performance or efficiency.\n",
    "\n",
    "**Textbook Support:**\n",
    "- Chapter 13: Transfer Learning\n",
    "- Chapter 4: Multilingual Named Entity Recognition\n",
    "\n",
    "**Video Lectures:**\n",
    "- [Applications of Transformers in NLP](https://www.youtube.com/watch?v=UnxcYRNBMIw) - Use cases of transformers in NLP.\n",
    "- [Transfer Learning in NLP](https://www.youtube.com/watch?v=ViDLgkHh0Pw) - Practical guide to transfer learning in NLP.\n",
    "\n",
    "**Tutorials:**\n",
    "- [Sentiment Analysis with Transformers](https://www.youtube.com/watch?v=nXZp759E2-Y) - Implementing sentiment analysis using Hugging Face models.\n",
    "\n",
    "---\n",
    "### Week 11: Advanced Techniques in NLP with Transformers\n",
    "\n",
    "**Objectives:**\n",
    "\n",
    "1. **Fine-Tuning NLP Models**:\n",
    "   - Understand the principles and techniques of fine-tuning pre-trained transformer models for specific NLP tasks.\n",
    "   - Learn how to adjust model parameters and hyperparameters to optimize performance for a custom dataset.\n",
    "\n",
    "2. **Optimization Strategies**:\n",
    "   - Explore advanced optimization strategies to enhance the performance and efficiency of NLP models.\n",
    "   - Understand techniques such as learning rate scheduling, gradient clipping, and mixed precision training.\n",
    "\n",
    "3. **Advanced NLP Techniques**:\n",
    "   - Implement advanced NLP techniques using transformers, such as text summarization, question answering, and sequence-to-sequence learning.\n",
    "   - Learn how to apply transfer learning to solve complex NLP tasks.\n",
    "\n",
    "4. **Practical Implementation Skills**:\n",
    "   - Gain hands-on experience in fine-tuning a transformer model on a custom NLP dataset using the Hugging Face library.\n",
    "   - Develop skills in debugging and troubleshooting issues that arise during the fine-tuning process.\n",
    "\n",
    "**Assessments:**\n",
    "\n",
    "1. **Quiz on Advanced NLP Techniques**:\n",
    "   - **Quiz Content**:\n",
    "     - Assess students' understanding of fine-tuning techniques and optimization strategies for transformer models.\n",
    "     - Include questions on advanced NLP applications such as text summarization, question answering, and sequence-to-sequence tasks.\n",
    "     - Test knowledge of specific methods for improving model efficiency and performance.\n",
    "\n",
    "   - **Evaluation Criteria**:\n",
    "     - Correctness of answers regarding key concepts and techniques.\n",
    "     - Ability to apply theoretical knowledge to practical scenarios.\n",
    "\n",
    "2. **Homework: Fine-Tune an NLP Model for a Custom Task**:\n",
    "   - **Assignment Details**:\n",
    "     - Provide students with a custom NLP dataset related to tasks such as text summarization, question answering, or another advanced NLP application.\n",
    "     - Instruct students to select an appropriate pre-trained transformer model from the Hugging Face library.\n",
    "     - Guide students through the process of fine-tuning the model on the provided dataset, including data preprocessing, model training, and performance evaluation.\n",
    "     - Require students to submit a report detailing their approach, the fine-tuning process, the model's performance metrics, and any challenges encountered during implementation.\n",
    "\n",
    "   - **Evaluation Criteria**:\n",
    "     - **Correctness**: Ensure the students have correctly implemented the fine-tuning process and the model functions as expected.\n",
    "     - **Performance**: Evaluate the performance of the model based on metrics appropriate for the task (e.g., ROUGE score for summarization, accuracy for question answering).\n",
    "     - **Clarity**: Assess the clarity and comprehensiveness of the report, including explanations of the chosen approach, data preprocessing steps, fine-tuning process, and evaluation results.\n",
    "     - **Innovation**: Give additional credit for innovative approaches or optimizations that improve the model's performance or efficiency.\n",
    "\n",
    "**Textbook Support:**\n",
    "- Chapter 6: Summarization\n",
    "- Chapter 8: Making Transformers Efficient in Production\n",
    "\n",
    "**Video Lectures:**\n",
    "- [Fine-Tuning and Optimizing NLP Models](https://www.youtube.com/watch?v=iwjyOzLWB6Q) - Advanced techniques for fine-tuning NLP models.\n",
    "- [Advanced NLP with Transformers](https://www.youtube.com/watch?v=UnxcYRNBMIw) - Further insights into advanced NLP techniques.\n",
    "\n",
    "**Tutorials:**\n",
    "- [Fine-Tuning a Transformer for a Custom NLP Dataset](https://www.youtube.com/watch?v=viTL3ghJfZQ) - Practical guide to fine-tuning transformers for custom tasks.\n",
    "\n",
    "---\n",
    "### Week 12: Retrieval-Augmented Generation (RAG) with Large Language Models (LLMs)\n",
    "\n",
    "**Objectives:**\n",
    "\n",
    "1. **Understanding Retrieval-Augmented Generation (RAG)**:\n",
    "   - Comprehend the concept and significance of Retrieval-Augmented Generation in enhancing the capabilities of large language models (LLMs).\n",
    "   - Learn about the key components of RAG: the retriever, the generator, and their integration.\n",
    "\n",
    "2. **Key Components and Workflow**:\n",
    "   - Understand the role of the retriever in retrieving relevant documents or passages based on a query.\n",
    "   - Understand the role of the generator in generating contextually accurate and relevant responses.\n",
    "   - Learn how the retriever and generator work together to form a RAG pipeline.\n",
    "\n",
    "3. **Applications of RAG**:\n",
    "   - Explore various applications of RAG in NLP tasks such as question answering, text summarization, and more.\n",
    "   - Analyze real-world use cases where RAG has been effectively implemented.\n",
    "\n",
    "4. **Implementing RAG Models**:\n",
    "   - Gain hands-on experience in implementing a basic RAG model using Hugging Face Transformers.\n",
    "   - Learn how to set up a retriever and generator and integrate them to form a complete RAG pipeline.\n",
    "   - Experiment with applying RAG to specific tasks like question answering.\n",
    "\n",
    "**Assessments:**\n",
    "\n",
    "1. **Quiz on RAG Concepts and Implementation**:\n",
    "   - **Quiz Content**:\n",
    "     - Assess students' understanding of the principles and components of RAG.\n",
    "     - Include questions on the roles of the retriever and generator, their integration, and the workflow of a RAG pipeline.\n",
    "     - Test knowledge on applications of RAG in various NLP tasks.\n",
    "\n",
    "   - **Evaluation Criteria**:\n",
    "     - Correctness of answers regarding the concepts and components of RAG.\n",
    "     - Ability to explain the workflow and applications of RAG.\n",
    "\n",
    "2. **Homework: Develop a Simple RAG-Based Application Using Hugging Face**:\n",
    "   - **Assignment Details**:\n",
    "     - Provide students with a specific NLP task, such as question answering or text summarization.\n",
    "     - Instruct students to choose appropriate datasets and pre-trained models from the Hugging Face library.\n",
    "     - Guide students through setting up a retriever to fetch relevant documents or passages based on the given task.\n",
    "     - Instruct students to configure a generator to produce responses or summaries based on the retrieved information.\n",
    "     - Require students to integrate the retriever and generator to form a complete RAG pipeline.\n",
    "     - Ask students to submit a report detailing their approach, the integration process, performance metrics, and any challenges encountered.\n",
    "\n",
    "   - **Evaluation Criteria**:\n",
    "     - **Correctness**: Ensure students have correctly implemented the RAG pipeline and the components work as expected.\n",
    "     - **Performance**: Evaluate the performance of the RAG model based on metrics appropriate for the task (e.g., accuracy for question answering, ROUGE score for summarization).\n",
    "     - **Clarity**: Assess the clarity and comprehensiveness of the report, including explanations of the chosen approach, the integration process, and evaluation results.\n",
    "     - **Innovation**: Give additional credit for innovative approaches or optimizations that improve the model's performance or efficiency.\n",
    "\n",
    "**Textbook Support:**\n",
    "\n",
    "**Video Lectures:**\n",
    "- [LangChain: Chat with Your Data](https://www.deeplearning.ai/short-courses/langchain-chat-with-your-data/) Use LangChain and RAG to build a chatbot that understands the context from your documents.\n",
    "\n",
    "---\n",
    "#### Weeks 13-14: Project Weeks\n",
    "\n",
    "**Lecture Topics:**\n",
    "- Project planning and development\n",
    "- Final project presentations\n",
    "\n",
    "**Activities:**\n",
    "- Work on final projects\n",
    "- Present and critique final projects\n",
    "\n",
    "**Assessments:**\n",
    "- Final project presentations and reports\n",
    "\n",
    "**Project Options:**\n",
    "- **Computer Vision Project:**\n",
    "  - Task: Build and fine-tune a CNN or Vision Transformer (ViT) for image classification.\n",
    "  - Dataset: CIFAR-10, MNIST, or any accessible image dataset.\n",
    "  - Resources: Google Colab, free datasets, PyTorch, Hugging Face Transformers.\n",
    "- **NLP Project:**\n",
    "  - Task: Develop an NLP application using transformers (e.g., text classification, named entity recognition, sentiment analysis).\n",
    "  - Dataset: IMDb reviews, AG News, or any accessible text dataset.\n",
    "  - Resources: Google Colab, free datasets, Hugging Face Transformers.\n",
    "\n",
    "**Project Planning and Development Resources:**\n",
    "- [Guidelines for Planning Machine Learning Projects](https://www.youtube.com/watch?v=9SZ2tQkQDww) - Tips on planning and executing ML projects.\n",
    "- [Google Colab Tutorials](https://www.youtube.com/watch?v=inN8seMm7UI) - Getting started with Google Colab for your projects.\n",
    "\n",
    "**Computer Vision Project:**\n",
    "- [Building and Fine-Tuning a CNN](https://www.youtube.com/watch?v=oK7Fi8gL3GA) - Tutorial on building and fine-tuning a CNN.\n",
    "- [Vision Transformers (ViT) Tutorial](https://www.youtube.com/watch?v=1q3LEadIk3I) - Implementing ViT for image classification.\n",
    "\n",
    "**NLP Project:**\n",
    "- [Developing an NLP Application with Transformers](https://www.youtube.com/watch?v=ehjewW0e1a8) - Tutorial on building an NLP application using Hugging Face transformers.\n",
    "- [Named Entity Recognition with Transformers](https://www.youtube.com/watch?v=3wvFL6D53AY) - Step-by-step guide to implementing NER.\n",
    "\n",
    "**Miscellaneous Resources for Part 2**\n",
    " \n",
    "https://youtu.be/SZorAJ4I-sA?si=WSvlE5EDSM0lcSO9\n",
    "\n",
    "https://youtu.be/bCz4OMemCcA?si=O0JG_SIfLDCIAZ6I\n",
    "https://youtu.be/90mGPxR2GgY?si=zVvGBy3yPWm6VJ2N\n",
    "(These videos by Umar Jamil are very good)\n",
    "\n",
    "https://bbycroft.net/llm\n",
    "https://huggingface.co/spaces/exbert-project/exbert\n",
    "https://arxiv.org/pdf/1910.05276\n",
    "\n",
    "https://youtu.be/t45S_MwAcOw?si=jHgwRAEKZDsOW3xi\n",
    " \n",
    "Hugging Face encoder/decode videos\n",
    "\n",
    "https://youtu.be/MUqNwgPjJvQ?si=e2lFDk1gjgOluStP\n",
    "https://youtu.be/d_ixlCubqQw?si=x88NFT7Ce0MgKu0M\n",
    "\n",
    "This one by Jeremy Howard has lots of good ideas. I often show the video from the 17:21 mark for weaker audiences:\n",
    "https://youtu.be/jkrNMKz9pWU?si=-gdapXOPSY5S0Ikz\n",
    "\n",
    "And of course the 3Blue1Brown videos are superb\n",
    "https://youtu.be/wjZofJX0v4M?si=-hwfraw0EONYBuiC\n",
    "https://youtu.be/eMlx5fFNoYc?si=w5zr5VKyI70k_wcW\n",
    "\n",
    "Stuff on word embeddings like word2vec\n",
    "https://youtu.be/gQddtTdmG_8?si=4_L6tXrFiO5y7QXG\n",
    "https://youtu.be/f7o8aDNxf7k?si=rmfwG4GrM_FSM1zi\n",
    "\n",
    "This one is long, but Manning is a genius\n",
    "https://youtu.be/ERibwqs9p38?si=YbYUWjUf1Rf0U7Qz\n",
    "\n",
    "A Turing Lecture about generative AI for general audiences:\n",
    "https://youtu.be/fwaDtRbfioU?si=W_UxNiB5\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "def embed_youtube_video(video_id):\n",
    "    \"\"\"\n",
    "    Embed a YouTube video in a Jupyter Notebook and provide a link to open it in a new tab.\n",
    "    \n",
    "    Parameters:\n",
    "    video_id (str): The ID of the YouTube video.\n",
    "    \"\"\"\n",
    "    html_code = f\"\"\"\n",
    "    You can watch the video below or <a href=\"https://www.youtube.com/watch?v={video_id}\" target=\"_blank\">click here to open in a new tab</a>.<br>\n",
    "    <iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/{video_id}\" frameborder=\"0\" allowfullscreen></iframe>\n",
    "    \"\"\"\n",
    "    display(HTML(html_code))\n",
    "\n",
    "# Example usage:\n",
    "embed_youtube_video(\"dQw4w9WgXcQ\")\n",
    "\n",
    "# Embedding a YouTube Video with an External Link\n",
    "\n",
    "You can watch the video below or [click here to open in a new tab](https://www.youtube.com/watch?v=dQw4w9WgXcQ){target=\"_blank\"}.\n",
    "\n",
    "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/dQw4w9WgXcQ\" frameborder=\"0\" allowfullscreen></iframe>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources from Alex\n",
    "\n",
    "Stuff on word embeddings like word2vec\n",
    "https://youtu.be/gQddtTdmG_8?si=4_L6tXrFiO5y7QXG\n",
    "https://youtu.be/f7o8aDNxf7k?si=rmfwG4GrM_FSM1zi\n",
    "\n",
    "* [Transformers, explained: Understand the model behind GPT, BERT, and T5](https://youtu.be/SZorAJ4I-sA?si=WSvlE5EDSM0lcSO9) - Light video intro to Transformers from Google Cloud Tech\n",
    "* **Videos from Umar Jamil**\n",
    "    * [Attention is all you need (Transformer) - Model explanation (including math), Inference and Training](https://youtu.be/bCz4OMemCcA?si=O0JG_SIfLDCIAZ6I)\n",
    "    * [BERT explained: Training, Inference, BERT vs GPT/LLamA, Fine tuning, CLS token](https://youtu.be/90mGPxR2GgY?si=zVvGBy3yPWm6VJ2N)\n",
    "* [LLM Visualization](https://bbycroft.net/llm) Looks cool, but no audio?\n",
    "* [EXBERT - Interactive BERT Visualizer](https://huggingface.co/spaces/exbert-project/exbert)\n",
    "* [Paper - EXBERT: A Visual Analysis Tool to Explore Learned Representations in Transformers Models](https://arxiv.org/pdf/1910.05276)\n",
    "\n",
    "* [Video - Transformer models and BERT model: Overview](https://youtu.be/t45S_MwAcOw?si=jHgwRAEKZDsOW3xi) A solid explanation of encoder / decoder, but not super detailed.  More detail than the video at the top of this list.\n",
    "* Hugging Face encoder/decode videos\n",
    "    * [Encoders](https://youtu.be/MUqNwgPjJvQ?si=e2lFDk1gjgOluStP)\n",
    "    * [Decoders](https://youtu.be/d_ixlCubqQw?si=x88NFT7Ce0MgKu0M)\n",
    "\n",
    "* [A Hacker's Guide to Language Models by Jeremy Howard](https://youtu.be/jkrNMKz9pWU?si=-gdapXOPSY5S0Ikz) Consider starting at 17:21 for weaker audiences.\n",
    "    * For the notebook used in this talk, see https://github.com/fastai/lm-hackers.\n",
    "    * 00:00:00 Introduction & Basic Ideas of Language Models\n",
    "    * 00:18:05 Limitations & Capabilities of GPT-4\n",
    "    * 00:31:28 AI Applications in Code Writing, Data Analysis & OCR\n",
    "    * 00:38:50 Practical Tips on Using OpenAI API\n",
    "    * 00:46:36 Creating a Code Interpreter with Function Calling\n",
    "    * 00:51:57 Using Local Language Models & GPU Options\n",
    "    * 00:59:33 Fine-Tuning Models & Decoding Tokens\n",
    "    * 01:05:37 Testing & Optimizing Models\n",
    "    * 01:10:32 Retrieval Augmented Generation\n",
    "    * 01:20:08 Fine-Tuning Models\n",
    "    * 01:26:00 Running Models on Macs\n",
    "    * 01:27:42 Llama.cpp & Its Cross-Platform Abilities\n",
    "\n",
    "* the 3Blue1Brown videos are superb\n",
    "    * [The 3Blue1Brown Website](https://www.3blue1brown.com/topics/neural-networks)\n",
    "    * [How large language models work, a visual intro to transformers | Chapter 5, Deep Learning](https://youtu.be/wjZofJX0v4M?si=-hwfraw0EONYBuiC)\n",
    "    * [Attention in transformers, visually explained | Chapter 6, Deep Learning](https://youtu.be/eMlx5fFNoYc?si=w5zr5VKyI70k_wcW)\n",
    "* Chris Manning at Stanford (NLP Class)\n",
    "    * [Lecture 1 | Natural Language Processing with Deep Learning](https://www.youtube.com/watch?v=OQQ-W_63UgQ&ab_channel=StanfordUniversitySchoolofEngineering) The bit around 21:00 is a great explanation of machine learning vs deep learning.\n",
    "    * [Lecture 2 | Word Vector Representations: word2vec](https://youtu.be/ERibwqs9p38?si=YbYUWjUf1Rf0U7Qz) Probably too high level.\n",
    "* [Mirella Lapata Turing Lecture about Generative AI](https://youtu.be/fwaDtRbfioU?si=W_UxNiB5ZMGWRbHc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
