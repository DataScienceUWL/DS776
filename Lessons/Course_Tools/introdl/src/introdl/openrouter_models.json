{
  "models": {
    "claude-haiku": {
      "id": "anthropic/claude-3.5-haiku",
      "provider": "anthropic",
      "parameters": "~30-50B",
      "size": "~30-50B",
      "architecture": "dense",
      "release_date": "2024-10-22",
      "notes": "Commercial model, size estimated",
      "open_weights": false,
      "json_support": {
        "json_object": true,
        "json_schema": false,
        "strict_schema": false
      }
    },
    "gemini-flash-lite": {
      "id": "google/gemini-2.5-flash-lite",
      "provider": "google",
      "parameters": "~5B",
      "size": "~5B",
      "architecture": "dense",
      "release_date": "2025-09-25",
      "notes": "Commercial model, size estimated",
      "open_weights": false,
      "json_support": {
        "json_object": true,
        "json_schema": true,
        "strict_schema": true
      }
    },
    "gemini-flash": {
      "id": "google/gemini-2.5-flash",
      "provider": "google",
      "parameters": "~20B",
      "size": "~20B",
      "architecture": "dense",
      "release_date": "2025-04-17",
      "notes": "Commercial model, size estimated",
      "open_weights": false,
      "json_support": {
        "json_object": true,
        "json_schema": true,
        "strict_schema": true
      }
    },
    "gpt-4o-mini": {
      "id": "openai/gpt-4o-mini-2024-07-18",
      "provider": "openai",
      "parameters": "~8B",
      "size": "~8B",
      "architecture": "dense (possibly MoE)",
      "release_date": "2024-07-18",
      "notes": "Commercial model, size estimated",
      "open_weights": false,
      "json_support": {
        "json_object": true,
        "json_schema": true,
        "strict_schema": false
      }
    },
    "llama-3.2-1b": {
      "id": "meta-llama/llama-3.2-1b-instruct",
      "provider": "meta",
      "parameters": "1B",
      "size": "1B",
      "architecture": "dense",
      "release_date": "2024-09-25",
      "notes": "Open-weight model, efficient edge/mobile model, very affordable",
      "open_weights": true,
      "json_support": {
        "json_object": true,
        "json_schema": false,
        "strict_schema": false
      }
    },
    "llama-3.2-3b": {
      "id": "meta-llama/llama-3.2-3b-instruct",
      "provider": "meta",
      "parameters": "3B",
      "size": "3B",
      "architecture": "dense",
      "release_date": "2024-09-25",
      "notes": "Open-weight model, very affordable (~$0.018/M), outperforms Gemma 2.6B and Phi 3.5-mini on NLP tasks",
      "open_weights": true,
      "json_support": {
        "json_object": true,
        "json_schema": false,
        "strict_schema": false
      }
    },
    "llama-3.3-70b": {
      "id": "meta-llama/llama-3.3-70b-instruct",
      "provider": "meta",
      "parameters": "70B",
      "size": "70B",
      "architecture": "dense",
      "release_date": "2024-12-06",
      "notes": "Open-weight model",
      "open_weights": true,
      "json_support": {
        "json_object": true,
        "json_schema": true,
        "strict_schema": true
      }
    },
    "llama-4-maverick": {
      "id": "meta-llama/llama-4-maverick",
      "provider": "meta",
      "parameters": "17B active, 128 experts",
      "size": "17B×128E",
      "architecture": "MoE",
      "release_date": "2025-04-05",
      "notes": "Open-weight model, Llama 4 experimental release with MoE architecture",
      "open_weights": true,
      "json_support": {
        "json_object": true,
        "json_schema": true,
        "strict_schema": true
      }
    },
    "gemma-3-12b": {
      "id": "google/gemma-3-12b-it",
      "provider": "google",
      "parameters": "12B",
      "size": "12B",
      "architecture": "dense",
      "release_date": "2025-03-12",
      "notes": "Open-weight model, Google Gemma 3 instruction-tuned",
      "open_weights": true,
      "json_support": {
        "json_object": true,
        "json_schema": true,
        "strict_schema": true
      }
    },
    "gemma-3-27b": {
      "id": "google/gemma-3-27b-it",
      "provider": "google",
      "parameters": "27B",
      "size": "27B",
      "architecture": "dense",
      "release_date": "2025-03-12",
      "notes": "Open-weight model, Google Gemma 3 instruction-tuned",
      "open_weights": true,
      "json_support": {
        "json_object": true,
        "json_schema": true,
        "strict_schema": true
      }
    },
    "mistral-nemo": {
      "id": "mistralai/mistral-nemo",
      "provider": "mistral",
      "parameters": "12B",
      "size": "12B",
      "architecture": "dense",
      "release_date": "2024-07-18",
      "notes": "Open-weight model, efficient small model",
      "open_weights": true,
      "json_support": {
        "json_object": true,
        "json_schema": true,
        "strict_schema": true
      }
    },
    "mistral-medium": {
      "id": "mistralai/mistral-medium-3",
      "provider": "mistral",
      "parameters": "~60-80B",
      "size": "~60-80B",
      "architecture": "dense",
      "release_date": "2025-05-07",
      "notes": "Open-weight model, size estimated",
      "open_weights": true,
      "json_support": {
        "json_object": true,
        "json_schema": true,
        "strict_schema": true
      }
    },
    "qwen3-32b": {
      "id": "qwen/qwen3-32b",
      "provider": "qwen",
      "parameters": "32B",
      "size": "32B",
      "architecture": "dense",
      "release_date": "2025-04-29",
      "notes": "Open-weight model, latest Qwen3 generation (April 2025)",
      "open_weights": true,
      "json_support": {
        "json_object": true,
        "json_schema": true,
        "strict_schema": true
      }
    },
    "deepseek-v3.1": {
      "id": "deepseek/deepseek-chat-v3.1",
      "provider": "deepseek",
      "parameters": "671B total, 37B active",
      "size": "37B×18E",
      "architecture": "MoE",
      "release_date": "2025-08-21",
      "notes": "Open-weight model, hybrid reasoning model with reasoning disabled for faster/cheaper responses",
      "open_weights": true,
      "json_support": {
        "json_object": true,
        "json_schema": true,
        "strict_schema": true
      }
    },
    "gpt-oss-20b": {
      "id": "openai/gpt-oss-20b",
      "provider": "openai",
      "parameters": "21B total, 3.6B active",
      "size": "3.6B×6E",
      "architecture": "MoE (4-bit quantized MXFP4)",
      "release_date": "2025-08-05",
      "notes": "Open-weight model, Apache 2.0 license, runs on 16GB memory",
      "open_weights": true,
      "json_support": {
        "json_object": true,
        "json_schema": false,
        "strict_schema": false
      }
    },
    "gpt-oss-120b": {
      "id": "openai/gpt-oss-120b",
      "provider": "openai",
      "parameters": "117B total, 5.1B active",
      "size": "5.1B×23E",
      "architecture": "MoE (4-bit quantized MXFP4)",
      "release_date": "2025-08-05",
      "notes": "Open-weight model, Apache 2.0 license, competitive with o4-mini, runs on 80GB GPU, JSON support unreliable",
      "open_weights": true,
      "json_support": {
        "json_object": true,
        "json_schema": false,
        "strict_schema": false
      }
    }
  },
  "default_model": "gemini-flash-lite",
  "cost_warning_thresholds": [
    0.5,
    0.75,
    0.9
  ],
  "student_credit_limit": 15.0,
  "description": "OpenRouter model configurations for DS776 NLP lessons. Using commercial models (Claude, Gemini, GPT) and affordable open-weight models (Meta Llama, Google Gemma, Mistral, Qwen, Deepseek). Includes model metadata, JSON capability data, release dates, and open-weights status.",
  "last_updated": "2025-10-09"
}
