{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DS776 Auto-Update (runs in ~2 seconds, only updates when needed)\n",
    "# If this cell fails, see Lessons/Course_Tools/AUTO_UPDATE_SYSTEM.md for help\n",
    "%run ../../Lessons/Course_Tools/auto_update_introdl.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 02 Assignment\n",
    "**Name:** [Student Name Here]  \n",
    "**Total Points:** 50\n",
    "\n",
    "## Submission Checklist\n",
    "- [ ] All code cells executed with output saved\n",
    "- [ ] All questions answered\n",
    "- [ ] Notebook converted to HTML (use the Homework_02_Utilities notebook)\n",
    "- [ ] Canvas notebook filename includes `_GRADE_THIS_ONE`\n",
    "- [ ] Files uploaded to Canvas\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FashionMNIST Classification with CNNs\n",
    "\n",
    "In this notebook you'll explore, train, and evaluate models on the FashionMNIST dataset. FashionMNIST was set up as a more difficult drop-in replacement for MNIST.\n",
    "\n",
    "For this assignment you'll want to use a CoCalc compute server with GPU. Make sure you've watched the video at the beginning of the lesson about compute servers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === YOUR IMPORTS HERE ===\n",
    "# Add any additional imports you need below this line\n",
    "\n",
    "\n",
    "from introdl.utils import config_paths_keys\n",
    "\n",
    "# Configure paths\n",
    "paths = config_paths_keys()\n",
    "DATA_PATH = paths['DATA_PATH']\n",
    "MODELS_PATH = paths['MODELS_PATH']\n",
    "# === END YOUR IMPORTS ==="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [5 pts] Warmup\n",
    "\n",
    "Train LeNet5Rev on FashionMNIST and evaluate the performance on the test set. Include convergence plots of loss and accuracy on the training and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === YOUR CODE HERE ===\n",
    "# TODO: Implement LeNet5Rev architecture\n",
    "# TODO: Load FashionMNIST dataset\n",
    "# TODO: Train the model\n",
    "# TODO: Create convergence plots\n",
    "\n",
    "\n",
    "# === END YOUR CODE ==="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [21 pts] Improve the Model\n",
    "\n",
    "Try increasing the number of convolutional layers up to six with ReLU layers. You may need to increase the number of channels (but not in every layer). Use two max pooling layers. Kernel size can be 3 or 5 but adjust the padding so that the convolutional layers preserve the size of the feature maps.\n",
    "\n",
    "You can also simplify the classifier. Try a single linear layer instead of multiple linear layers separated by ReLU functions.\n",
    "\n",
    "You should be able to achieve about 92% accuracy on the test set. Show convergence plots for each model you try.\n",
    "\n",
    "You should try at least three different models. Describe your experiments. For each experiment include the model and plot convergence results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 1: [Describe Your Approach]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === YOUR CODE HERE ===\n",
    "# TODO: Define and train your first improved model\n",
    "\n",
    "\n",
    "# === END YOUR CODE ==="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 2: [Describe Your Approach]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === YOUR CODE HERE ===\n",
    "# TODO: Define and train your second improved model\n",
    "\n",
    "\n",
    "# === END YOUR CODE ==="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 3: [Describe Your Approach]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === YOUR CODE HERE ===\n",
    "# TODO: Define and train your third improved model\n",
    "\n",
    "\n",
    "# === END YOUR CODE ==="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [2 pts] Describe the Things You Tried\n",
    "\n",
    "Summarize the network architectures you tried. What worked best? What didn't help?\n",
    "\n",
    "\ud83d\udcdd **YOUR ANSWER HERE:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [8 pts] Analyze Your Best Model\n",
    "\n",
    "Make a confusion matrix for the predictions of your best model on the test set. You can set `use_class_labels = True` when using `evaluate_classifier` to see the names of the classes. You can also access the names of the classes as an attribute of the dataset, e.g. `dataset.classes`.\n",
    "\n",
    "Describe which classes get most confused by your model. Plot examples of the images that your model is getting wrong. Do these misclassifications make sense? Are the images from the misclassified classes hard to distinguish by eye?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === YOUR CODE HERE ===\n",
    "# TODO: Create confusion matrix for best model\n",
    "# TODO: Identify and visualize misclassified examples\n",
    "# TODO: Analyze confusion patterns\n",
    "\n",
    "\n",
    "# === END YOUR CODE ==="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which classes are most confused? Are the misclassifications reasonable?\n",
    "\n",
    "\ud83d\udcdd **YOUR ANSWER HERE:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [8 pts] Questions from Chapter 3.1-3.5 Reading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1 (1 pt):** Section 3.1 explains the concept of spatial structural prior beliefs. According to the reading:\n",
    "- What fundamental difference exists between columnar data (like in a spreadsheet) and image data in terms of structure?\n",
    "\n",
    "\ud83d\udcdd **YOUR ANSWER HERE:**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2 (1 pt):** Based on the tensor representation discussion in Section 3.1.1:\n",
    "- Why can't we arbitrarily shuffle the pixel values in an image without destroying its meaning, unlike shuffling columns in tabular data?\n",
    "\n",
    "\ud83d\udcdd **YOUR ANSWER HERE:**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3 (1 pt):** Section 3.2 introduces the core concept of convolutions:\n",
    "- Complete this statement from the reading: \"The prior that convolutions encode is that ___________ are related, and ___________ have no relationship.\"\n",
    "\n",
    "\ud83d\udcdd **YOUR ANSWER HERE:**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4 (1 pt):** From the 1D convolution explanation in Section 3.2.1:\n",
    "- If you apply a filter of size K=5 to a 1D input of length 20, what will be the length of the output (without padding)?\n",
    "\n",
    "\ud83d\udcdd **YOUR ANSWER HERE:**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 5 (1 pt):** According to Section 3.2.3 on padding:\n",
    "- If you use a convolutional filter of size K=5, how much padding should you apply to keep the output the same size as the input?\n",
    "\n",
    "\ud83d\udcdd **YOUR ANSWER HERE:**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 6 (1 pt):** From Section 3.2.4 on weight sharing:\n",
    "- Why should you \"never repeat convolutions\" according to the reading? What should you include instead?\n",
    "\n",
    "\ud83d\udcdd **YOUR ANSWER HERE:**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 7 (1 pt):** Based on Section 3.3's examples with blur and edge detection filters:\n",
    "- Look at the edge detection filter shown in the reading. Explain in your own words why this particular arrangement of values [[-1,-1,-1], [-1,8,-1], [-1,-1,-1]] is effective at detecting edges.\n",
    "\n",
    "\ud83d\udcdd **YOUR ANSWER HERE:**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 8 (1 pt):** From Section 3.5 on max pooling and translation invariance:\n",
    "- According to the reading's digit shift experiment, why do we want \"translation invariance\" in our models?\n",
    "\n",
    "\ud83d\udcdd **YOUR ANSWER HERE:**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [4 pts] Questions from L02_2 Convolution and Pooling Formulas\n",
    "\n",
    "**Question 9 (1 pt):** Using the convolution output size formula from the lesson:\n",
    "- A Conv2d layer has input size 8\u00d78, kernel size 3\u00d73, stride 2, and padding 1. Calculate the output size using the formula: Output = \u230a(Input + 2\u00d7Padding - Kernel)/Stride\u230b + 1\n",
    "\n",
    "\ud83d\udcdd **YOUR ANSWER HERE:**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 10 (1 pt):** Based on Example 2 in the lesson (RGB image with multiple filters):\n",
    "- If you have an RGB input image (3 channels) and apply a Conv2d layer with 12 output channels, how many separate filters does this layer contain? How many feature maps are produced?\n",
    "\n",
    "\ud83d\udcdd **YOUR ANSWER HERE:**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 11 (1 pt):** From the pooling examples in the lesson:\n",
    "- You have a 5\u00d75 input and apply MaxPool2d with kernel_size=3, stride=2, padding=1. Using the pooling formula, what will be the output size?\n",
    "\n",
    "\ud83d\udcdd **YOUR ANSWER HERE:**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 12 (1 pt):** From the lesson's discussion of feature maps and channels:\n",
    "- In your CNN experiments above, when you increased the number of convolutional layers, you likely increased the number of filters/channels in deeper layers. According to the lesson concepts, why do deeper layers typically use more filters than earlier layers?\n",
    "\n",
    "\ud83d\udcdd **YOUR ANSWER HERE:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [2 pts] Reflection\n",
    "\n",
    "1. What, if anything, did you find difficult to understand for this lesson? Why?\n",
    "\n",
    "\ud83d\udcdd **YOUR ANSWER HERE:**\n",
    "\n",
    "2. What resources did you find supported your learning most and least for this lesson? (Be honest - I use your input to shape the course.)\n",
    "\n",
    "\ud83d\udcdd **YOUR ANSWER HERE:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export Notebook to HTML for Canvas Upload\n\nUncomment the two lines below and run the cell to export the current notebook to HTML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from introdl import export_this_to_html\n# export_this_to_html()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}