{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lesson 10: Named Entity Recognition (NER) and Tokenization\n",
    "\n",
    "### Topics\n",
    "* Overview of Named Entity Recognition (NER)\n",
    "* Subword tokenization techniques (e.g., BPE, WordPiece)\n",
    "* Multilingual considerations in tokenization and NER\n",
    "\n",
    "### Outcomes\n",
    "\n",
    "1. **Explain Named Entity Recognition (NER)**: Define NER and its applications, identifying how it is used to label specific entities (e.g., names, locations) in text.\n",
    "   \n",
    "2. **Differentiate Tokenization Methods**: Describe different tokenization techniques (e.g., Byte-Pair Encoding, WordPiece) and their relevance in NER and multilingual settings.\n",
    "\n",
    "3. **Apply NER with Transformers**: Fine-tune a transformer model for NER tasks, learning how token-level classification works in transformers.\n",
    "\n",
    "4. **Discuss Multilingual Challenges**: Explain tokenization and NER challenges in multilingual contexts, including handling multiple languages and out-of-vocabulary (OOV) words.\n",
    "\n",
    "### Readings and Videos\n",
    "* Read *Chapter 4: Multilingual Named Entity Recognition* in *Natural Language Processing with Transformers*\n",
    "* **Course Notebooks with Videos**: Open each notebook in the Lesson_10 directory and watch the embedded videos in the recommended order.\n",
    "\n",
    "### Assessments\n",
    "1. Complete the reading quiz in Canvas (10 points).\n",
    "2. Complete the exercises in your homework notebook in CoCalc (40 points).\n",
    "\n",
    "### Homework Ideas\n",
    "1. **Tokenize and Label Named Entities**: Using Hugging Faceâ€™s `AutoTokenizer` and a pre-trained NER model, have students tokenize and label named entities (e.g., names, locations) in sample sentences. They can compare tokenized outputs across different tokenization methods.\n",
    "   \n",
    "2. **Fine-Tune an NER Model**: Guide students through fine-tuning a transformer model on an NER dataset, such as the CoNLL-2003 dataset. They can experiment with tokenization settings and observe model performance on recognizing entities.\n",
    "\n",
    "3. **Explore Multilingual NER**: Have students run multilingual text through an NER model, observing how well entities are recognized in different languages. They can analyze any challenges or inconsistencies they observe in tokenization and entity labeling across languages. "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
