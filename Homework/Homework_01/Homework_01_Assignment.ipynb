{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 01 Assignment\n",
    "**Name:** [Student Name Here]  \n",
    "**Total Points:** 50\n",
    "\n",
    "## Submission Checklist\n",
    "- [ ] All code cells executed with output saved\n",
    "- [ ] All questions answered\n",
    "- [ ] Notebook converted to HTML (use the Homework_01_Utilities notebook)\n",
    "- [ ] Canvas notebook filename includes `_GRADE_THIS_ONE`\n",
    "- [ ] Files uploaded to Canvas\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Classification of 2D Points Arranged in a Spiral\n",
    "\n",
    "## Instructions\n",
    "\n",
    "Read these carefully to be sure you don't leave anything out.\n",
    "\n",
    "Start by playing with the 2 class spiral classification problem in the [Neural Network Playground](https://playground.tensorflow.org/#activation=relu&batchSize=10&dataset=spiral&regDataset=reg-plane&learningRate=0.03&regularizationRate=0&noise=35&networkShape=4,2&seed=0.76765&showTestData=false&discretize=false&percTrainData=80&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification&initZero=false&hideText=false&problem_hide=true&discretize_hide=true&regularization_hide=true&dataset_hide=true&regularizationRate_hide=true).  Note - this link gives you a reduced version of the original website so you can focus on mainly the structure of the NN for this assignment.  \n",
    "\n",
    "Don't change the test/training ratio or the noise level.  Also, use only X1 and X2 as features (inputs) for your network.  Experiment with the network structure and try retraining each network a few times until you find a network architecture that seems to work reasonably well.  Once you've done that you should implement that network here in PyTorch.  \n",
    "\n",
    "We'll generate the initial spiral data for you.  You do the rest.  You should mimic the setup in the compact version of the logisitic regression notebook from class (in Canvas), but make changes to the network, training loop, etc. as needed.\n",
    "\n",
    "In addition to plotting the loss for the training and validation sets vs the epochs, figure out how to do the same for accuracy and share that plot.\n",
    "\n",
    "In the end you should be able to achieve 95% accuracy on the validation data.  I'll likely change a couple of random seeds to see if you've picked a robust architecture and training parameters!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === YOUR IMPORTS HERE ===\n",
    "# Add any additional imports you need below this line\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from Homework_01_Helpers import make_spirals\n",
    "\n",
    "from introdl.utils import config_paths_keys, train_network\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# config_paths_keys() sets where models and data will be stored\n",
    "paths = config_paths_keys()\n",
    "MODELS_PATH = paths[\"MODELS_PATH\"] # Where to save models\n",
    "DATA_PATH = paths[\"DATA_PATH\"]     # Where to save data\n",
    "# === END YOUR IMPORTS ==="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [5 pts] Describe What You Learned in NN Playground\n",
    "\n",
    "Use this cell to explain what you learned in NN playground. What model did you select? What learning rate? What activation function?\n",
    "\n",
    "üìù **YOUR ANSWER HERE:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [5 pts] Prepare the Data\n",
    "\n",
    "We'll build the spirals and split the data into train and test sets. We're using a larger training set than in NN playground for more robust training. Don't modify the provided code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provided code - DO NOT MODIFY\n",
    "from Homework_01_Helpers import make_spirals\n",
    "\n",
    "# Generate spiral data\n",
    "n_points = 400\n",
    "X, y = make_spirals(n_points=n_points, noise=0.35, random_state=0)\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train_tensor = torch.FloatTensor(X_train)\n",
    "y_train_tensor = torch.LongTensor(y_train)\n",
    "X_test_tensor = torch.FloatTensor(X_test)\n",
    "y_test_tensor = torch.LongTensor(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup the Datasets and DataLoaders here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === YOUR CODE HERE ===\n",
    "# TODO: Create TensorDatasets for training and test data\n",
    "# TODO: Create DataLoaders with appropriate batch size\n",
    "\n",
    "\n",
    "# === END YOUR CODE ==="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [5 pts] Visualize the Data\n",
    "\n",
    "Make side-by-side plots showing the training and test data along with the classes for each point. You may have to look up how to use matplotlib.pyplot.subplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === YOUR CODE HERE ===\n",
    "# TODO: Create side-by-side plots of training and test data\n",
    "# - Use subplots to create two plots side by side\n",
    "# - Color points by their class (0 or 1)\n",
    "# - Add titles and labels\n",
    "\n",
    "\n",
    "# === END YOUR CODE ==="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [5 pts] Define the Model\n",
    "\n",
    "Define your model. Create an instance of it. Use `summary` from torchinfo to generate a model summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === YOUR CODE HERE ===\n",
    "# TODO: Define your model class inheriting from nn.Module\n",
    "# Based on your experiments in NN Playground, implement:\n",
    "#   - The appropriate number of layers\n",
    "#   - The appropriate activation functions\n",
    "#   - The appropriate layer sizes\n",
    "\n",
    "class SpiralClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Your implementation\n",
    "        pass\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Your implementation\n",
    "        pass\n",
    "\n",
    "# Create an instance of your model\n",
    "# model = SpiralClassifier()\n",
    "\n",
    "# Display model summary\n",
    "# from torchinfo import summary\n",
    "# summary(model, input_size=(1, 2))\n",
    "\n",
    "# === END YOUR CODE ==="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many trainable parameters are in your model?\n",
    "\n",
    "üìù **YOUR ANSWER HERE:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [5 pts] Train the Model\n",
    "\n",
    "Configure the model training and do the training. Save the checkpoint file in MODELS_PATH.\n",
    "\n",
    "**You should be able to achieve around 95% accuracy on the test data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === YOUR CODE HERE ===\n",
    "# TODO: Configure and train your model\n",
    "# - Set up loss function (appropriate for classification)\n",
    "# - Set up optimizer with appropriate learning rate\n",
    "# - Use train_network function with appropriate parameters\n",
    "# - Save checkpoint to MODELS_PATH\n",
    "\n",
    "\n",
    "# === END YOUR CODE ==="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [5 pts] Inspect Convergence Graphically\n",
    "\n",
    "Load the checkpoint file and use it to plot training and test loss vs epoch and training and test accuracy vs epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === YOUR CODE HERE ===\n",
    "# TODO: Load checkpoint and create plots\n",
    "# - Load the checkpoint file\n",
    "# - Extract training history\n",
    "# - Create 2 subplots: loss vs epoch and accuracy vs epoch\n",
    "# - Show both training and validation metrics\n",
    "\n",
    "\n",
    "# === END YOUR CODE ==="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the maximum test accuracy found by your model?\n",
    "\n",
    "üìù **YOUR ANSWER HERE:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [5 pts] Visualize the Model Fit\n",
    "\n",
    "Plot the fitted model as in the lesson."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === YOUR CODE HERE ===\n",
    "# TODO: Visualize the decision boundary\n",
    "# - Create a mesh grid covering the data space\n",
    "# - Use your model to predict on the grid\n",
    "# - Plot the decision boundary as a contour\n",
    "# - Overlay the actual data points\n",
    "\n",
    "\n",
    "# === END YOUR CODE ==="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comment on the quality of the fit. Does the decision boundary accurately represent the separation of the classes or is there anything about it that seems incorrect?\n",
    "\n",
    "üìù **YOUR ANSWER HERE:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [5 pts] Make Predictions\n",
    "\n",
    "Include a function for making predictions and find the probabilities and predicted labels for new points: (0,0), (0,2), and (0,4)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === YOUR CODE HERE ===\n",
    "# TODO: Create prediction function and make predictions\n",
    "# - Define a function that takes points and returns probabilities and labels\n",
    "# - Make predictions for the three specified points\n",
    "# - Display the results clearly\n",
    "\n",
    "def predict_points(model, points):\n",
    "    \"\"\"\n",
    "    Make predictions for given points.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained model\n",
    "        points: Array of points to predict\n",
    "    \n",
    "    Returns:\n",
    "        probabilities: Class probabilities for each point\n",
    "        predictions: Predicted class labels\n",
    "    \"\"\"\n",
    "    # Your implementation\n",
    "    pass\n",
    "\n",
    "# Test points\n",
    "test_points = np.array([[0, 0], [0, 2], [0, 4]])\n",
    "\n",
    "# Make predictions\n",
    "# probs, preds = predict_points(model, test_points)\n",
    "\n",
    "# === END YOUR CODE ==="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [3 pts] Training vs Validation Data\n",
    "\n",
    "*NOTE: I was not very clear in the lesson, but what we're calling a test set is being used as a validation set in the text and homework.*\n",
    "\n",
    "1. In your spiral classification problem above, you split your data into training and validation sets. Explain why we need separate datasets for training and validation. What problem are we trying to avoid?\n",
    "\n",
    "üìù **YOUR ANSWER HERE:**\n",
    "\n",
    "2. During training, when should you evaluate on the validation set? Every batch? Every epoch? Only at the end? Explain your reasoning.\n",
    "\n",
    "üìù **YOUR ANSWER HERE:**\n",
    "\n",
    "3. If your training accuracy is 99% but your validation accuracy is only 60%, what does this indicate about your model? What might you do to fix this?\n",
    "\n",
    "üìù **YOUR ANSWER HERE:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [5 pts] Understanding the Training Loop\n",
    "\n",
    "The `train_network` function you used above contains a training loop. Below is simplified code showing the key parts of what happens inside that function. For each marked line, explain in your own words what that line does and why it's necessary for training the network. Use Chapter 1 of the textbook to help you understand these operations.\n",
    "\n",
    "```python\n",
    "def training_loop(model, train_loader, loss_func, optimizer, epochs):\n",
    "    for epoch in range(epochs):\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            \n",
    "            # LINE A: What does optimizer.zero_grad() do and why is it necessary?\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # LINE B: What is happening when we call model(data)?\n",
    "            output = model(data)\n",
    "            \n",
    "            # LINE C: What does the loss function compute and what type of value does it return?\n",
    "            loss = loss_func(output, target)\n",
    "            \n",
    "            # LINE D: What does loss.backward() calculate and where does it store the results?\n",
    "            loss.backward()\n",
    "            \n",
    "            # LINE E: What does optimizer.step() do with the information from loss.backward()?\n",
    "            optimizer.step()\n",
    "```\n",
    "\n",
    "üìù **YOUR EXPLANATIONS:**\n",
    "- **LINE A:** \n",
    "- **LINE B:** \n",
    "- **LINE C:** \n",
    "- **LINE D:** \n",
    "- **LINE E:** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [2 pts] Reflection\n",
    "\n",
    "1. What, if anything, did you find difficult to understand for the lesson? Why?\n",
    "\n",
    "üìù **YOUR ANSWER HERE:**\n",
    "\n",
    "2. What resources did you find supported your learning most and least for this lesson? (Be honest - I use your input to shape the course.)\n",
    "\n",
    "üìù **YOUR ANSWER HERE:**"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [
    {
     "file_id": "1-HQWPweMIqAYecMoaiEwveKgKWaENYwo",
     "timestamp": 1707429755677
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python (ds776_env)",
   "language": "python",
   "name": "ds776_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
