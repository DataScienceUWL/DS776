{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Lesson 11: Text Generation and Decoding Strategies\n\n### Topics\n* Overview of transformer-based text generation\n* Decoding strategies: Greedy search, beam search, top-k sampling, and nucleus sampling\n* Understanding chat roles (system, user, assistant) for conversational AI\n* Using LLM APIs (OpenAI chat completions via OpenRouter) for text generation\n* Building custom API client classes with object-oriented design\n* Extending classes via inheritance for chatbot functionality\n* Working with larger quantized models (30B-70B parameters)\n* Applications of text generation in NLP\n\n### Outcomes\n\n1. **Explain Text Generation Basics**: Describe how transformer models like GPT-2 generate text, and identify common applications of text generation, such as chatbots, content creation, and automated summarization.\n   \n2. **Use Decoding Strategies**: Implement and compare different decoding methods (e.g., greedy search, beam search, top-k sampling, nucleus sampling) to observe how each affects text generation quality.\n\n3. **Use LLM APIs via OpenRouter**: Access remote language models through standardized OpenAI-compatible APIs, managing API keys securely with environment variables, and understanding the trade-offs between local and API-based generation.\n\n4. **Build Custom API Client Classes**: Create reusable Python classes for text generation that wrap API calls using object-oriented design principles, demonstrating encapsulation, inheritance, and extensibility.\n\n5. **Implement Chat Roles and Conversation History**: Understand how chat roles (system, user, assistant) work in conversational AI, and build chatbot classes that maintain conversation history across multiple turns.\n\n6. **Apply Object-Oriented Programming**: Extend base classes using inheritance to add new functionality, demonstrating how ChatbotClient extends LLMClient to add conversation management capabilities.\n\n7. **Work with Larger Quantized Models**: Load and use 30B-70B parameter models efficiently on GPU servers using 4-bit quantization, understanding memory management and performance trade-offs between model sizes.\n\n8. **Evaluate Generated Text**: Assess the quality of generated text, discussing trade-offs in coherence, creativity, and relevance with different decoding strategies and model sizes.\n\n9. **Identify Real-World Applications**: Explain practical uses of text generation in industries like customer service, media, and content creation, understanding the strengths and limitations of transformer-based text generation.\n\n### Readings and Videos\n* Read *Chapter 5: Text Generation* and pages 148-156 about metrics in *Natural Language Processing with Transformers*\n* **Course Notebooks with Videos**: Open each notebook in the Lesson_11 directory and watch the embedded videos in the recommended order.\n\n### Assessments\n1. Complete the reading quiz in Canvas (10 points).\n2. Complete the exercises in your homework notebook in CoCalc (40 points).\n\n### Homework Ideas\n\n1. **Experiment with Different Decoding Methods**: In a notebook, students can use a model like GPT-2 to generate text using various decoding strategies (e.g., beam search, top-k sampling, nucleus sampling). They should document the output quality for each method, comparing coherence, relevance, and creativity.\n\n2. **Build Custom API Client Classes**: Guide students to create custom Python classes (`LLMClient` and `ChatbotClient`) that wrap the OpenAI API (via OpenRouter) for text generation tasks. They should implement proper initialization, error handling, conversation history management, and demonstrate object-oriented programming principles including inheritance and encapsulation.\n\n3. **Compare Model Sizes**: Have students compare text generation quality and speed across different model sizes (3B, 8B, 70B parameters). They should analyze trade-offs in accuracy, creativity, and computational cost for different use cases.\n\n4. **Build a Chatbot with Context**: Guide students to create a chatbot using the ChatbotClient class that maintains conversation history and uses chat roles (system, user, assistant). They can experiment with different system prompts and observe how the model maintains context across multiple turns.\n\n5. **Analyze Decoding Trade-offs**: Have students experiment with decoding hyperparameters (e.g., beam width, top-k values, temperature) on a small dataset. They can analyze and document how adjustments affect the generated text's diversity, accuracy, and readability, providing insights into the practical trade-offs of each decoding strategy."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}