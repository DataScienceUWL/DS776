{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DS776 Auto-Update (runs in ~2 seconds, only updates when needed)\n",
    "# If this cell fails, see Lessons/Course_Tools/AUTO_UPDATE_SYSTEM.md for help\n",
    "%run ../../Lessons/Course_Tools/auto_update_introdl.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 7: Exploring Hugging Face Pipelines and LLM Prompting\n",
    "\n",
    "In this assignment, you will explore different NLP tasks using Hugging Face's transformers pipelines and LLM-based prompting with `llm_generate()`. You will experiment with different models, zero-shot prompting, and compare results across approaches.\n",
    "\n",
    "**Total Points: 50**\n",
    "- Reading Questions: 8 points\n",
    "- Task 1 (Sentiment Analysis): 6 points\n",
    "- Task 2 (Named Entity Recognition): 6 points  \n",
    "- Task 3 (Text Generation): 6 points\n",
    "- Task 4 (Translation): 6 points\n",
    "- Task 5 (Summarization): 8 points\n",
    "- Task 6 (Sarcasm Detection): 8 points\n",
    "- Reflection: 2 points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from transformers import pipeline\n",
    "from introdl import (\n",
    "    get_device,\n",
    "    wrap_print_text,\n",
    "    config_paths_keys,\n",
    "    llm_generate,\n",
    "    clear_pipeline,\n",
    "    print_pipeline_info,\n",
    "    display_markdown, \n",
    "    show_session_spending \n",
    ")\n",
    "# Wrap print to format text nicely at 120 characters\n",
    "print = wrap_print_text(print, width=120)\n",
    "\n",
    "device = get_device()\n",
    "\n",
    "paths = config_paths_keys()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Questions (8 points)\n",
    "\n",
    "Answer the following questions based on Chapter 1: Hello Transformers from *Natural Language Processing with Transformers*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1 (2 points):** What was the main limitation of the encoder-decoder architecture using RNNs that led to the development of attention mechanisms? How does attention solve this problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üìù **YOUR ANSWER HERE:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2 (2 points):** Explain the three main steps of the ULMFiT transfer learning process: pretraining, domain adaptation, and fine-tuning. Why was ULMFiT significant for transformer development?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üìù **YOUR ANSWER HERE:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3 (2 points):** What is the key difference between how GPT and BERT use the Transformer architecture? (Hint: Think about encoder vs decoder and their pretraining objectives.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üìù **YOUR ANSWER HERE:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4 (2 points):** Name and briefly describe three main challenges associated with transformer models mentioned in the chapter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üìù **YOUR ANSWER HERE:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes About Using LLMs Programmatically\n",
    "\n",
    "**Using `llm_generate()` for all LLM tasks:**\n",
    "- Use `llm_generate()` with `'gemini-flash-lite'` as your default model (fast and cost-effective)\n",
    "- For each task, also try at least **one other model** to compare results (e.g., `'gpt-4o-mini'`, `'mistral-medium'`, `'llama-3.3-70b'`)\n",
    "- You can pass `temperature=0` to get more deterministic (reproducible) responses\n",
    "- Use `mode='json'` when you need structured JSON output\n",
    "\n",
    "**System and User Prompts:**\n",
    "- Use the **system prompt** to set the overall behavior (e.g., \"You are a sentiment analysis expert\")\n",
    "- Use the **user prompt** for specific instructions and the text to analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provided Texts for Tasks 1 and 2\n",
    "\n",
    "texts = [\n",
    "    \"The new AI technology developed by OpenAI is revolutionizing various industries, from healthcare to finance.\",\n",
    "    \"Marie Curie was a physicist and chemist who conducted research on radioactivity.\",\n",
    "    \"In 2023, NASA successfully landed another rover on Mars, aiming to explore signs of ancient life.\",\n",
    "    \"The recent advancements in quantum computing by IBM have the potential to solve complex problems that are currently unsolvable with classical computers.\",\n",
    "    \"Despite the company's efforts, the new product launch by XYZ Corp was a complete failure, leading to significant financial losses and a drop in stock prices.\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Sentiment Analysis (6 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1a.** Use the default sentiment analysis pipeline from HuggingFace to determine the sentiment of each text. Use `clear_pipeline()` to free memory when done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1b.** Now use `llm_generate()` with `'gemini-flash-lite'` to perform sentiment analysis. Create appropriate system and user prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1c.** Try a different model with `llm_generate()` for the same task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1d.** Which approach (HuggingFace pipeline or which LLM model) best captures the sentiments? Explain your reasoning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üìù **YOUR ANSWER HERE:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Named Entity Recognition (6 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2a.** Apply the default HuggingFace NER pipeline to each of the texts. Display results in a pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2b.** Use `llm_generate()` with `mode='json'` to get structured NER output. Use `'gemini-flash-lite'` and craft prompts to return JSON with entity information. Display results as a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "# Hint: Use mode='json' and describe the JSON structure you want in the prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2c.** Try a different LLM model with JSON mode and compare the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Text Generation (6 points)\n",
    "\n",
    "Think of a short creative task (e.g., writing an advertisement, lyrics for a jingle, a product description, etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3a.** Use the default HuggingFace text generation pipeline for your task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3b.** Use `llm_generate()` with two different models to perform the same task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 1: gemini-flash-lite\n",
    "# Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 2: (your choice)\n",
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3c.** Which approach produced the best result? Explain why."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üìù **YOUR ANSWER HERE:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: Translation (6 points)\n",
    "\n",
    "Pick your own short text (at least 3 sentences) and translate it to another language (not Spanish) and back, then compare."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4a.** Use HuggingFace translation pipelines. Search for an appropriate model on HuggingFace Hub for your chosen language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "# Translate to target language\n",
    "# Translate back to English\n",
    "# Compare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4b.** Use `llm_generate()` with two different models to translate to your chosen language and back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4c.** Which works better - the specialized HuggingFace model or the LLMs? Explain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üìù **YOUR ANSWER HERE:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5: Summarization (8 points)\n",
    "\n",
    "For this task you'll generate summaries of [\"The Bitter Lesson\"](http://www.incompleteideas.net/IncIdeas/BitterLesson.html) by Rich Sutton. This is an important paper about deep learning that you should read!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the text from \"The Bitter Lesson\"\n",
    "# You may need to: !pip install beautifulsoup4\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"http://www.incompleteideas.net/IncIdeas/BitterLesson.html\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Extract the text from the webpage\n",
    "text = soup.get_text()\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5a.** Use the default HuggingFace summarization pipeline. Note: \"The Bitter Lesson\" is too long for the default model. Split the text roughly in half and summarize each half separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5b.** Use `llm_generate()` with `'gemini-flash-lite'` to summarize the entire article (no need to split)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5c.** Try a different LLM model for summarization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5d.** Compare all three summaries. Which one seems best and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üìù **YOUR ANSWER HERE:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 6: Sarcasm Detection with an LLM (8 points)\n",
    "\n",
    "The Sarcasm News Headlines dataset contains headlines labeled as sarcastic (1) or not sarcastic (0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Sarcasm News Headlines Dataset\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "\n",
    "dataset = load_dataset(\"raquiba/Sarcasm_News_Headline\")\n",
    "\n",
    "# Convert to Pandas DataFrame\n",
    "df = pd.DataFrame(dataset['train'])\n",
    "df = df.rename(columns={'is_sarcastic': 'label'})\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6a.** Use `llm_generate()` with `'gemini-flash-lite'` to classify the first 10 headlines as sarcastic or not.  You should build the prompts programatically as shown in the lesson notebooks. Compare to actual labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6b.** Try a different model for sarcasm detection and compare results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6c.**  Arguably, many of the examples in the dataset are ironic and not sarcastic.  (Irony pertains to situations while sarcasm is a form of expression.)  Try prompting your 'gemini-flash-lite' to be an irony detector to see if it performs better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6d.** Which model and/or prompting approach performs best?  Give a brief explanation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üìù **YOUR ANSWER HERE:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [2 pts] Reflection\n",
    "\n",
    "1. What, if anything, did you find difficult to understand for the lesson? Why?\n",
    "\n",
    "üìù **YOUR ANSWER HERE:**\n",
    "\n",
    "2. What resources did you find supported your learning most and least for this lesson? (Be honest - I use your input to shape the course.)\n",
    "\n",
    "üìù **YOUR ANSWER HERE:**"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## Export to HTML for Canvas Submission\n\nRun the cell below to export this notebook to HTML for submission.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "from introdl import export_this_to_html\nexport_this_to_html()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export Notebook to HTML for Canvas Upload\n",
    "\n",
    "Uncomment the two lines below and run the cell to export the current notebook to HTML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from introdl import export_this_to_html\n",
    "# export_this_to_html()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ds776_env)",
   "language": "python",
   "name": "ds776_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}