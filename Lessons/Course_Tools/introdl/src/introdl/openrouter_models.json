{
  "models": {
    "gpt-4o-mini": {
      "id": "openai/gpt-4o-mini-2024-07-18",
      "provider": "openai",
      "parameters": "~8B",
      "architecture": "dense (possibly MoE)",
      "notes": "Commercial model, size estimated",
      "json_support": {
        "json_object": true,
        "json_schema": true,
        "strict_schema": false
      }
    },
    "gpt-4o": {
      "id": "openai/gpt-4o-2024-11-20",
      "provider": "openai",
      "parameters": "~200B",
      "architecture": "possibly MoE",
      "notes": "Commercial model, size estimated",
      "json_support": {
        "json_object": true,
        "json_schema": true,
        "strict_schema": false
      }
    },
    "gemini-flash-lite": {
      "id": "google/gemini-2.5-flash-lite",
      "provider": "google",
      "parameters": "~5B",
      "architecture": "dense",
      "notes": "Commercial model, size estimated",
      "json_support": {
        "json_object": true,
        "json_schema": true,
        "strict_schema": true
      }
    },
    "gemini-flash": {
      "id": "google/gemini-2.5-flash",
      "provider": "google",
      "parameters": "~20B",
      "architecture": "dense",
      "notes": "Commercial model, size estimated",
      "json_support": {
        "json_object": true,
        "json_schema": true,
        "strict_schema": true
      }
    },
    "claude-haiku": {
      "id": "anthropic/claude-3.5-haiku",
      "provider": "anthropic",
      "parameters": "~30-50B",
      "architecture": "dense",
      "notes": "Commercial model, size estimated",
      "json_support": {
        "json_object": true,
        "json_schema": false,
        "strict_schema": false
      }
    },
    "gpt-oss-20b": {
      "id": "openai/gpt-oss-20b",
      "provider": "openai",
      "parameters": "21B",
      "architecture": "MoE (4-bit quantized MXFP4)",
      "notes": "Open-weight model, Apache 2.0 license, runs on 16GB memory",
      "json_support": {
        "json_object": true,
        "json_schema": true,
        "strict_schema": true
      }
    },
    "gpt-oss-120b": {
      "id": "openai/gpt-oss-120b",
      "provider": "openai",
      "parameters": "117B",
      "architecture": "MoE (4-bit quantized MXFP4)",
      "notes": "Open-weight model, Apache 2.0 license, competitive with o4-mini, runs on 80GB GPU, JSON support unreliable",
      "json_support": {
        "json_object": false,
        "json_schema": false,
        "strict_schema": false
      }
    },
    "llama-3.2-1b": {
      "id": "meta-llama/llama-3.2-1b-instruct",
      "provider": "meta",
      "parameters": "1B",
      "architecture": "dense",
      "notes": "Open-weight model, efficient edge/mobile model, very affordable",
      "json_support": {
        "json_object": true,
        "json_schema": false,
        "strict_schema": false
      }
    },
    "llama-3.2-3b": {
      "id": "meta-llama/llama-3.2-3b-instruct",
      "provider": "meta",
      "parameters": "3B",
      "architecture": "dense",
      "notes": "Open-weight model, very affordable (~$0.018/M), outperforms Gemma 2.6B and Phi 3.5-mini on NLP tasks",
      "json_support": {
        "json_object": true,
        "json_schema": false,
        "strict_schema": false
      }
    },
    "llama-3.3-70b": {
      "id": "meta-llama/llama-3.3-70b-instruct",
      "provider": "meta",
      "parameters": "70B",
      "architecture": "dense",
      "notes": "Open-weight model",
      "json_support": {
        "json_object": true,
        "json_schema": true,
        "strict_schema": true
      }
    },
    "mistral-nemo": {
      "id": "mistralai/mistral-nemo",
      "provider": "mistral",
      "parameters": "12B",
      "architecture": "dense",
      "notes": "Open-weight model, efficient small model",
      "json_support": {
        "json_object": true,
        "json_schema": true,
        "strict_schema": true
      }
    },
    "qwen3-32b": {
      "id": "qwen/qwen3-32b",
      "provider": "qwen",
      "parameters": "32B",
      "architecture": "dense",
      "notes": "Open-weight model, latest Qwen3 generation (April 2025)",
      "json_support": {
        "json_object": true,
        "json_schema": true,
        "strict_schema": true
      }
    },
    "mistral-medium": {
      "id": "mistralai/mistral-medium-3",
      "provider": "mistral",
      "parameters": "~60-80B",
      "architecture": "dense",
      "notes": "Open-weight model, size estimated",
      "json_support": {
        "json_object": true,
        "json_schema": true,
        "strict_schema": true
      }
    },
    "deepseek-v3.1": {
      "id": "deepseek/deepseek-chat-v3.1",
      "provider": "deepseek",
      "parameters": "671B total, 37B active",
      "architecture": "MoE",
      "notes": "Open-weight model, hybrid reasoning model with reasoning disabled for faster/cheaper responses",
      "json_support": {
        "json_object": true,
        "json_schema": true,
        "strict_schema": true
      }
    }
  },
  "default_model": "gemini-flash-lite",
  "cost_warning_thresholds": [
    0.5,
    0.75,
    0.9
  ],
  "student_credit_limit": 15.0,
  "description": "OpenRouter model configurations for DS776 NLP lessons. Removed free-tier models (rate limiting issues) and deepseek models. Using paid variants of gpt-oss-20b, llama-3.2-1b for better reliability. Focus on commercial models (OpenAI, Google, Anthropic) and affordable open-weight models (Meta Llama, Mistral, Qwen). Includes model metadata and JSON capability data from automated testing.",
  "last_updated": "2025-10-09"
}