{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lesson 11 Reading Quiz\n",
    "\n",
    "Read Chapter 5: \"Text Generation\"\n",
    "\n",
    "---\n",
    "\n",
    "#### 1. What is the primary objective of text generation in NLP?  \n",
    "A. To classify text based on predefined categories.  \n",
    "B. To identify specific entities in a text, such as names or dates.  \n",
    "C. To generate coherent and meaningful text based on an input sequence.  \n",
    "D. To summarize lengthy articles into shorter paragraphs.  \n",
    "\n",
    "---\n",
    "\n",
    "#### 2. Which transformer model is commonly associated with text generation tasks?  \n",
    "A. BART  \n",
    "B. GPT-2  \n",
    "C. T5  \n",
    "D. XLM-RoBERTa  \n",
    "\n",
    "---\n",
    "\n",
    "#### 3. What does greedy search do in the context of decoding strategies?  \n",
    "A. It chooses the next token randomly.  \n",
    "B. It selects the next token with the highest probability at each step.  \n",
    "C. It generates multiple sequences simultaneously.  \n",
    "D. It uses a predefined list of tokens to create outputs.  \n",
    "\n",
    "---\n",
    "\n",
    "#### 4. What distinguishes nucleus sampling from top-k sampling?  \n",
    "A. Nucleus sampling selects the top-k most likely tokens.  \n",
    "B. Nucleus sampling samples from the smallest set of tokens whose probabilities sum to a given threshold (p).  \n",
    "C. Nucleus sampling relies solely on deterministic selection.  \n",
    "D. Nucleus sampling generates text using beam search.  \n",
    "---\n",
    "\n",
    "#### 5. Why is beam search often used for text generation?  \n",
    "A. It introduces randomness to increase diversity in outputs.  \n",
    "B. It avoids low-probability sequences by considering multiple paths simultaneously.  \n",
    "C. It generates text more quickly than other methods.  \n",
    "D. It limits the vocabulary size to improve efficiency.  \n",
    "\n",
    "---\n",
    "\n",
    "#### 6. Which metric is typically used to evaluate the quality of generated text?  \n",
    "A. BLEU  \n",
    "B. Accuracy  \n",
    "C. Precision  \n",
    "D. Recall  \n",
    "\n",
    "---\n",
    "\n",
    "#### 7. What is a key challenge in evaluating abstractive text generation?  \n",
    "A. Models cannot process long inputs efficiently.  \n",
    "B. Human evaluation is subjective and difficult to standardize.  \n",
    "C. Pretrained models do not support text generation tasks.  \n",
    "D. Metrics like BLEU and ROUGE are computationally intensive.  \n",
    "\n",
    "---\n",
    "\n",
    "#### 8. What is one major advantage of transformer-based text generation over traditional methods?  \n",
    "A. It eliminates the need for tokenization.  \n",
    "B. It can generate contextually coherent sequences without sequential processing.  \n",
    "C. It requires less computational power than RNN-based methods.  \n",
    "D. It does not require any training data.  \n",
    "\n",
    "---\n",
    "\n",
    "#### 9. In which industry is text generation commonly used for content creation?  \n",
    "A. Retail  \n",
    "B. Healthcare  \n",
    "C. Media and marketing  \n",
    "D. Finance   \n",
    "\n",
    "---\n",
    "\n",
    "#### 10. What is a common issue with transformer-based text generation models?  \n",
    "A. They cannot handle non-English languages.  \n",
    "B. They struggle to maintain coherence over long outputs.  \n",
    "C. They do not support fine-tuning for domain-specific tasks.  \n",
    "D. They require extensive labeled data for training.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
