{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test 02: Import Order Independence\n",
    "\n",
    "**Purpose:** Verify that after running the auto_update cell, import order no longer matters for cache path configuration.\n",
    "\n",
    "**The Problem (before fix):**\n",
    "- If `import transformers` ran before `from introdl import ...`, HuggingFace would lock cache to `~/.cache`\n",
    "- Environment variables had to be set BEFORE importing any HF/torch libraries\n",
    "\n",
    "**Expected Results (after fix):**\n",
    "- Import order should NOT matter\n",
    "- All cache paths should be correct regardless of import sequence\n",
    "\n",
    "**Run this on:** Both CoCalc base and Compute Server\n",
    "\n",
    "---\n",
    "\n",
    "## IMPORTANT: Restart kernel before running this test!\n",
    "\n",
    "This test checks that import order doesn't matter. For accurate results, start with a fresh kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DS776 Environment Setup & Package Update\n",
    "# Configures storage paths for proper cleanup/sync, then updates introdl if needed\n",
    "# If this cell fails, see Lessons/Course_Tools/AUTO_UPDATE_SYSTEM.md for help\n",
    "%run ../../Lessons/Course_Tools/auto_update_introdl.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to check cache paths\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "def check_cache_paths(test_name):\n",
    "    \"\"\"Check if all cache paths are configured correctly.\"\"\"\n",
    "    home = Path.home()\n",
    "    bad_cache = str(home / '.cache')\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    # Check torch\n",
    "    import torch\n",
    "    torch_dir = torch.hub.get_dir()\n",
    "    results.append(('torch.hub.get_dir()', torch_dir, bad_cache not in torch_dir))\n",
    "    \n",
    "    # Check transformers\n",
    "    from transformers import TRANSFORMERS_CACHE\n",
    "    results.append(('TRANSFORMERS_CACHE', TRANSFORMERS_CACHE, bad_cache not in TRANSFORMERS_CACHE))\n",
    "    \n",
    "    # Check huggingface_hub\n",
    "    from huggingface_hub import constants as hf_constants\n",
    "    results.append(('HF_HUB_CACHE', str(hf_constants.HF_HUB_CACHE), bad_cache not in str(hf_constants.HF_HUB_CACHE)))\n",
    "    \n",
    "    # Check datasets\n",
    "    import datasets\n",
    "    results.append(('HF_DATASETS_CACHE', str(datasets.config.HF_DATASETS_CACHE), bad_cache not in str(datasets.config.HF_DATASETS_CACHE)))\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"TEST: {test_name}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    all_passed = True\n",
    "    for name, value, passed in results:\n",
    "        status = \"PASS\" if passed else \"FAIL\"\n",
    "        if not passed:\n",
    "            all_passed = False\n",
    "        print(f\"{status}: {name}\")\n",
    "        print(f\"       {value}\")\n",
    "    \n",
    "    print(f\"\\nOVERALL: {'PASS' if all_passed else 'FAIL'}\")\n",
    "    return all_passed\n",
    "\n",
    "print(\"Helper function defined. Ready to test import orders.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test A: Import transformers FIRST (before introdl)\n",
    "\n",
    "This was the problematic case before the fix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test A: Import transformers first, then introdl\n",
    "# Note: We already have transformers imported from the helper, \n",
    "# but let's check the state\n",
    "\n",
    "import transformers\n",
    "print(f\"transformers imported from: {transformers.__file__}\")\n",
    "print(f\"transformers version: {transformers.__version__}\")\n",
    "\n",
    "# Now import introdl\n",
    "from introdl import config_paths_keys\n",
    "print(\"\\nintrodl imported successfully\")\n",
    "\n",
    "# Check paths\n",
    "check_cache_paths(\"Import transformers FIRST\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test B: Import torch and torchvision FIRST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test B: Import torch/torchvision first\n",
    "import torch\n",
    "import torchvision\n",
    "print(f\"torch version: {torch.__version__}\")\n",
    "print(f\"torchvision version: {torchvision.__version__}\")\n",
    "print(f\"torch.hub.get_dir(): {torch.hub.get_dir()}\")\n",
    "\n",
    "# Verify it's not in ~/.cache\n",
    "from pathlib import Path\n",
    "home = Path.home()\n",
    "torch_dir = torch.hub.get_dir()\n",
    "\n",
    "if str(home / '.cache') in torch_dir:\n",
    "    print(\"\\nFAIL: torch.hub is using ~/.cache!\")\n",
    "else:\n",
    "    print(\"\\nPASS: torch.hub is NOT using ~/.cache\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test C: Import datasets FIRST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test C: Import datasets first\n",
    "from datasets import load_dataset\n",
    "import datasets\n",
    "print(f\"datasets version: {datasets.__version__}\")\n",
    "print(f\"HF_DATASETS_CACHE: {datasets.config.HF_DATASETS_CACHE}\")\n",
    "\n",
    "# Verify it's not in ~/.cache\n",
    "from pathlib import Path\n",
    "home = Path.home()\n",
    "ds_cache = str(datasets.config.HF_DATASETS_CACHE)\n",
    "\n",
    "if str(home / '.cache') in ds_cache:\n",
    "    print(\"\\nFAIL: datasets cache is using ~/.cache!\")\n",
    "else:\n",
    "    print(\"\\nPASS: datasets cache is NOT using ~/.cache\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test D: Mixed import order (common student pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test D: Common student import pattern\n",
    "# Students often do random import orders\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from introdl import config_paths_keys, get_device\n",
    "\n",
    "print(\"All imports completed successfully\")\n",
    "print(f\"\\nDevice: {get_device()}\")\n",
    "\n",
    "# Final check\n",
    "check_cache_paths(\"Mixed import order (common student pattern)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "If all tests passed:\n",
    "- Import order no longer matters after running the auto_update cell\n",
    "- The environment variables are set early enough to affect all library imports\n",
    "\n",
    "**Next:** Run Test_03 to actually download HuggingFace models and verify they go to the right place."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
