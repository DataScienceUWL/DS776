{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Other LLM Providers (Optional)\n",
    "\n",
    "**‚ö†Ô∏è This notebook is optional** - you only need it if you want to use LLM providers other than OpenRouter.\n",
    "\n",
    "## Why Use Other Providers?\n",
    "\n",
    "**OpenRouter** is our default and **recommended** provider because:\n",
    "- ‚úÖ **Automatic cost tracking** - know exactly how much you're spending\n",
    "- ‚úÖ **Access to many models** - Claude, GPT, Gemini, Llama, and more\n",
    "- ‚úÖ **Single API key** - one key for all models\n",
    "- ‚úÖ **Student credits** - $15 credit provided for this course\n",
    "\n",
    "However, you might want to use other providers directly if:\n",
    "- üí∞ **~10-20% cheaper** - Direct API access skips OpenRouter's small markup\n",
    "- üîë **You already have API keys** - from OpenAI, Google, Anthropic, etc.\n",
    "- ‚ö° **Ultra-fast inference** - Groq offers extremely fast responses\n",
    "\n",
    "## Comparison of Providers\n",
    "\n",
    "| Provider | Best For | Cost Tracking | Setup Complexity |\n",
    "|----------|----------|---------------|------------------|\n",
    "| **OpenRouter** (default) | Everything - recommended | ‚úÖ Automatic | ‚úÖ Easy (one key) |\n",
    "| **OpenAI** | Latest GPT models | ‚ö†Ô∏è Manual | ‚ö†Ô∏è Moderate |\n",
    "| **Anthropic** | Claude models | ‚ö†Ô∏è Manual | ‚ö†Ô∏è Moderate |\n",
    "| **Google** | Gemini models | ‚ö†Ô∏è Manual | ‚ö†Ô∏è Moderate |\n",
    "| **Together.AI** | Open-weight models | ‚ö†Ô∏è Manual | ‚ö†Ô∏è Moderate |\n",
    "| **Groq** | Ultra-fast inference | ‚ö†Ô∏è Manual | ‚ö†Ô∏è Moderate |\n",
    "\n",
    "**Cost Tracking:**\n",
    "- **Automatic (OpenRouter only)**: Tracks every API call, shows warnings at 50%/75%/90% of credit\n",
    "- **Manual**: You provide `cost_per_m_in` and `cost_per_m_out` parameters for basic tracking, or monitor through provider dashboards"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup: Adding API Keys\n",
    "\n",
    "All API keys should be added to `~/home_workspace/api_keys.env`. They'll be automatically loaded by `config_paths_keys()`.\n",
    "\n",
    "### Get API Keys:\n",
    "1. **OpenAI**: https://platform.openai.com/api-keys\n",
    "2. **Anthropic**: https://console.anthropic.com/settings/keys\n",
    "3. **Google**: https://makersuite.google.com/app/apikey\n",
    "4. **Together.AI**: https://api.together.xyz/settings/api-keys\n",
    "5. **Groq**: https://console.groq.com/keys\n",
    "\n",
    "### Add to `~/home_workspace/api_keys.env`:\n",
    "```bash\n",
    "# OpenRouter (already set up for you)\n",
    "OPENROUTER_API_KEY=sk-or-...\n",
    "\n",
    "# Add these only if you have accounts:\n",
    "OPENAI_API_KEY=sk-proj-...\n",
    "ANTHROPIC_API_KEY=sk-ant-...\n",
    "GOOGLE_API_KEY=...\n",
    "TOGETHER_API_KEY=...\n",
    "GROQ_API_KEY=gsk_...\n",
    "```\n",
    "\n",
    "The keys will be available as `os.environ['PROVIDER_API_KEY']` after running `config_paths_keys()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How `llm_generate()` Works with Multiple Providers\n",
    "\n",
    "The function has been simplified:\n",
    "\n",
    "```python\n",
    "llm_generate(\n",
    "    model_name,\n",
    "    prompts,\n",
    "    api_key=None,  # If None, uses OPENROUTER_API_KEY\n",
    "    base_url=\"https://openrouter.ai/api/v1\",  # Default to OpenRouter\n",
    "    cost_per_m_in=None,  # $/M input tokens (optional, for cost tracking)\n",
    "    cost_per_m_out=None,  # $/M output tokens (optional, for cost tracking)\n",
    "    ...\n",
    ")\n",
    "```\n",
    "\n",
    "**Key Points:**\n",
    "- Default behavior: Uses OpenRouter with automatic cost tracking\n",
    "- To use other providers: Pass `api_key` and `base_url`\n",
    "- For cost tracking: Also pass `cost_per_m_in` and `cost_per_m_out`\n",
    "- All providers loaded by `config_paths_keys()` are available as `os.environ['KEY_NAME']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Environment: Unknown Environment | Course root: /mnt/e/GDrive_baggett.jeff/Teaching/Classes_current/2025-2026_Fall_DS776/DS776\n",
      "   Using workspace: <DS776_ROOT_DIR>/home_workspace\n",
      "\n",
      "üìÇ Storage Configuration:\n",
      "   DATA_PATH: <DS776_ROOT_DIR>/home_workspace/data\n",
      "   MODELS_PATH: <DS776_ROOT_DIR>/Lessons/Lesson_07_Transformers_Intro/Lesson_07_Models (local to this notebook)\n",
      "   CACHE_PATH: <DS776_ROOT_DIR>/home_workspace/downloads\n",
      "üîë API keys: 9 loaded from home_workspace/api_keys.env\n",
      "üîê Available: ANTHROPIC_API_KEY, GEMINI_API_KEY, GOOGLE_API_KEY... (9 total)\n",
      "‚úÖ HuggingFace Hub: Logged in\n",
      "‚úÖ Loaded pricing for 330 OpenRouter models\n",
      "‚úÖ Cost tracking initialized ($9.92 credit remaining)\n",
      "üì¶ introdl v1.6.21 ready\n",
      "\n",
      "‚úÖ API keys loaded into os.environ\n",
      "   Available keys: ['ANTHROPIC_API_KEY', 'GEMINI_API_KEY', 'OPENAI_API_KEY', 'TOGETHER_API_KEY', 'ZOTERO_API_KEY',\n",
      "'GROQ_API_KEY', 'OPENROUTER_API_KEY', 'GOOGLE_API_KEY']\n"
     ]
    }
   ],
   "source": [
    "# Standard imports\n",
    "import os\n",
    "from introdl import config_paths_keys, wrap_print_text, llm_generate\n",
    "\n",
    "# Load API keys from ~/home_workspace/api_keys.env\n",
    "paths = config_paths_keys()\n",
    "\n",
    "# Wrap print to format text nicely at 120 characters\n",
    "print = wrap_print_text(print, width=120)\n",
    "\n",
    "print(\"‚úÖ API keys loaded into os.environ\")\n",
    "print(f\"   Available keys: {[k for k in os.environ.keys() if 'API_KEY' in k]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: OpenRouter (Default - Automatic Cost Tracking)\n",
    "\n",
    "No changes needed - this is our default and still works exactly the same!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üí∞ Cost: $0.000017 | Tokens: 12 in / 40 out | Model: google/gemini-2.5-flash-lite\n",
      "Transformers are a type of neural network architecture that excels at handling sequential data, like text, by using a\n",
      "mechanism called \"self-attention\" to weigh the importance of different parts of the input sequence.\n"
     ]
    }
   ],
   "source": [
    "# OpenRouter - automatic cost tracking (unchanged!)\n",
    "response = llm_generate(\n",
    "    'gemini-flash-lite',\n",
    "    'Explain transformers in one sentence',\n",
    "    print_cost=True\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: OpenAI with Manual Cost Tracking\n",
    "\n",
    "Use GPT models directly with manual cost tracking.\n",
    "\n",
    "**GPT-4o Pricing:** $2.50/M input, $10.00/M output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üí∞ Cost: $0.000340 | Tokens: 24 in / 28 out | Model: gpt-4o\n",
      "Deep learning is a subset of machine learning that involves neural networks with many layers that can learn complex\n",
      "patterns and representations from large amounts of data.\n"
     ]
    }
   ],
   "source": [
    "# OpenAI with manual cost tracking\n",
    "response = llm_generate(\n",
    "    'gpt-4o',\n",
    "    'Explain deep learning in one sentence',\n",
    "    api_key=os.environ['OPENAI_API_KEY'],\n",
    "    base_url='https://api.openai.com/v1',\n",
    "    cost_per_m_in=2.50,  # $2.50 per M input tokens\n",
    "    cost_per_m_out=10.00,  # $10.00 per M output tokens\n",
    "    print_cost=True\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 3: Anthropic (Claude)\n",
    "\n",
    "Access Claude models directly (no cost tracking by default)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è  Cost tracking requested but no pricing provided. Add cost_per_m_in and cost_per_m_out parameters to track costs for non-OpenRouter providers.\n",
      "Attention in transformers is a mechanism that allows the model to focus on different parts of the input sequence when\n",
      "processing or generating output. Here's a detailed explanation:\n",
      "\n",
      "Key Components of Attention:\n",
      "\n",
      "1. Query (Q), Key (K), and Value (V) Vectors:\n",
      "- Query: What we're looking for\n",
      "- Key: What we're comparing against\n",
      "- Value: The actual information to be aggregated\n",
      "\n",
      "2. Basic Steps:\n",
      "- Calculate compatibility scores between Query and all Keys\n",
      "- Convert scores to probabilities using softmax\n",
      "- Use these probabilities to create a weighted sum of Values\n",
      "\n",
      "Types of Attention:\n",
      "\n",
      "1. Self-Attention:\n",
      "- Each position attends to all positions in the same sequence\n",
      "- Helps understand relationships between different parts of the input\n",
      "\n",
      "2. Multi-Head Attention:\n",
      "- Multiple attention mechanisms in parallel\n",
      "- Allows the model to focus on different aspects simultaneously\n",
      "\n",
      "3. Maske\n"
     ]
    }
   ],
   "source": [
    "# Anthropic (no cost tracking)\n",
    "response = llm_generate(\n",
    "    'claude-3-5-sonnet-20241022',\n",
    "    'What is attention in transformers?',\n",
    "    api_key=os.environ['ANTHROPIC_API_KEY'],\n",
    "    base_url='https://api.anthropic.com/v1',\n",
    "    max_tokens=200\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 4: Google Gemini\n",
    "\n",
    "Use Gemini models directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è  Cost tracking requested but no pricing provided. Add cost_per_m_in and cost_per_m_out parameters to track costs for non-OpenRouter providers.\n",
      "Okay, here's a brief explanation of backpropagation, focusing on the key concepts:\n",
      "\n",
      "**In a Nutshell:**\n",
      "\n",
      "Backpropagation is the algorithm used to train artificial neural networks. It's how the network learns to adjust its\n",
      "internal parameters (weights and biases) to make more accurate predictions. It does this by calculating the error at the\n",
      "output and then propagating that error *backwards* through the network to update the weights and biases.\n",
      "\n",
      "**Key Steps (Simplified):**\n",
      "\n",
      "1. **Forward Pass:**\n",
      "   - Input data is fed into the network.\n",
      "   - The data passes through each layer, with each neuron performing a calculation (weighted sum of inputs + bias,\n",
      "followed by an activation function).\n",
      "   - The\n"
     ]
    }
   ],
   "source": [
    "# Google Gemini\n",
    "response = llm_generate(\n",
    "    'gemini-2.0-flash-exp',\n",
    "    'Explain backpropagation briefly',\n",
    "    api_key=os.environ['GOOGLE_API_KEY'],\n",
    "    base_url='https://generativelanguage.googleapis.com/v1beta/openai/',\n",
    "    max_tokens=150\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 5: Together.AI (Open Models)\n",
    "\n",
    "Access open-weight models like Llama through Together.AI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è  Cost tracking requested but no pricing provided. Add cost_per_m_in and cost_per_m_out parameters to track costs for non-OpenRouter providers.\n",
      "**Gradient Descent: A Fundamental Optimization Algorithm**\n",
      "\n",
      "Gradient descent is a widely used optimization algorithm in machine learning and mathematical optimization. It is a\n",
      "first-order iterative optimization algorithm that finds the minimum (or maximum) of a function by iteratively adjusting\n",
      "the parameters of the function.\n",
      "\n",
      "**How Gradient Descent Works:**\n",
      "\n",
      "The basic idea behind gradient descent is to iteratively update the parameters of a function to minimize (or maximize)\n",
      "the function's value. Here's a step-by-step explanation:\n",
      "\n",
      "1. **Initialize Parameters**: Start with an initial guess for the parameters of the function.\n",
      "2. **Compute Gradient**: Calculate the gradient of the function at the current parameters. The gradient points in the\n",
      "direction of the greatest increase of the function.\n",
      "3. **Update\n"
     ]
    }
   ],
   "source": [
    "# Together.AI\n",
    "response = llm_generate(\n",
    "    'meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo',\n",
    "    'What is gradient descent?',\n",
    "    api_key=os.environ['TOGETHER_API_KEY'],\n",
    "    base_url='https://api.together.xyz/v1',\n",
    "    max_tokens=150\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 6: Groq (Ultra-Fast Inference)\n",
    "\n",
    "Groq offers extremely fast inference for supported models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è  Cost tracking requested but no pricing provided. Add cost_per_m_in and cost_per_m_out parameters to track costs for non-OpenRouter providers.\n",
      "**Convolutional Neural Networks (CNNs)**\n",
      "\n",
      "Convolutional Neural Networks (CNNs) are a type of neural network designed to process data with grid-like topology, such\n",
      "as images. They are widely used in computer vision tasks, including:\n",
      "\n",
      "* Image classification\n",
      "* Object detection\n",
      "* Segmentation\n",
      "* Image generation\n",
      "\n",
      "**Key Components of CNNs:**\n",
      "\n",
      "1. **Convolutional Layers**: These layers apply filters to small regions of the input data, scanning the data in a\n",
      "sliding\n",
      "\n",
      "‚ö° Response time: 0.43s\n"
     ]
    }
   ],
   "source": [
    "# Groq - ultra-fast\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "response = llm_generate(\n",
    "    'llama-3.3-70b-versatile',\n",
    "    'What are CNNs?',\n",
    "    api_key=os.environ['GROQ_API_KEY'],\n",
    "    base_url='https://api.groq.com/openai/v1',\n",
    "    max_tokens=100\n",
    ")\n",
    "elapsed = time.time() - start\n",
    "\n",
    "print(response)\n",
    "print(f\"\\n‚ö° Response time: {elapsed:.2f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost Tracking Comparison\n",
    "\n",
    "### OpenRouter (Automatic)\n",
    "```python\n",
    "llm_generate('gemini-flash-lite', 'Your prompt', print_cost=True)\n",
    "# üí∞ Cost: $0.000012 | Tokens: 15 in / 25 out | Model: google/gemini-2.5-flash-lite\n",
    "```\n",
    "\n",
    "### Other Providers (Manual)\n",
    "```python\n",
    "llm_generate('gpt-4o', 'Your prompt',\n",
    "             api_key=os.environ['OPENAI_API_KEY'],\n",
    "             base_url='https://api.openai.com/v1',\n",
    "             cost_per_m_in=2.50,\n",
    "             cost_per_m_out=10.00,\n",
    "             print_cost=True)\n",
    "# üí∞ Cost: $0.000287 | Tokens: 15 in / 25 out | Model: gpt-4o\n",
    "```\n",
    "\n",
    "### Without Cost Parameters\n",
    "```python\n",
    "llm_generate('gpt-4o', 'Your prompt',\n",
    "             api_key=os.environ['OPENAI_API_KEY'],\n",
    "             base_url='https://api.openai.com/v1',\n",
    "             print_cost=True)\n",
    "# ‚ö†Ô∏è  Cost tracking requested but no pricing provided. Add cost_per_m_in and cost_per_m_out parameters...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monitoring Costs Through Provider Dashboards\n",
    "\n",
    "Since automatic tracking only works with OpenRouter, monitor costs through provider dashboards:\n",
    "\n",
    "- **OpenAI**: https://platform.openai.com/usage\n",
    "- **Anthropic**: https://console.anthropic.com/settings/usage  \n",
    "- **Google**: https://console.cloud.google.com/billing\n",
    "- **Together.AI**: https://api.together.xyz/settings/billing\n",
    "- **Groq**: https://console.groq.com/settings/billing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Processing Works with All Providers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üí∞ Cost: $0.000622 | Tokens: 71 in / 1019 out | Model: gpt-4o-mini\n",
      "\n",
      "1. Supervised learning is a type of machine learning where a model is trained on a labeled dataset. In this context,\n",
      "\"labeled\" means that each training example is paired with an output label or target value that the model is supposed to\n",
      "predict. The goal of supervised learning is to learn a mapping from inputs to outputs based on this training data.\n",
      "\n",
      "The process typically involves the following steps:\n",
      "\n",
      "1. **Dataset Preparation**: A dataset is prepared that includes input features (independent variables) and their\n",
      "corresponding output labels (dependent variables).\n",
      "\n",
      "2. **Model Selection**: A suitable machine learning algorithm or model is chosen based on the nature of the data and the\n",
      "problem to be solved.\n",
      "\n",
      "3. **Training**: The model is trained using the labeled dataset. During training, the model learns to identify patterns\n",
      "and relationships in the data that correlate the input features with the output labels.\n",
      "\n",
      "4. **Evaluation**: After training, the model is evaluated on a separate test dataset that it has not seen before. This\n",
      "step is crucial to assess how well the model generalizes to new, unseen data.\n",
      "\n",
      "5. **Prediction**: Once the model is trained and validated, it can be used to make predictions on new instances where\n",
      "the output labels are unknown.\n",
      "\n",
      "Supervised learning is commonly used for tasks such as:\n",
      "\n",
      "- **Classification**: Assigning input data to discrete categories (e.g., spam detection in emails).\n",
      "- **Regression**: Predicting continuous values (e.g., predicting house prices based on features like size and location).\n",
      "\n",
      "Overall, supervised learning is widely used in various applications, including finance, healthcare, natural language\n",
      "processing, and image recognition, among others.\n",
      "\n",
      "2. Unsupervised learning is a type of machine learning where the algorithm is trained on data without labeled outputs.\n",
      "Unlike supervised learning, where the model learns from a dataset containing input-output pairs (i.e., the model is\n",
      "provided with the correct answers during training), unsupervised learning deals with data that has no explicit labels.\n",
      "\n",
      "The main goal of unsupervised learning is to identify patterns, structures, or relationships within the data. It can be\n",
      "used for various tasks, including:\n",
      "\n",
      "1. **Clustering**: Grouping similar data points together based on their features. Common algorithms include K-means,\n",
      "hierarchical clustering, and DBSCAN.\n",
      "\n",
      "2. **Dimensionality Reduction**: Reducing the number of features or dimensions in the dataset while preserving important\n",
      "information. Techniques include Principal Component Analysis (PCA), t-Distributed Stochastic Neighbor Embedding (t-SNE),\n",
      "and Autoencoders.\n",
      "\n",
      "3. **Anomaly Detection**: Identifying unusual data points that do not fit the general pattern of the data. This is often\n",
      "used in fraud detection or network security.\n",
      "\n",
      "4. **Association Rule Learning**: Discovering interesting relationships or associations between variables in large\n",
      "datasets, such as market basket analysis.\n",
      "\n",
      "Unsupervised learning is particularly useful when you have a large amount of data but lack the resources or labels to\n",
      "categorize it manually. It can help uncover hidden structures in data and provide insights that might not be immediately\n",
      "apparent.\n",
      "\n",
      "3. Reinforcement learning (RL) is a type of machine learning where an agent learns to make decisions by taking actions\n",
      "in an environment to maximize some notion of cumulative reward. The key components of reinforcement learning include:\n",
      "\n",
      "1. **Agent**: The learner or decision-maker that interacts with the environment.\n",
      "\n",
      "2. **Environment**: The setting or context in which the agent operates. The environment provides feedback to the agent\n",
      "based on its actions.\n",
      "\n",
      "3. **State**: A representation of the current situation of the agent within the environment. The state can change over\n",
      "time based on the actions taken by the agent.\n",
      "\n",
      "4. **Action**: A choice made by the agent that affects the state of the environment. The set of all possible actions is\n",
      "referred to as the action space.\n",
      "\n",
      "5. **Reward**: A scalar feedback signal received by the agent after taking an action in a given state. The reward\n",
      "indicates the immediate benefit of the action taken.\n",
      "\n",
      "6. **Policy**: A strategy used by the agent to determine the next action based on the current state. The policy can be\n",
      "deterministic or stochastic.\n",
      "\n",
      "7. **Value Function**: A function that estimates the expected cumulative reward that can be obtained from a given state\n",
      "(or state-action pair). It helps the agent evaluate how good a state or action is in terms of long-term reward.\n",
      "\n",
      "The learning process typically involves the following steps:\n",
      "1. The agent observes the current state of the environment.\n",
      "2. The agent selects an action based on its policy.\n",
      "3. The action is executed, and the environment responds by transitioning to a new state and providing a reward.\n",
      "4. The agent updates its policy and/or value functions based on the reward received and the new state.\n",
      "\n",
      "Reinforcement learning is often used in various applications, including robotics, game playing (e.g., AlphaGo),\n",
      "autonomous vehicles, and recommendation systems. It is particularly well-suited for problems where the optimal strategy\n",
      "is not known in advance and must be learned through exploration and exploitation of the environment.\n"
     ]
    }
   ],
   "source": [
    "# Batch processing with any provider\n",
    "prompts = [\n",
    "    \"What is supervised learning?\",\n",
    "    \"What is unsupervised learning?\",\n",
    "    \"What is reinforcement learning?\"\n",
    "]\n",
    "\n",
    "responses = llm_generate(\n",
    "    'gpt-4o-mini',\n",
    "    prompts,\n",
    "    api_key=os.environ['OPENAI_API_KEY'],\n",
    "    base_url='https://api.openai.com/v1',\n",
    "    cost_per_m_in=0.15,\n",
    "    cost_per_m_out=0.60,\n",
    "    print_cost=True\n",
    ")\n",
    "\n",
    "for i, response in enumerate(responses, 1):\n",
    "    print(f\"\\n{i}. {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common Base URLs Reference\n",
    "\n",
    "```python\n",
    "# OpenRouter (default)\n",
    "base_url = \"https://openrouter.ai/api/v1\"\n",
    "\n",
    "# OpenAI\n",
    "base_url = \"https://api.openai.com/v1\"\n",
    "\n",
    "# Anthropic\n",
    "base_url = \"https://api.anthropic.com/v1\"\n",
    "\n",
    "# Google (Gemini)\n",
    "base_url = \"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    "\n",
    "# Together.AI\n",
    "base_url = \"https://api.together.xyz/v1\"\n",
    "\n",
    "# Groq\n",
    "base_url = \"https://api.groq.com/openai/v1\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "**Recommendation: Stick with OpenRouter** for this course because:\n",
    "- ‚úÖ Automatic cost tracking\n",
    "- ‚úÖ Single API key for all models\n",
    "- ‚úÖ $15 credit provided\n",
    "- ‚úÖ Simple to use\n",
    "\n",
    "**Use other providers if:**\n",
    "- You need ~5.5% lower costs (direct API)\n",
    "- You already have API credits elsewhere\n",
    "\n",
    "**Remember:**\n",
    "- All keys go in `~/home_workspace/api_keys.env`\n",
    "- Load with `config_paths_keys()`\n",
    "- Pass `cost_per_m_in` and `cost_per_m_out` for manual cost tracking\n",
    "- Monitor costs through provider dashboards"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ds776_env)",
   "language": "python",
   "name": "ds776_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
