{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To perform transfer learning with ResNet-18 using Hugging Face tools on the Cats and Dogs dataset, you can use the `transformers` and `datasets` libraries for model setup and data preprocessing. Here’s a guide to set this up:\n",
    "\n",
    "### 1. Install Necessary Packages\n",
    "Ensure you have the Hugging Face `transformers` and `datasets` libraries installed:\n",
    "\n",
    "### 2. Load the Dataset\n",
    "You can use the `datasets` library to load and preprocess the dataset from Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0b17ea00e3d4dc0a76026d30c41faa2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/25000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73bf43a7c921489a8659b9d907b43ba7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/19998 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jbaggett/miniforge3/envs/DS776v2/lib/python3.11/site-packages/PIL/TiffImagePlugin.py:900: UserWarning: Truncated File Read\n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bce10965e65b4a9a88f6855718855d9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from torchvision import transforms\n",
    "\n",
    "# Load only the dataset without predefined train/test splits\n",
    "dataset = load_dataset(\n",
    "    \"imagefolder\",\n",
    "    data_dir=\"../../data/cats_and_dogs/PetImages\",\n",
    "    split=\"train\"  # Load the entire dataset initially\n",
    ").train_test_split(test_size=0.2)  # Split into 80% train and 20% test\n",
    "\n",
    "# Define the transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(130),\n",
    "    transforms.CenterCrop(128),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Apply transformations to each image\n",
    "def preprocess_images(example):\n",
    "    example['image'] = transform(example['image'])\n",
    "    return example\n",
    "\n",
    "# Map transformations onto both train and test splits\n",
    "dataset['train'] = dataset['train'].map(preprocess_images, batched=False)\n",
    "dataset['test'] = dataset['test'].map(preprocess_images, batched=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### 3. Load the ResNet-18 Model from Hugging Face\n",
    "Using `transformers`, load the ResNet-18 model and modify its classification head.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForImageClassification\n",
    "import torch\n",
    "\n",
    "# Load a ResNet-18 model pretrained on ImageNet\n",
    "model = AutoModelForImageClassification.from_pretrained(\"microsoft/resnet-18\")\n",
    "\n",
    "# Change the classification head to output 2 classes\n",
    "model.classifier[-1] = torch.nn.Linear(model.classifier[-1].in_features, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### 4. Training Loop\n",
    "You can set up a training loop or use the Hugging Face `Trainer` API to simplify training. Here’s an example using `Trainer`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1:   0%|          | 0/1250 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'to'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 24\u001b[0m\n\u001b[1;32m     21\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m tqdm(train_loader, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining Epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;66;03m# Get data and move to device\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimage\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m(device)\n\u001b[1;32m     25\u001b[0m     labels \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;66;03m# Zero the gradients\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'to'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Set up data loaders\n",
    "train_loader = DataLoader(dataset['train'], batch_size=16, shuffle=True)\n",
    "eval_loader = DataLoader(dataset['test'], batch_size=16)\n",
    "\n",
    "# Set model to device\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Initialize optimizer\n",
    "optimizer = AdamW(model.parameters(), lr=1e-4)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 3\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch in tqdm(train_loader, desc=f\"Training Epoch {epoch+1}\"):\n",
    "        # Get data and move to device\n",
    "        inputs = batch['image'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "        \n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = torch.nn.functional.cross_entropy(outputs.logits, labels)\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "    \n",
    "    avg_train_loss = train_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch+1} Train Loss: {avg_train_loss:.4f}\")\n",
    "    \n",
    "    # Evaluation loop\n",
    "    model.eval()\n",
    "    eval_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in eval_loader:\n",
    "            inputs = batch['image'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            loss = torch.nn.functional.cross_entropy(outputs.logits, labels)\n",
    "            eval_loss += loss.item()\n",
    "            \n",
    "            # Get predictions\n",
    "            preds = outputs.logits.argmax(dim=1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "    \n",
    "    avg_eval_loss = eval_loss / len(eval_loader)\n",
    "    accuracy = correct / len(dataset['test'])\n",
    "    print(f\"Epoch {epoch+1} Eval Loss: {avg_eval_loss:.4f}, Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "This setup allows you to perform transfer learning on ResNet-18 using Hugging Face tools, with the desired resizing, center cropping, and modified classification head for binary classification."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DS776v2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
