{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **10-Question Multiple-Choice Reading Quiz for Chapter 6: \"Summarization\"**  \n",
    "\n",
    "---\n",
    "\n",
    "#### **1. What distinguishes abstractive summarization from extractive summarization?**  \n",
    "A. Extractive summarization generates entirely new phrases.  \n",
    "B. Abstractive summarization generates new sentences to convey the inputâ€™s meaning.  \n",
    "C. Abstractive summarization selects and rearranges sentences from the input.  \n",
    "D. Extractive summarization requires fine-tuning on specific tasks.  \n",
    "**Answer**: B  \n",
    "\n",
    "---\n",
    "\n",
    "#### **2. Which dataset is commonly used for training summarization models?**  \n",
    "A. SQuAD  \n",
    "B. GLUE  \n",
    "C. CNN/DailyMail  \n",
    "D. CoNLL-2003  \n",
    "**Answer**: C  \n",
    "\n",
    "---\n",
    "\n",
    "#### **3. What is the primary advantage of transformer models like BART for summarization tasks?**  \n",
    "A. They tokenize inputs into characters for better granularity.  \n",
    "B. They rely on convolutional layers to improve performance.  \n",
    "C. They use a purely encoder-based architecture.  \n",
    "D. They combine a bidirectional encoder with an autoregressive decoder.  \n",
    "**Answer**: D  \n",
    "\n",
    "---\n",
    "\n",
    "#### **4. How does the ROUGE metric evaluate summarization quality?**  \n",
    "A. By comparing the complexity of the input and output text.  \n",
    "B. By measuring the length of generated summaries.  \n",
    "C. By assessing the grammatical correctness of the summary.  \n",
    "D. By calculating the overlap between generated and reference summaries.  \n",
    "**Answer**: D  \n",
    "\n",
    "---\n",
    "\n",
    "#### **5. What is one key feature of the PEGASUS model for summarization?**  \n",
    "A. It uses a pretraining objective focused on gap-sentence generation.  \n",
    "B. It predicts masked tokens using a sequence-to-sequence architecture.  \n",
    "C. It relies exclusively on extractive summarization techniques.  \n",
    "D. It does not require fine-tuning for domain-specific tasks.  \n",
    "**Answer**: A  \n",
    "\n",
    "---\n",
    "\n",
    "#### **6. Why is summarization considered a sequence-to-sequence (seq2seq) task?**  \n",
    "A. It requires aligning each input token to an output token.  \n",
    "B. It maps an input sequence (text) to a target sequence (summary).  \n",
    "C. It processes sequences in a parallel manner without alignment.  \n",
    "D. It involves labeling individual tokens in the input sequence.  \n",
    "**Answer**: B  \n",
    "\n",
    "---\n",
    "\n",
    "#### **7. Which of the following is a challenge specific to abstractive summarization?**  \n",
    "A. Generating summaries that are too short.  \n",
    "B. Maintaining factual consistency between the input and output.  \n",
    "C. Limited availability of datasets for training extractive models.  \n",
    "D. Preserving grammatical correctness in the summary.  \n",
    "**Answer**: B  \n",
    "\n",
    "---\n",
    "\n",
    "#### **8. What is the role of fine-tuning in summarization models?**  \n",
    "A. To adapt pre-trained models like BART or T5 to specific domains.  \n",
    "B. To eliminate the need for evaluation metrics like ROUGE.  \n",
    "C. To train models from scratch for specific tasks.  \n",
    "D. To replace the encoder architecture for abstractive tasks.  \n",
    "**Answer**: A  \n",
    "\n",
    "---\n",
    "\n",
    "#### **9. In which domain is summarization frequently applied?**  \n",
    "A. Summarizing customer service interactions for efficiency.  \n",
    "B. Natural language generation for chatbots.  \n",
    "C. Sentiment analysis of product reviews.  \n",
    "D. Translation of multilingual documents.  \n",
    "**Answer**: A  \n",
    "\n",
    "---\n",
    "\n",
    "#### **10. What is one limitation of using ROUGE for evaluating abstractive summarization?**  \n",
    "A. It does not provide any insight into grammatical correctness.  \n",
    "B. It is computationally intensive for large datasets.  \n",
    "C. It struggles to measure overlap between summaries and references.  \n",
    "D. It relies heavily on word order, which abstractive summaries may change.  \n",
    "**Answer**: D  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
